<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Consulting Interview Training Materials</title>
    <url>/2021/06/16/Consulting-Case-Frameworks/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>This is a backup of some useful resources</p>
<blockquote>
<ol>
<li>STREETOFWALLS, <a href="http://www.streetofwalls.com/finance-training-courses/consulting-case-study-training/consulting-case-study-101-frameworks/" target="_blank" rel="noopener">CONSULTING CASE STUDY 101: AN INTRODUCTION TO FRAMEWORKS</a></li>
<li>Accenture, <a href="https://www.accenture.com/_acnmedia/Careers/PDF-14/Accenture-FY19-Case-Workbook.pdf" target="_blank" rel="noopener">Case Interview Workbook</a></li>
<li>STREETOFWALLS, <a href="http://www.streetofwalls.com/finance-training-courses/consulting-interview-training/consulting-interview-questions/" target="_blank" rel="noopener">CONSULTING INTERVIEW QUESTIONS &amp; ANSWERS</a></li>
<li><a href="https://www.consultingcase101.com/" target="_blank" rel="noopener">consultingcase101</a></li>
</ol>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>Dilution of investment</title>
    <url>/2021/06/08/Dilution-of-investment/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Investments"><a href="#Investments" class="headerlink" title="Investments"></a>Investments</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right">Investor</th>
<th style="text-align:right">Entry</th>
<th style="text-align:right">Investment</th>
<th style="text-align:right">Required return (discount rate)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">Angel</td>
<td style="text-align:right">Year 0</td>
<td style="text-align:right">500K</td>
<td style="text-align:right">50%</td>
</tr>
<tr>
<td style="text-align:right">VC1</td>
<td style="text-align:right">Year 2</td>
<td style="text-align:right">750K</td>
<td style="text-align:right">40%</td>
</tr>
<tr>
<td style="text-align:right">VC2</td>
<td style="text-align:right">Year 4</td>
<td style="text-align:right">1M</td>
<td style="text-align:right">25%</td>
</tr>
</tbody>
</table>
</div>
<p>Net profits in year 5: 375K<br>Valuation/profits = 20<br>Valuation = 20 profits = 20 * 375K = 7.5 M<br>The expected valuation in 5 years is 7.5M </p>
<a id="more"></a>
<h2 id="Angle-Round-Year-0-500K-50"><a href="#Angle-Round-Year-0-500K-50" class="headerlink" title="Angle Round (Year 0, 500K, 50%)"></a>Angle Round (Year 0, 500K, 50%)</h2><p><strong>Q:</strong> What is the valuation today?<br><strong>A:</strong> 7.5M/(1+50%)^5 = 987654<br>—&gt;<br>Angle owns 500k/987654 = 50.6%<br>Founders own 49.4%</p>
<p><strong>Shares</strong><br>100,000 shares already belong to founders<br>100000/(100000+x) = 49.4%<br>—&gt;<br>x = 102,532 angle shares<br>102532+100000 = 202532 total # of shares</p>
<p><strong>Pre-money &amp; post-money (angel round)</strong><br>post-money evaluation<br>987k<br>pre-money evaluation<br>987k-500k = 487k</p>
<p><strong>Price/share</strong> = post money / # of shares<br>= 987654/202532 = 4.88</p>
<h2 id="VC1-Year-2-750K-40"><a href="#VC1-Year-2-750K-40" class="headerlink" title="VC1 (Year 2, 750K, 40%)"></a>VC1 (Year 2, 750K, 40%)</h2><p><strong>Q:</strong> The future value of a 750K investment in year 5<br><strong>A:</strong> 750K * (1+40%)^3 = 2.06M<br>—&gt;<br>VC1 owns 2.06M/7.5M = 27.4%<br>Angle and Founders own 72.6%</p>
<p><strong>Shares</strong><br>202532 total # of shares in angle round<br>202532/(202532+x) = 72.6%<br>—&gt;<br>x = 76591 vc1 shares<br>202532+76591 = 279123 total # of shares</p>
<p><strong>Post-money (vc1 round)</strong><br>post-money evaluation<br>7.5M / (1+40)^3 = 2.73M<br>pre-money evaluation<br>2.73M-750k = 1.98M</p>
<p><strong>Price/share</strong> = post money / # of shares<br>= 2.73M/279123 = 9.79</p>
<p><strong>Diluted</strong><br>VC1 owns 27.4%<br>Founders own 100000/279123 = 35.8%<br>Angles own 102532/279123 = 36.7%</p>
<h2 id="VC2-Year-4-1M-25"><a href="#VC2-Year-4-1M-25" class="headerlink" title="VC2 (Year 4, 1M, 25%)"></a>VC2 (Year 4, 1M, 25%)</h2><p><strong>Q:</strong> The future value of a 1M investment in year 5<br><strong>A:</strong> 1M * (1+25%)^1 = 1.25M<br>—&gt;<br>VC2 owns 1.25/7.5M = 16.7%<br>Angle and Founders own 83.3%</p>
<p><strong>Shares</strong><br>279123 total # of shares in vc1 round<br>279123/(279123+x) = 83.3%<br>—&gt;<br>x = 55959 vc2 shares<br>279123+55959 = 335082 total # of shares</p>
<p><strong>Post-money (vc1 round)</strong><br>post-money evaluation<br>7.5M / (1+25)^1 = 6M<br>pre-money evaluation<br>6M-1M = 5M</p>
<p><strong>Price/share</strong> = post money / # of shares<br>= 5M/335082  = 17.9</p>
<p><strong>Diluted</strong><br>VC2 owns 16.7%<br>Founders own 100000/335082 = 29.8%<br>Angles own 102532/335082 = 30.6%<br>VC1 owns 76591/335082 = 22.9%</p>
<h2 id="Dilution-50-discount-rate"><a href="#Dilution-50-discount-rate" class="headerlink" title="Dilution (50% discount rate)"></a>Dilution (50% discount rate)</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right">Round</th>
<th style="text-align:right">Year</th>
<th style="text-align:right">Invest</th>
<th style="text-align:right">Post-money Evaluation</th>
<th style="text-align:right">Founders</th>
<th style="text-align:right">Angle</th>
<th style="text-align:right">VC1</th>
<th style="text-align:right">VC2</th>
<th style="text-align:right">Price/share</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">Angel</td>
<td style="text-align:right">Year 0</td>
<td style="text-align:right">500K</td>
<td style="text-align:right">988k</td>
<td style="text-align:right">49.4%</td>
<td style="text-align:right">50.6%</td>
<td style="text-align:right">/</td>
<td style="text-align:right">/</td>
<td style="text-align:right">4.88</td>
</tr>
<tr>
<td style="text-align:right">VC1</td>
<td style="text-align:right">Year 2</td>
<td style="text-align:right">750K</td>
<td style="text-align:right">2.7M</td>
<td style="text-align:right">35.8%</td>
<td style="text-align:right">36.7%</td>
<td style="text-align:right">27.4%</td>
<td style="text-align:right">/</td>
<td style="text-align:right">9.79</td>
</tr>
<tr>
<td style="text-align:right">VC2</td>
<td style="text-align:right">Year 4</td>
<td style="text-align:right">1M</td>
<td style="text-align:right">6M</td>
<td style="text-align:right">29.8%</td>
<td style="text-align:right">30.6%</td>
<td style="text-align:right">22.9%</td>
<td style="text-align:right">16.7%</td>
<td style="text-align:right">17.9</td>
</tr>
<tr>
<td style="text-align:right">Exit</td>
<td style="text-align:right">Year 5</td>
<td style="text-align:right">/</td>
<td style="text-align:right">7.5M</td>
<td style="text-align:right">2.24M</td>
<td style="text-align:right">2.30M</td>
<td style="text-align:right">1.72M</td>
<td style="text-align:right">1.25M</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td style="text-align:right">4.6x</td>
<td style="text-align:right">2.3x</td>
<td style="text-align:right">1.25x</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>Business</category>
      </categories>
  </entry>
  <entry>
    <title>Quantative Risk Management - Warp-up</title>
    <url>/2021/01/10/Quantative-Risk-Management-Warp-up/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h1><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/51.%20Warp-up.png" alt></p>
<h1 id="Toolkit"><a href="#Toolkit" class="headerlink" title="Toolkit"></a>Toolkit</h1><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/52.%20Toolkit.png" alt></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/53.%20Reference.png" alt></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Quantative Risk Management 4/4 - Advanced risk management</title>
    <url>/2021/01/10/Quantative-Risk-Management-4-4-Advanced-risk-management/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>4/4 Objectives:</strong></p>
<ol>
<li>explore more general risk management tools. These advanced techniques are pivotal when attempting to understand extreme events, such as losses incurred during the financial crisis, and complicated loss distributions which may defy traditional estimation techniques. </li>
<li>discover how neural networks can be implemented to approximate loss distributions and conduct real-time portfolio optimization.</li>
</ol>
<a id="more"></a>
<h1 id="Extreme-value-theory"><a href="#Extreme-value-theory" class="headerlink" title="Extreme value theory"></a>Extreme value theory</h1><p>Extreme value theory uses statistics to help understand the distribution of extreme values. In other words, it is a way to help model _the tail_ of the loss distribution. One way to do this is called the “block maxima” approach. </p>
<p><strong>Extreme value theory</strong>: statistical distribution of extre values<br><strong>Block Maxima</strong>:</p>
<ul>
<li>break period into sub-periods</li>
<li>form blocks from each sub-period</li>
<li>set of block maxima = dataset<br><strong>Peak over threshold (POT)</strong>:</li>
<li>Find all losses over given level</li>
<li>Set of such losses = dataset</li>
</ul>
<h2 id="Generalized-Extreme-Value-Distribution-GEV"><a href="#Generalized-Extreme-Value-Distribution-GEV" class="headerlink" title="Generalized Extreme Value Distribution (GEV)"></a>Generalized Extreme Value Distribution (GEV)</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/32.%20GEV.png" alt></p>
<h2 id="VaR-and-CVaR-from-GEV-distribution"><a href="#VaR-and-CVaR-from-GEV-distribution" class="headerlink" title="VaR and CVaR from GEV distribution"></a>VaR and CVaR from GEV distribution</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/33.%20VaR%20CVaR%20and%20GEV.png" alt></p>
<h2 id="Coving-losses"><a href="#Coving-losses" class="headerlink" title="Coving losses"></a>Coving losses</h2><p>risk management: covering losses</p>
<ul>
<li><strong>regulatory requirement</strong> (banks, insurance)</li>
<li>reserves must be avaliable to cover losses (for a specific time peroid/ at a specific confidence level)</li>
</ul>
<p><strong>VaR from GEV distribution</strong>:<br>estimate maximum loss in a given period and at a given confidence level</p>
<p>Example: reserve requirement （储备金要求）<br>99％的置信水平和一周的时间范围内<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/34.%20Covering%20losses%20example.png" alt></p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="Block-maxima"><a href="#Block-maxima" class="headerlink" title="Block maxima"></a>Block maxima</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Resample the data into weekly blocks</span></span><br><span class="line">weekly_maxima = losses.resample(<span class="string">"W"</span>).max()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the resulting weekly maxima</span></span><br><span class="line">axis_1.plot(weekly_maxima, label = <span class="string">"Weekly Maxima"</span>)</span><br><span class="line">axis_1.legend()</span><br><span class="line">plt.figure(<span class="string">"weekly"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resample the data into monthly blocks</span></span><br><span class="line">monthly_maxima = losses.resample(<span class="string">"M"</span>).max()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the resulting monthly maxima</span></span><br><span class="line">axis_2.plot(monthly_maxima, label = <span class="string">"Monthly Maxima"</span>)</span><br><span class="line">axis_2.legend()</span><br><span class="line">plt.figure(<span class="string">"monthly"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resample the data into quarterly blocks</span></span><br><span class="line">quarterly_maxima = losses.resample(<span class="string">"Q"</span>).max()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the resulting quarterly maxima</span></span><br><span class="line">axis_3.plot(quarterly_maxima, label = <span class="string">"Quarterly Maxima"</span>)</span><br><span class="line">axis_3.legend()</span><br><span class="line">plt.figure(<span class="string">"quarterly"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/35.%20Block%20maxima.svg" alt="Block maxima"></p>
<h3 id="Extreme-events-during-the-crisis"><a href="#Extreme-events-during-the-crisis" class="headerlink" title="Extreme events during the crisis"></a>Extreme events during the crisis</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Plot the log daily losses of GE over the period 2007-2009</span></span><br><span class="line">losses.plot()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find all daily losses greater than 10%</span></span><br><span class="line">extreme_losses = losses[losses &gt; <span class="number">0.10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatter plot the extreme losses</span></span><br><span class="line">extreme_losses.plot(style=<span class="string">'o'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/36.%20Extreme%20events%20during%20the%20crisis.svg" alt="Extreme events during the crisis"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Fit extreme distribution to weekly maximum of losses</span><br><span class="line">fitted = genextreme.fit(weekly_max)</span><br><span class="line"></span><br><span class="line"># Plot extreme distribution with weekly max losses historgram</span><br><span class="line">x = np.linspace(min(weekly_max), max(weekly_max), 100)</span><br><span class="line">plt.plot(x, genextreme.pdf(x, *fitted))</span><br><span class="line">plt.hist(weekly_max, 50, density = True, alpha = 0.3)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/37.%20Extreme%20events%20during%20the%20crisis.svg" alt></p>
<h3 id="GEV-risk-estimation"><a href="#GEV-risk-estimation" class="headerlink" title="GEV risk estimation"></a>GEV risk estimation</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Compute the weekly block maxima for GE&apos;s stock</span><br><span class="line">weekly_maxima = losses.resample(&quot;W&quot;).max()</span><br><span class="line"></span><br><span class="line"># Fit the GEV distribution to the maxima</span><br><span class="line">p = genextreme.fit(weekly_maxima)</span><br><span class="line"></span><br><span class="line"># Compute the 99% VaR (needed for the CVaR computation)</span><br><span class="line">VaR_99 = genextreme.ppf(0.99, *p)</span><br><span class="line"></span><br><span class="line"># Compute the 99% CVaR estimate</span><br><span class="line">CVaR_99 = (1 / (1 - 0.99)) * genextreme.expect(lambda x: x, </span><br><span class="line">           args=(p[0],), loc = p[1], scale = p[2], lb = VaR_99)</span><br><span class="line"></span><br><span class="line"># Display the covering loss amount</span><br><span class="line">print(&quot;Reserve amount: &quot;, 1000000 * CVaR_99)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Reserve amount:  148202.41307731598</span><br></pre></td></tr></table></figure></p>
<h1 id="Kernel-density-estimation"><a href="#Kernel-density-estimation" class="headerlink" title="Kernel density estimation"></a>Kernel density estimation</h1><h2 id="The-histogram-revisited"><a href="#The-histogram-revisited" class="headerlink" title="The histogram revisited"></a>The histogram revisited</h2><p>Up to now our <strong><em>risk factor distributions</em></strong> have been <strong>assumed</strong> (such as the _Normal_ or _T distribution_), <strong>fitted</strong> (from, for example, _parametric estimation_ or _Monte Carlo simulation_), or <strong>ignored</strong> (as with _historical simulation_). </p>
<p>In each case, actual data can be summarized with a <strong>histogram</strong>. A histogram is not a distribution: but we would like a <strong>function</strong> to represent the histogram as a probability distribution (or density function). </p>
<p>How can we do this? A middle ground between parametric estimation and ignoring the distribution is to _filter the data so that they become smooth enough to represent a distribution._ This can be done with <strong>non-parametric</strong> estimation, which does <strong>not assume</strong> a parametrized class of distributions (such as the Normal, Skewed Normal, or Student’s t-distribution).</p>
<h2 id="Data-smoothing"><a href="#Data-smoothing" class="headerlink" title="Data smoothing"></a>Data smoothing</h2><p>Kernal: filter choice/ the “window”<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/38.%20Kernel.png" alt="kernel"><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/39.%20Data%20Smoothing.png" alt="smooth"></p>
<h2 id="The-Gaussian-kernel"><a href="#The-Gaussian-kernel" class="headerlink" title="The Gaussian kernel"></a>The Gaussian kernel</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/40.%20The%20Gaussian%20kernel.png" alt="gaussian"></p>
<h2 id="KDE-in-Python"><a href="#KDE-in-Python" class="headerlink" title="KDE in Python"></a>KDE in Python</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/41.%20KDE%20in%20Python.png" alt="KDE in Python"></p>
<h2 id="Find-VaR-using-KDE"><a href="#Find-VaR-using-KDE" class="headerlink" title="Find VaR using KDE"></a>Find VaR using KDE</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/42.%20Find%20VaR%20using%20KDE.png" alt="Find VaR using KDE"></p>
<h2 id="Exercises-1"><a href="#Exercises-1" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id><a href="#" class="headerlink" title=" "></a> </h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generate a fitted T distribution over losses</span></span><br><span class="line">params = t.fit(losses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate a Gaussian kernal density estimate over losses</span></span><br><span class="line">kde = gaussian_kde(losses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the PDFs of both estimates to a histogram, and display</span></span><br><span class="line">loss_range = np.linspace(np.min(losses), np.max(losses), <span class="number">1000</span>)</span><br><span class="line">axis.plot(loss_range, t.pdf(loss_range, *params), label = <span class="string">'T distribution'</span>)</span><br><span class="line">axis.plot(loss_range, kde.pdf(loss_range), label = <span class="string">'Gaussian KDE'</span>)</span><br><span class="line">plt.legend(); plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/43.%20KDE%20of%20a%20loss%20distribution.svg" alt="KDE of a loss distribution"></p>
<h3 id="Fitted-distributions"><a href="#Fitted-distributions" class="headerlink" title="Fitted distributions"></a>Fitted distributions</h3><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/44.%20fitted%20distributions.svg" alt></p>
<ul>
<li>The Gaussian KDE captures the tails well, but another distribution is better at fitting the loss distribution’s peak.</li>
<li>The T distribution does capture the peak well. But there’s another distribution which captures the tails of the distribution better.</li>
<li>The T and Gaussian KDE estimates are both good fits, each in a different way: the T captures the peak well, while the KDE captures the tails better.</li>
</ul>
<h3 id="CVaR-and-loos-cover-selection"><a href="#CVaR-and-loos-cover-selection" class="headerlink" title="CVaR and loos cover selection"></a>CVaR and loos cover selection</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Find the VaR as a quantile of random samples from the distributions</span></span><br><span class="line">VaR_99_T   = np.quantile(t.rvs(size=<span class="number">1000</span>, *p), <span class="number">0.99</span>)</span><br><span class="line">VaR_99_KDE = np.quantile(kde.resample(size=<span class="number">1000</span>), <span class="number">0.99</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the expected tail losses, with lower bounds given by the VaR measures</span></span><br><span class="line">integral_T   = t.expect(<span class="keyword">lambda</span> x: x, args = (p[<span class="number">0</span>],), loc = p[<span class="number">1</span>], scale = p[<span class="number">2</span>], lb = VaR_99_T)</span><br><span class="line">integral_KDE = kde.expect(<span class="keyword">lambda</span> x: x, lb = VaR_99_KDE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the 99% CVaR estimates</span></span><br><span class="line">CVaR_99_T   = (<span class="number">1</span> / (<span class="number">1</span> - <span class="number">0.99</span>)) * integral_T</span><br><span class="line">CVaR_99_KDE = (<span class="number">1</span> / (<span class="number">1</span> - <span class="number">0.99</span>)) * integral_KDE</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the results</span></span><br><span class="line">print(<span class="string">"99% CVaR for T: "</span>, CVaR_99_T, <span class="string">"; 99% CVaR for KDE: "</span>, CVaR_99_KDE)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">99% CVaR for T:  0.2716201587142073 ; 99% CVaR for KDE:  0.2395800993943245</span><br></pre></td></tr></table></figure></p>
<h1 id="Neural-network-risk-management"><a href="#Neural-network-risk-management" class="headerlink" title="Neural network risk management"></a>Neural network risk management</h1><h2 id="Real-time-portfolio-updating"><a href="#Real-time-portfolio-updating" class="headerlink" title="Real-time portfolio updating"></a>Real-time portfolio updating</h2><p><strong>Risk management </strong></p>
<ul>
<li><strong>Define</strong> risk measures (VaR, CVaR)</li>
<li><strong>Estimate</strong> risk measures (parameteric, historical, Monte Carlo)</li>
<li><strong>Optimized</strong> portfolio (e.g. Mordern Portfolio Theory)</li>
</ul>
<p><strong>New Market information -&gt; update portfolio weights</strong></p>
<ul>
<li><strong>Problem</strong>: portfolio optimization costly</li>
<li><strong>Solution:</strong> weights = <em>f</em>(weights)</li>
<li><em>Evaluate f </em>in real-time</li>
<li><em>Update f</em> only occasionally</li>
</ul>
<h2 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/45.%20Neural%20Networks.png" alt="Neural Networks"><br>A neural network is a function: it takes an input (such as _asset prices_) and returns an output (such as _portfolio weights_). </p>
<p>It’s called a neural network because it contains interconnected processing nodes known as ‘neurons’, loosely resembling the connections between neurons in the brain. </p>
<p><strong>Neural networks</strong> have been around since the 1940s, but they have enjoyed a resurgence of development since the early 2000s. </p>
<p>They are used to solve problems with <strong>large data sets</strong>, such as image recognition, financial analysis, and search engine performance. </p>
<p>Very large neural networks make up <strong>“Deep Learning”</strong> and are a part of the <strong>Machine Learning</strong> discipline. In 2015, Google released Tensorflow, an open-source environment, initially in Python, for performing Deep Learning.</p>
<h2 id="Neural-network-structure"><a href="#Neural-network-structure" class="headerlink" title="Neural network structure"></a>Neural network structure</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/46.%20Neural%20Network%20Structure.png" alt="Neural network structure"></p>
<h2 id="Using-neural-networks-for-portfolio-optimization"><a href="#Using-neural-networks-for-portfolio-optimization" class="headerlink" title="Using neural networks for portfolio optimization"></a>Using neural networks for portfolio optimization</h2><p>Training</p>
<ul>
<li>Compare output and pre-existing “best” portfolio weights</li>
<li>Goal: minimize “error” between output and weights</li>
<li>Small error -&gt; network is trained<br>通过将神经网络与预先存在的“最佳”权重进行比较，来评估神经网络在创建其输出中的表现。(这些权重可从历史数据的投资组合优化中找到)<br>目的是使输出和历史“最佳”权重之间的差异尽可能小，使得神经网络这个函数可以达到<strong>输出最佳投资权重</strong>的功能。</li>
</ul>
<p>Usage</p>
<ul>
<li>Input: new, unseen asset prices</li>
<li>Output: predicted “best” portfolio weights for new asset prices</li>
<li>Best weights = risk management</li>
</ul>
<h2 id="Creating-neural-networks-in-Python"><a href="#Creating-neural-networks-in-Python" class="headerlink" title="Creating neural networks in Python"></a>Creating neural networks in Python</h2><p><strong>Keras</strong>: high-level python library for neural networks/ deep learning<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">10</span>, imput_dim = <span class="number">4</span>, activation = <span class="string">'sigmoid'</span>))</span><br><span class="line">model.add(Dense(<span class="number">4</span>))</span><br></pre></td></tr></table></figure></p>
<ol>
<li>To use Keras, we first need to import the kind of neural network—this is a ‘Sequential’ network going from input-to-hidden-to-output layers. </li>
<li>Then we need to import the connections between <strong>layers</strong> (the arrows we saw previously). We’ll connect all neurons together using ‘Dense’ layers. </li>
<li>Next we’ll define our neural network ‘model’ and create our <strong>hidden and output layers</strong>, using the ‘.add()’ method. Notice how the input layer is specified with the ‘input_dim’ keyword, which in our case covers the four assets in our investment bank portfolio. And since we also need four output weights, there are four “neurons” in the last output layer. </li>
</ol>
<h2 id="Training-the-network-in-Python"><a href="#Training-the-network-in-Python" class="headerlink" title="Training the network in Python"></a>Training the network in Python</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/47.%20Training%20the%20Network.png" alt><br>We’ve put asset prices into the ‘training_input’ matrix and portfolio weights into the ‘training_output’ vector. These are used to train the network. </p>
<ol>
<li>The model is first compiled to specify the error minimization function and how optimization is performed. </li>
<li>Then we “fit” the network to the data, which carries out the minimization. </li>
<li>The number of iterations to fit the data is given with the ‘epochs’ keyword—generally more is better.</li>
</ol>
<h2 id="Risk-Management-in-Python"><a href="#Risk-Management-in-Python" class="headerlink" title="Risk Management in Python"></a>Risk Management in Python</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/48.%20Risk%20Management%20in%20Python.png" alt><br>To use the network we can give it ‘new_asset_prices’ it has never seen before!<br>The network evaluates the new asset prices using the <strong>‘.predict()’</strong> method, and _returns a set of portfolio weights_. </p>
<p>Over time, of course, new asset prices will accumulate, and they provide valuable information. Re-training the network every so often on new data, and backtesting it on old data, is part of the neural network workflow.</p>
<h2 id="Exercises-2"><a href="#Exercises-2" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="Single-layer-neural-networks"><a href="#Single-layer-neural-networks" class="headerlink" title="Single layer neural networks"></a>Single layer neural networks</h3><ul>
<li>Create the output training values using Numpy’s <code>sqrt()</code> function.</li>
<li>Create the neural network with one hidden layer of 16 neurons, one input value, and one output value.</li>
<li>Compile and fit the neural network on the training values, for 100 epochs</li>
<li>Plot the training values (in blue) against the neural network’s predicted values.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the training values from the square root function</span></span><br><span class="line">y = np.sqrt(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the neural network</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">16</span>, input_dim=<span class="number">1</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the network</span></span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'rmsprop'</span>)</span><br><span class="line">model.fit(x, y, epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Plot the resulting approximation and the training values</span></span><br><span class="line">plt.plot(x, y, x, model.predict(x))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/49.%20Single%20Layer%20neural%20networks.svg" alt></p>
<h3 id="Asset-price-prediction"><a href="#Asset-price-prediction" class="headerlink" title="Asset price prediction"></a>Asset price prediction</h3><p>Now we can use a neural network to predict an asset price, which is a large component of quantitative financial analysis as well as risk management.</p>
<ul>
<li>Set the input data to be all bank <code>prices</code> except Morgan Stanley, and the output data to be only Morgan Stanley’s <code>prices</code>.</li>
<li>Create a <code>Sequential</code> neural network <code>model</code> with two <code>Dense</code> hidden layers: the first with 16 neurons (and three input neurons), and the second with 8 neurons.</li>
<li>Add a single Dense output layer of 1 neuron to represent Morgan Stanley’s price.</li>
<li>Compile the neural network, and train it by fitting the <code>model</code>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Set the input and output data</span></span><br><span class="line">training_input = prices.drop(<span class="string">'Morgan Stanley'</span>, axis=<span class="number">1</span>)</span><br><span class="line">training_output = prices[<span class="string">'Morgan Stanley'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create and train the neural network with two hidden layers</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">16</span>, input_dim=<span class="number">3</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.add(Dense(<span class="number">8</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_logarithmic_error'</span>, optimizer=<span class="string">'rmsprop'</span>)</span><br><span class="line">model.fit(training_input, training_output, epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatter plot of the resulting model prediction</span></span><br><span class="line">axis.scatter(training_output, model.predict(training_input)); plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/50.%20Asset%20price%20prediction.svg" alt></p>
<h2 id="Real-time-risk-management"><a href="#Real-time-risk-management" class="headerlink" title="Real-time risk management"></a>Real-time risk management</h2><p>A 14-day rolling window of asset returns provides enough data to create a time series of <em>minimum volatility portfolios</em> using Modern Portfolio Theory, as we saw in Chapter 2. These <code>minimum_vol</code> portfolio weights are the training values for a neural network. This is a (1497 x 4) matrix.</p>
<p>The input is the matrix of weekly <code>average_asset_returns</code>, corresponding to each efficient portfolio. This is a (1497 x 4) matrix.</p>
<p>Create a Sequential neural network with the proper input dimension and two hidden layers. Training this network would take too long, so you’ll use an available <code>pre_trained_model</code> of identical type to predict portfolio weights for a new asset price vector.</p>
<ul>
<li>Create a Sequential neural network with two hidden layers, one input layer and one output layer.</li>
<li>Use the <code>pre_trained_model</code> to predict what the minimum volatility portfolio would be, when new asset data <code>asset_returns</code> is presented.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create neural network model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">128</span>, input_dim = <span class="number">4</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">4</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the pre-trained model to predict portfolio weights given new asset returns</span></span><br><span class="line">asset_returns = np.array([<span class="number">0.001060</span>, <span class="number">0.003832</span>, <span class="number">0.000726</span>, <span class="number">-0.002787</span>])</span><br><span class="line">asset_returns.shape = (<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">print(<span class="string">"Predicted minimum volatility portfolio: "</span>, pre_trained_model.predict(asset_returns))</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Predicted minimum volatility portfolio:  [[0.         0.28107247 0.         0.7649856 ]]</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Quantative Risk Management 3/4 Estimating and identifying risk</title>
    <url>/2021/01/09/Quantative-Risk-Management-3-4-Estimating-and-identifying-risk/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>3/4 objectives:</p>
<ol>
<li>estimate risk measures using parametric estimation and historical real-world data. </li>
<li>discover how Monte Carlo simulation can help you predict uncertainty. </li>
<li>learn how the global financial crisis signaled that randomness itself was changing, by understanding structural breaks and how to identify them.</li>
</ol>
<a id="more"></a>
<h1 id="Parameter-Estimation"><a href="#Parameter-Estimation" class="headerlink" title="Parameter Estimation"></a>Parameter Estimation</h1><h2 id="A-class-of-distribution"><a href="#A-class-of-distribution" class="headerlink" title="A class of distribution"></a>A class of distribution</h2><p>theta: the vector of unknown <strong>parameters</strong><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/15.%20A%20class%20of%20distributions.png" alt="A class of distribution"></p>
<h2 id="Fitting-a-distribution"><a href="#Fitting-a-distribution" class="headerlink" title="Fitting a distribution"></a>Fitting a distribution</h2><p>Fit distribution according to error-minimizing criteria</p>
<ul>
<li>Example: <code>scipy.stats.norm.fit()</code>, fitting Normal distribution to data</li>
<li>Result: optimally fitted mean and standard deviation</li>
</ul>
<p>Advantages:</p>
<ul>
<li>Visualize difference between data and estimate using histogram</li>
<li>Provide goodness-of-fit test</li>
</ul>
<h2 id="Goodness-of-fit"><a href="#Goodness-of-fit" class="headerlink" title="Goodness of fit"></a>Goodness of fit</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/16.%20Goodness%20of%20fit%20example.png" alt="Goodness of fit Example"></p>
<p>norm: too wild<br>t: good, taller’ and ‘narrower’. </p>
<p>This means that the degrees of freedom of the T distribution, which is the number of independent observations, is estimated to be low. </p>
<p>Although the T distribution provides a good fit, the data is still not quite right. In particular, the histogram is not symmetrical: it’s a bit lopsided. </p>
<h2 id="Skewness-（偏度-偏态、偏态系数）"><a href="#Skewness-（偏度-偏态、偏态系数）" class="headerlink" title="Skewness （偏度/偏态、偏态系数）"></a>Skewness （偏度/偏态、偏态系数）</h2><p>Skewness: degree to which data is non-symmetrically distributed<br>是统计数据分布非对称程度的数字特征</p>
<p>We can test for skewness in the data by seeing how far data are from being symmetric. In Python we test for skewness using ‘skewtest’ from ‘scipy.stats’. The null hypothesis is that there is no skewness, indicating that a symmetric distribution is appropriate. After importing the test, it is applied to the loss data. The results indicate both the test statistic value and its significance level. In our example, a test statistic of -7.78 has a more than 99.9% confidence level, showing that the data has statistically significant skewness. Parametric estimation using a Skewed Normal distribution might then be appropriate.</p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/17.%20Testing%20skewness.png" alt="Skewness"></p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="Parameter-estimation-Normal"><a href="#Parameter-estimation-Normal" class="headerlink" title="Parameter estimation: Normal"></a>Parameter estimation: Normal</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the Normal distribution and skewness test from scipy.stats</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm, anderson</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit portfolio losses to the Normal distribution</span></span><br><span class="line">params = norm.fit(losses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the 95% VaR from the fitted distribution, using parameter estimates</span></span><br><span class="line">VaR_95 = norm.ppf(<span class="number">0.95</span>, *params)</span><br><span class="line">print(<span class="string">"VaR_95, Normal distribution: "</span>, VaR_95)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the data for Normality</span></span><br><span class="line">print(<span class="string">"Anderson-Darling test result: "</span>, anderson(losses))</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VaR_95, Normal distribution:  0.07376954007991526</span><br><span class="line">Anderson-Darling test result:  AndersonResult(statistic=30.302775165424237, critical_values=array([0.573, 0.653, 0.783, 0.913, 1.086]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]))</span><br></pre></td></tr></table></figure></p>
<h3 id="Parameter-estimation-Skewed-Normal"><a href="#Parameter-estimation-Skewed-Normal" class="headerlink" title="Parameter estimation: Skewed Normal"></a>Parameter estimation: Skewed Normal</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the skew-normal distribution and skewness test from scipy.stats</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> skewnorm, skewtest</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the data for skewness</span></span><br><span class="line">print(<span class="string">"Skewtest result: "</span>, skewtest(losses))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the portfolio loss data to the skew-normal distribution</span></span><br><span class="line">params = skewnorm.fit(losses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the 95% VaR from the fitted distribution, using parameter estimates</span></span><br><span class="line">VaR_95 = skewnorm.ppf(<span class="number">0.95</span>, *params)</span><br><span class="line">print(<span class="string">"VaR_95 from skew-normal: "</span>, VaR_95)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Skewtest result:  SkewtestResult(statistic=-12.561846503056646, pvalue=3.4225103594408506e-36)</span><br><span class="line">VaR_95 from skew-normal:  0.06759217691716421</span><br></pre></td></tr></table></figure></p>
<h1 id="Historical-and-Monte-Carlo-Simulation"><a href="#Historical-and-Monte-Carlo-Simulation" class="headerlink" title="Historical and Monte Carlo Simulation"></a>Historical and Monte Carlo Simulation</h1><h2 id="Historical-simulation-in-Python"><a href="#Historical-simulation-in-Python" class="headerlink" title="Historical simulation in Python"></a>Historical simulation in Python</h2><p>Historical simulation: use past to predict future</p>
<p>VaR: start with returns in assets_returns<br>Compute <code>portfolio_returns</code> using portforlio <code>weights</code><br>Convert <code>portfolio_returns</code> into losses<br>VaR: compute <code>np.quantile()</code> for losses at a confidence level<br>Assume future distribution of losses is exactly the same as past (which may not be true)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights = [<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>]</span><br><span class="line">portfolio_returns = assets_returns.dot(weights)</span><br><span class="line">losses = -portfolio_returns</span><br><span class="line">VaR_95 = np.quantaile(losses, <span class="number">0.95</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Monte-Carlo-Simulation-in-Python"><a href="#Monte-Carlo-Simulation-in-Python" class="headerlink" title="Monte Carlo Simulation in Python"></a>Monte Carlo Simulation in Python</h2><p><strong>Monte Carlo Simulation: A powerful combination of parametric estimation and historical simulation</strong><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/18.%20Monte%20Carlo%20Simulation%20step1.png" alt="step1"><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/19.%20Monte%20Carlo%20Simulation%20step2.png" alt="step2"><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/20.%20Monte%20Carlo%20Simulation%20step3.png" alt="step3"></p>
<h2 id="Simulating-asset-returns"><a href="#Simulating-asset-returns" class="headerlink" title="Simulating asset returns"></a>Simulating asset returns</h2><p>A more thorough (and common) approach is to <strong>simulate the returns</strong> for the individual assets in a portfolio, rather than just the portfolio’s total return.<br>This allows greater realism as each risk factor can contribute their own sample path.<br>In addition, risk factors can be <strong>correlated:</strong> the covariance matrix <code>e_cov</code> can be used to compute asset returns in the simulation procedure.</p>
<h2 id="Exercises-1"><a href="#Exercises-1" class="headerlink" title="Exercises"></a>Exercises</h2><h2 id="Historical-simulation"><a href="#Historical-simulation" class="headerlink" title="Historical simulation"></a>Historical simulation</h2><p>Historical simulation of VaR assumes that the distribution of historical losses is the same as the distribution of future losses. We’ll test if this is true for our investment bank portfolio by comparing the 95% VaR from 2005 - 2006 to the 95% VaR from 2007 - 2009.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create portfolio returns for the two sub-periods using the list of asset returns</span></span><br><span class="line">portfolio_returns = np.array([x.dot(weights) <span class="keyword">for</span> x <span class="keyword">in</span> asset_returns])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Derive portfolio losses from portfolio returns</span></span><br><span class="line">losses = - portfolio_returns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the historical simulated VaR estimates</span></span><br><span class="line">VaR_95 = [np.quantile(x, <span class="number">0.95</span>) <span class="keyword">for</span> x <span class="keyword">in</span> losses]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the VaR estimates</span></span><br><span class="line">print(<span class="string">"VaR_95, 2005-2006: "</span>, VaR_95[<span class="number">0</span>], <span class="string">'; VaR_95, 2007-2009: '</span>, VaR_95[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VaR_95, 2005-2006:  0.014687184472834514 ; VaR_95, 2007-2009:  0.05790574066814192</span><br></pre></td></tr></table></figure></p>
<h3 id="Monte-Carlo-Simulation"><a href="#Monte-Carlo-Simulation" class="headerlink" title="Monte Carlo Simulation"></a>Monte Carlo Simulation</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Initialize daily cumulative loss for the assets, across N runs</span></span><br><span class="line">daily_loss = np.zeros((<span class="number">4</span>,N))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the Monte Carlo simulations for N runs</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(N):</span><br><span class="line">    <span class="comment"># Compute simulated path of length total_steps for correlated returns</span></span><br><span class="line">    correlated_randomness = e_cov @ norm.rvs(size = (<span class="number">4</span>,total_steps))</span><br><span class="line">    <span class="comment"># Adjust simulated path by total_steps and mean of portfolio losses</span></span><br><span class="line">    steps = <span class="number">1</span>/total_steps</span><br><span class="line">    minute_losses = mu * steps + correlated_randomness * np.sqrt(steps)</span><br><span class="line">    daily_loss[:, n] = minute_losses.sum(axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Generate the 95% VaR estimate</span></span><br><span class="line">losses = weights @ daily_loss</span><br><span class="line">print(<span class="string">"Monte Carlo VaR_95 estimate: "</span>, np.quantile(losses, <span class="number">0.95</span>))</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Monte Carlo VaR_95 estimate:  0.0032448493079297045</span><br></pre></td></tr></table></figure></p>
<h1 id="Structural-breaks"><a href="#Structural-breaks" class="headerlink" title="Structural breaks"></a>Structural breaks</h1><p>在计量经济学和统计学中，结构性折断是回归模型参数随时间的意外变化，通常会导致巨大的预测误差和模型的不可靠性。</p>
<h2 id="Risk-and-distribution"><a href="#Risk-and-distribution" class="headerlink" title="Risk and distribution"></a>Risk and distribution</h2><p>Risk management toolkit:</p>
<ul>
<li>Risk mitigation: MPT</li>
<li>Risk measurement: VaR, CVaR</li>
</ul>
<p>Risk: dispersion, volatility</p>
<ul>
<li>Variance (standard deviation) as risk definition</li>
</ul>
<p>Connection bewteen _risk_ and _<strong>distribution</strong> of risk factors_ as random variables</p>
<h2 id="Stationarty-平稳性"><a href="#Stationarty-平稳性" class="headerlink" title="Stationarty (平稳性)"></a>Stationarty (平稳性)</h2><p>Assumption: distribution is the same over time<br>Unchanging distribution = stationary<br>Global financial crisis period efficient frontier —&gt; not stationary</p>
<p>Estimation techniques require <strong>stationarity</strong>:</p>
<ul>
<li>Historical: unknown stationary distribution from past data</li>
<li>Parametric: assumed stationary distribution class</li>
<li>Monte Carlo: assumed stationary distribution for random draws</li>
</ul>
<h2 id="Structural-breaks-1"><a href="#Structural-breaks-1" class="headerlink" title="Structural breaks"></a>Structural breaks</h2><p>If we knew that the distribution was changing over time, and we knew when distribution changes occur, then we could estimate our risk measures only during <strong>sub-periods</strong> when the distribution didn’t change.<br>In other words, distributions would be <strong>stationary only within certain sub-periods of the data</strong>. </p>
<p>Structural breaks: points of change<br>— change in “trend” of average and/or volatility of data</p>
<h2 id="Example-China’s-population-growth"><a href="#Example-China’s-population-growth" class="headerlink" title="Example: China’s population growth"></a>Example: China’s population growth</h2><p>As an example of a structural break, let’s examine the population growth rate of China from 1950 to 2019. We can see that the growth is relatively linear over this period…</p>
<p>…but around 1990 the growth rate slows down. This indicates that there may be a structural break around 1990. </p>
<p>In other words, the underlying distribution of net population gains (births minus deaths) changed, causing there to be fewer net gains from 1990 onwards. Some reasons for such a change could be changes in government policy, changes in living standards, and other micro- and macro-level factors.</p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/21.%20China%20population.png" alt="China Population"></p>
<h2 id="The-Chow-test"><a href="#The-Chow-test" class="headerlink" title="The Chow test"></a>The Chow test</h2><p>Previous example: A visual examination is useful to identify structural breaks.<br>the “Chow Test”: statistical measurement, which asks if the data support a <strong>structural break</strong> at a given break point of time, for a given <strong>linear risk factor model</strong>. </p>
<p>Null hypothesis: no structural break. </p>
<p>In the test, 3 ordinary least squares (OLS) regressions are performed: </p>
<ol>
<li>one for the entire period,</li>
<li>two for before and after the break point.<br>The sum-of-squared residuals are then collected, and the Chow test statistic is created. The statistic is distributed as an “F”-distribution statistic.</li>
</ol>
<h2 id="The-Chow-test-in-Python"><a href="#The-Chow-test-in-Python" class="headerlink" title="The Chow test in Python"></a>The Chow test in Python</h2><p>Let’s use the Chow test to see if there was a structural break somewhere around 1990 in China’s population growth. We’ll use a very simple <strong>“factor model”</strong> where log-population is regressed against year. </p>
<h3 id="Step1-OLS-regression-of-the-whole-period"><a href="#Step1-OLS-regression-of-the-whole-period" class="headerlink" title="Step1: OLS regression of the whole period"></a>Step1: OLS regression of the whole period</h3><p>An OLS regression over the 1950 - 2019 period, regressing the natural logarithm of population against year and an intercept. This gives our ‘baseline’ regression, <strong>assuming no structural break</strong>. The _sum-of-squared residuals（残差平方和）_ from the regression are stored.<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/22.%20The%20Chow%20test1.png" alt></p>
<h3 id="Step2-Two-OLS-regression-of-two-sub-period"><a href="#Step2-Two-OLS-regression-of-two-sub-period" class="headerlink" title="Step2: Two OLS regression of two sub-period"></a>Step2: Two OLS regression of two sub-period</h3><p>Break 1950-2019 into <strong>1950-1989</strong> and <strong>1990-2019</strong> sub-periods and perform OLS regression on each sub period<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/23.%20The%20Chow%20test2.png" alt><br>*ssr: Sum of squared (whitened) residuals. 残差平方和：它被用作参数选择和模型选择的最优准则。</p>
<h3 id="Step3-Compute-the-Chow-test-statistic"><a href="#Step3-Compute-the-Chow-test-statistic" class="headerlink" title="Step3: Compute the Chow test statistic"></a>Step3: Compute the Chow test statistic</h3><p>Finally, we compute the Chow test statistic using the three sum of squared residuals and the degrees of freedom of the test. The Chow test statistic should be distributed as an “F” distribution. The “F” distribution has <strong>two degrees of freedom</strong>: </p>
<ul>
<li>The first (used in the numerator) is the number of regression parameters, here equal to 2: the intercept and slope coefficient. </li>
<li>The second (used in the denominator), is the total number of data points, 70, minus twice the first degree of freedom, or 70 minus 4, which is 66.<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/24.%20The%20Chow%20test3.png" alt></li>
</ul>
<p>The computed test statistic is statistically different from zero at the 99.9% confidence level. We can reject the null hypothesis that there was no structural break in the data.</p>
<h2 id="Exercises-2"><a href="#Exercises-2" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="Crisis-structural-break-I"><a href="#Crisis-structural-break-I" class="headerlink" title="Crisis structural break I"></a>Crisis structural break I</h3><p>Step 1: Investigate whether something “structural” changed between 2005 and 2010.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a plot of quarterly minimum portfolio returns</span></span><br><span class="line">plt.plot(port_q_min, label=<span class="string">"Quarterly minimum return"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a plot of quarterly mean volatility</span></span><br><span class="line">plt.plot(vol_q_mean, label=<span class="string">"Quarterly mean volatility"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create legend and plot</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/25.%20Crisis%20structural%20break1.svg" alt></p>
<h3 id="Crisis-structural-break-II"><a href="#Crisis-structural-break-II" class="headerlink" title="Crisis structural break II"></a>Crisis structural break II</h3><p>Step 2: Use the richer factor model relationship between portfolio returns and mortgage delinquencies from Chapter 1 to <strong>test for a structural break around 2008</strong>, by computing the <strong>Chow test statistic</strong> for the factor model.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the statsmodels API to be able to run regressions</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a constant to the regression</span></span><br><span class="line">mort_del = sm.add_constant(mort_del)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Regress quarterly minimum portfolio returns against mortgage delinquencies</span></span><br><span class="line">result = sm.OLS(port_q_min, mort_del).fit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieve the sum-of-squared residuals</span></span><br><span class="line">ssr_total = result.ssr</span><br><span class="line">print(<span class="string">"Sum-of-squared residuals, 2005-2010: "</span>, ssr_total)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sum-of-squared residuals, 2005-2010:  0.05039331102490134</span><br></pre></td></tr></table></figure></p>
<h3 id="Crisis-structural-break-III"><a href="#Crisis-structural-break-III" class="headerlink" title="Crisis structural break III"></a>Crisis structural break III</h3><p>Step 3: put everything together to perform the Chow test.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Add intercept constants to each sub-period 'before' and 'after'</span></span><br><span class="line">before_with_intercept = sm.add_constant(before[<span class="string">'mort_del'</span>])</span><br><span class="line">after_with_intercept  = sm.add_constant(after[<span class="string">'mort_del'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit OLS regressions to each sub-period</span></span><br><span class="line">r_b = sm.OLS(before[<span class="string">'returns'</span>], before_with_intercept).fit()</span><br><span class="line">r_a = sm.OLS(after[<span class="string">'returns'</span>],  after_with_intercept).fit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get sum-of-squared residuals for both regressions</span></span><br><span class="line">ssr_before = r_b.ssr</span><br><span class="line">ssr_after = r_a.ssr</span><br><span class="line"><span class="comment"># Compute and display the Chow test statistic</span></span><br><span class="line">numerator = ((ssr_total - (ssr_before + ssr_after)) / <span class="number">2</span>)</span><br><span class="line">denominator = ((ssr_before + ssr_after) / (<span class="number">24</span> - <span class="number">4</span>))</span><br><span class="line">print(<span class="string">"Chow test statistic: "</span>, numerator / denominator)</span><br></pre></td></tr></table></figure></p>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Chow test statistic:  28.93147360547482</span><br></pre></td></tr></table></figure></p>
<h1 id="Volatility-and-extreme-values"><a href="#Volatility-and-extreme-values" class="headerlink" title="Volatility and extreme values"></a>Volatility and extreme values</h1><h2 id="Structural-break-indications"><a href="#Structural-break-indications" class="headerlink" title="Structural break indications"></a>Structural break indications</h2><ul>
<li>Visualization of <strong>trend</strong> may not indicate break point</li>
<li>Alternatively: examine <strong>volatility</strong> rather than trend</li>
</ul>
<h2 id="1-Rolling-window-volatility"><a href="#1-Rolling-window-volatility" class="headerlink" title="1. Rolling window volatility"></a>1. Rolling window volatility</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/26.%20Rolling%20window%20volatility.png" alt><br>We can see <strong>if volatility is non-stationary</strong> by constructing a rolling window of losses (or returns) and computing the volatility for each window.<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/27.%20Rolling%20window%20volatility1.png" alt><br>Plotting the resulting volatility series can help identify dates where the volatility appeared to change significantly. These can then be used with the Chow Test to see if one or more structural breaks is supported by the data.<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/28.%20Rolling%20window%20volatility2.png" alt><br>It is sometimes also helpful to visualize changes in volatility, rather than volatility itself. This provides, in addition to possible structural break points, useful information about how the variance has changed over time. </p>
<h2 id="2-Extreme-values"><a href="#2-Extreme-values" class="headerlink" title="2. Extreme values"></a>2. Extreme values</h2><p>VaR, CVaR: maximum loss, expected shortfall at particular confidence level</p>
<p>Visualizing changes in maximum loss by plotting VaR?</p>
<ul>
<li>Useful for large data sets</li>
<li>Small data sets: not enough information</li>
</ul>
<p>Alternative: find losses exceding some threshold （阀值）<br>Example：VaR95 is the maximum loss in 95% of the time —&gt; 5% of the time, losses can be expected to exceed VaR_95</p>
<p>Backtesting: use previous data ex-post to see how risk estimate performs<br>—- Used extensively in enterprise risk management</p>
<h2 id="Backtesting-回测"><a href="#Backtesting-回测" class="headerlink" title="Backtesting (回测)"></a>Backtesting (回测)</h2><p>CVaR for backtesting: accounts for tail better than VaR</p>
<ul>
<li>尾端风险/极端风险（Tail Risk）是指统计学上两个极端值可能出现的风险</li>
<li>肥尾效应（Fat tail）是指极端行情发生的机率增加，可能因为发生一些不寻常的事件<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/29.%20Backtesting.png" alt></li>
</ul>
<h2 id="Exercises-3"><a href="#Exercises-3" class="headerlink" title="Exercises:"></a>Exercises:</h2><h3 id="Volatility-and-structural-breaks"><a href="#Volatility-and-structural-breaks" class="headerlink" title="Volatility and structural breaks"></a>Volatility and structural breaks</h3><p>Visualizing volatility changes helps reveal possible structural break points in time series.<br>By identifying when volatility appears to change, an informed choice of break point can be made that can, in turn, be used for further statistical analysis (such as the Chow test).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Find the time series of returns with and without Citibank</span></span><br><span class="line">ret_with_citi = prices_with_citi.pct_change().dot(weights_with_citi)</span><br><span class="line">ret_without_citi = prices_without_citi.pct_change().dot(weights_without_citi)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the average 30-day rolling window volatility as the standard deviation</span></span><br><span class="line">vol_with_citi = ret_with_citi.rolling(<span class="number">30</span>).std().dropna().rename(<span class="string">"With Citi"</span>)</span><br><span class="line">vol_without_citi = ret_without_citi.rolling(<span class="number">30</span>).std().dropna().rename(<span class="string">"Without Citi"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Combine two volatilities into one Pandas DataFrame</span></span><br><span class="line">vol = pd.concat([vol_with_citi, vol_without_citi], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot volatilities over time</span></span><br><span class="line">vol.plot().set_ylabel(<span class="string">"Losses"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/30.%20Volatility%20and%20structural%20breaks.svg" alt></p>
<h2 id="Extreme-values-and-backtesting"><a href="#Extreme-values-and-backtesting" class="headerlink" title="Extreme values and backtesting"></a>Extreme values and backtesting</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute the 95% VaR on 2009-2010 losses</span></span><br><span class="line">VaR_95 = np.quantile(estimate_data, <span class="number">0.95</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find backtest_data exceeding the 95% VaR</span></span><br><span class="line">extreme_values = backtest_data[backtest_data &gt; VaR_95]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compare the fraction of extreme values for 2007-2008 to the Var_95 estimate</span></span><br><span class="line">print(<span class="string">"VaR_95: "</span>, VaR_95, <span class="string">"; Backtest: "</span>, len(extreme_values) / len(backtest_data) )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the extreme values and look for clustering</span></span><br><span class="line">plt.stem(extreme_values.index, extreme_values.values)</span><br><span class="line">plt.ylabel(<span class="string">"Extreme values &gt; VaR_95"</span>); plt.xlabel(<span class="string">"Date"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/31.%20Extreme%20values%20and%20backtesting.svg" alt></p>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VaR_95:  0.04986983664383684 ; Backtest:  0.06547619047619048</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Quantative Risk Management 2/4 - Goal-oriented risk management</title>
    <url>/2021/01/09/Quantative-Risk-Management-2-4-Goal-oriented-risk-management/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>2/4 Object:</strong></p>
<ol>
<li>expand your portfolio optimization toolkit with risk measures such as Value at Risk (VaR) and Conditional Value at Risk (CVaR)</li>
<li>use specialized Python libraries including pandas, scipy, and pypfopt. </li>
<li>how to mitigate risk exposure using the Black-Scholes model to hedge an options portfolio.</li>
</ol>
<a id="more"></a>
<h1 id="Measuring-Risk"><a href="#Measuring-Risk" class="headerlink" title="Measuring Risk"></a>Measuring Risk</h1><h2 id="The-Loss-Distribution"><a href="#The-Loss-Distribution" class="headerlink" title="The Loss Distribution"></a>The Loss Distribution</h2><p>Forex example:<br>EUR and USD (exchange rate is r)<br>r EUR = 1 USD<br>Loss = EUR 100 x (1-r)<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/7.%20Loss%20Distribution.png" alt="Loss Distribution"></p>
<p>random realization of <strong>r</strong> =&gt; <strong>distribution</strong> of portfolio losses in the future</p>
<h2 id="Maximum-loss"><a href="#Maximum-loss" class="headerlink" title="Maximum loss"></a>Maximum loss</h2><p>What’s the max loss of a portforlio?<br>Losses cannot be bounded with 100% certainty<br>Confidence level: replace 100% certainty with likelyhood of upper bound<br>Can express questions like “what’s the maximum loss that would take place 95% of the time?”</p>
<ul>
<li>here the confidence level is 95%</li>
</ul>
<h2 id="Value-at-risk-VaR"><a href="#Value-at-risk-VaR" class="headerlink" title="Value at risk (VaR)"></a>Value at risk (VaR)</h2><p><strong>VaR</strong>（风险价值）: statistic measuring maximum portfolio loss at a particular confidence level </p>
<p>某一置信度下的最大损失</p>
<p>Typical confidence levels: 95%, 99%, and 99.5% (usually represented as decimals)</p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/7.%20VaR.png" alt="VaR"><br>Forex example: </p>
<h2 id="Conditional-Value-at-Risk-CVaR"><a href="#Conditional-Value-at-Risk-CVaR" class="headerlink" title="Conditional Value at Risk (CVaR)"></a>Conditional Value at Risk (CVaR)</h2><p><strong>CVaR</strong>（条件风险价值）: measures expected loss given a minimum loss equal to the VaR. It equals expected value of the tail of the loss distribution </p>
<p>VaR的一个问题是他不考虑超过该置信度后的损失情况, 而CVaR表示投资组合的损失超过某个给定VaR值的条件下，该投资组合的平均损失值。</p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/8.%20CVaR.png" alt="CVaR"></p>
<h2 id="Deriving-the-VaR"><a href="#Deriving-the-VaR" class="headerlink" title="Deriving the VaR"></a>Deriving the VaR</h2><ol>
<li>Specify the confidence level (e.g. 95%, 0.95)</li>
<li>Creat a Series of <code>loss</code> observations </li>
<li>Compute <code>loss.quantile()</code> at specified confidence level</li>
<li>VaR = computed <code>.quantile()</code> at desired confidence level</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = pd.Series(observations)</span><br><span class="line">VaR = loss.quantile(<span class="number">0.95</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"VaR_95= "</span>, VaR_95)</span><br></pre></td></tr></table></figure>
<p>If we know losses are distributed according to a statistical distribution like the Normal distribution, we can also use the “.ppf()”, or percent point function, to find the VaR.</p>
<p>—&gt; <code>scipy.stats</code> loss distribution: percent point function <code>.ppf()</code> can also be used.</p>
<h2 id="Deriving-the-CVaR"><a href="#Deriving-the-CVaR" class="headerlink" title="Deriving the CVaR"></a>Deriving the CVaR</h2><ol>
<li>Specify the confidence level (e.g. 95%, 0.95)</li>
<li>Creat or use sample from loss distribution</li>
<li>Compute VaR at a specified confidence level</li>
<li>Compute CVaR as expected loss (Normal distribution: <code>scipy.stats.norm.expected()</code> does this)</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">losses = pd.Series(scipy.stats.norm.rvs(size = <span class="number">1000</span>)</span><br><span class="line">VaR = scipy.stats.norm.ppf(<span class="number">0</span>,<span class="number">95</span>)</span><br><span class="line">CVaR = (<span class="number">1</span>/(<span class="number">1</span><span class="number">-0.95</span>))*scipy.stats.norm.expect(<span class="keyword">lambda</span> x: x, lb = VaR_95)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"CVaR= "</span>, CVaR)</span><br></pre></td></tr></table></figure>
<h2 id="Visulizing-the-VaR"><a href="#Visulizing-the-VaR" class="headerlink" title="Visulizing the VaR"></a>Visulizing the VaR</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/9.%20Visualizing%20VaR.png" alt="Visulizing the VaR"><br>*N(mean, variance) stands for normal distribution </p>
<h2 id="Excercises"><a href="#Excercises" class="headerlink" title="Excercises"></a>Excercises</h2><h3 id="VaR-for-the-Normal-distribution"><a href="#VaR-for-the-Normal-distribution" class="headerlink" title="VaR for the Normal distribution"></a>VaR for the Normal distribution</h3><p>To get accustomed to the Value at Risk (VaR) measure, it helps to apply it to a known distribution. The Normal (or Gaussian) distribution is especially appealing as it 1) has an analytically simple form, and 2) represents a wide variety of empirical phenomena. For this exercise you’ll assume that the loss of a portfolio is normally distributed, i.e., the higher the value drawn from the distribution, the higher the loss.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the VaR measure at the 95% confidence level using norm.ppf()</span></span><br><span class="line">VaR_95 = norm.ppf(<span class="number">0.95</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the VaR meaasure at the 5% significance level using numpy.quantile()</span></span><br><span class="line">draws = norm.rvs(size = <span class="number">100000</span>)</span><br><span class="line">VaR_99 = np.quantile(draws, <span class="number">0.99</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compare the 95% and 99% VaR</span></span><br><span class="line">print(<span class="string">"95% VaR: "</span>, VaR_95, <span class="string">"; 99% VaR: "</span>, VaR_99)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the normal distribution histogram and 95% VaR measure</span></span><br><span class="line">plt.hist(draws, bins = <span class="number">100</span>)</span><br><span class="line">plt.axvline(x = VaR_95, c=<span class="string">'r'</span>, label = <span class="string">"VaR at 95% Confidence Level"</span>)</span><br><span class="line">plt.legend(); plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/10.%20VaR%20for%20the%20Normal%20Distribution.svg" alt="VaR for the Normal Dirstribution"></p>
<h3 id="Comparing-CVaR-and-VaR"><a href="#Comparing-CVaR-and-VaR" class="headerlink" title="Comparing CVaR and VaR"></a>Comparing CVaR and VaR</h3><p>The <strong>conditional value at risk</strong> (CVaR), or expected shortfall (ES), asks what the average loss will be, conditional upon losses exceeding some threshold at a certain confidence level. It uses VaR as a point of departure, but contains more information because it takes into consideration the tail of the loss distribution.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute the mean and variance of the portfolio returns</span></span><br><span class="line">pm = portfolio_losses.mean()</span><br><span class="line">ps = portfolio_losses.std()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the 95% VaR using the .ppf()</span></span><br><span class="line">VaR_95 = norm.ppf(<span class="number">0.95</span>, loc = pm, scale = ps)</span><br><span class="line"><span class="comment"># Compute the expected tail loss and the CVaR in the worst 5% of cases</span></span><br><span class="line">tail_loss = norm.expect(<span class="keyword">lambda</span> x: x, loc = pm, scale = ps, lb = VaR_95)</span><br><span class="line">CVaR_95 = (<span class="number">1</span> / (<span class="number">1</span> - <span class="number">0.95</span>)) * tail_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the normal distribution histogram and add lines for the VaR and CVaR</span></span><br><span class="line">plt.hist(norm.rvs(size = <span class="number">100000</span>, loc = pm, scale = ps), bins = <span class="number">100</span>)</span><br><span class="line">plt.axvline(x = VaR_95, c=<span class="string">'r'</span>, label = <span class="string">"VaR, 95% confidence level"</span>)</span><br><span class="line">plt.axvline(x = CVaR_95, c=<span class="string">'g'</span>, label = <span class="string">"CVaR, worst 5% of outcomes"</span>)</span><br><span class="line">plt.legend(); plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/11.%20Comparing%20CVaR%20and%20VaR.svg" alt="Comparing CVaR and VaR"></p>
<h1 id="Risk-exposure-and-loss"><a href="#Risk-exposure-and-loss" class="headerlink" title="Risk exposure and loss"></a>Risk exposure and loss</h1><h2 id="Deciding-between-options"><a href="#Deciding-between-options" class="headerlink" title="Deciding between options"></a>Deciding between options</h2><ol>
<li>Chances of negaticve shock: <strong>probability of loss</strong></li>
<li>Loss associated with shock: amount or conditional amount (e.g. <strong>VaR, CVaR</strong>)</li>
<li>Desire to avoid shock: <strong>Risk tolerance</strong></li>
</ol>
<h2 id="Risk-exposure-and-VaR"><a href="#Risk-exposure-and-VaR" class="headerlink" title="Risk exposure and VaR"></a>Risk exposure and VaR</h2><p>Risk exposure = probability of loss x loss measure<br>Loss measure: e.g. VaR</p>
<p>loss distribution:<br>normal distribution: good for large number of samples<br>students’ t distribution: good for small number of samples</p>
<h2 id="Risk-appetite"><a href="#Risk-appetite" class="headerlink" title="Risk appetite"></a>Risk appetite</h2><ul>
<li>Insurance is a way to pay a fixed value to avoid an uncertain outcome, which is risk-averse behavior.</li>
</ul>
<p><strong>risk averse (or risk avoiding) </strong>- if they would accept a certain payment (certainty equivalent) of less than $50 (for example, $40), rather than taking the gamble and possibly receiving nothing.<br><strong>risk neutral</strong> – if they are indifferent between the bet and a certain $50 payment.</p>
<h2 id="degrees-of-freedom-df"><a href="#degrees-of-freedom-df" class="headerlink" title="degrees of freedom (df)"></a>degrees of freedom (df)</h2><p>number of independent observations</p>
<ul>
<li>Small df: “fat tailed” T distribution</li>
<li>Large df: Normal distribution</li>
</ul>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="VaR-and-risk-exposure"><a href="#VaR-and-risk-exposure" class="headerlink" title="VaR and risk exposure"></a>VaR and risk exposure</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the Student's t-distribution</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> t</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create rolling window parameter list</span></span><br><span class="line">mu = losses.rolling(<span class="number">30</span>).mean()</span><br><span class="line">sigma = losses.rolling(<span class="number">30</span>).std()</span><br><span class="line">rolling_parameters = [(<span class="number">29</span>, mu[i], s) <span class="keyword">for</span> i,s <span class="keyword">in</span> enumerate(sigma)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the 99% VaR array using the rolling window parameters</span></span><br><span class="line">VaR_99 = np.array( [ t.ppf(<span class="number">0.99</span>, *params) </span><br><span class="line">                    <span class="keyword">for</span> params <span class="keyword">in</span> rolling_parameters ] )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the minimum risk exposure over the 2005-2010 time period</span></span><br><span class="line">plt.plot(losses.index, <span class="number">0.01</span> * VaR_99 * <span class="number">100000</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/12.%20VaR%20and%20risk%20exposure.svg" alt="VaR and risk exposure"></p>
<h3 id="CVaR-and-risk-exposure"><a href="#CVaR-and-risk-exposure" class="headerlink" title="CVaR and risk exposure"></a>CVaR and risk exposure</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Fit the Student's t distribution to crisis losses</span></span><br><span class="line">p = t.fit(crisis_losses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the VaR_99 for the fitted distribution</span></span><br><span class="line">VaR_99 = t.ppf(<span class="number">0.99</span>, *p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the fitted parameters and VaR_99 to compute CVaR_99</span></span><br><span class="line">tail_loss = t.expect(<span class="keyword">lambda</span> y: y, args = (p[<span class="number">0</span>],), loc = p[<span class="number">1</span>], scale = p[<span class="number">2</span>], lb = VaR_99 )</span><br><span class="line">CVaR_99 = (<span class="number">1</span> / (<span class="number">1</span> - <span class="number">0.99</span>)) * tail_loss</span><br><span class="line">print(CVaR_99)</span><br></pre></td></tr></table></figure>
<p>结果为<code>0.3380538488604617</code></p>
<h1 id="Risk-management-with-VaR-and-CVaR"><a href="#Risk-management-with-VaR-and-CVaR" class="headerlink" title="Risk management with VaR and CVaR"></a>Risk management with VaR and CVaR</h1><h2 id="Incorporating-VaR-into-MPT"><a href="#Incorporating-VaR-into-MPT" class="headerlink" title="Incorporating VaR into MPT"></a>Incorporating VaR into MPT</h2><p>Mordern Portfolio Theory (MPT): “mean-variance” optimization</p>
<ul>
<li>Highest expected return</li>
<li>Risk level (volatility) is given</li>
<li>Objective function: expected return</li>
</ul>
<p>VaR/CVaR: measure risk over distribution of loss</p>
<p>Adapt MPT to optimize over loss distribution vs. expected return</p>
<h2 id="A-new-objective-minimize-CVaR"><a href="#A-new-objective-minimize-CVaR" class="headerlink" title="A new objective: minimize CVaR"></a>A new objective: minimize CVaR</h2><p>change objective of portfolio optimization</p>
<ul>
<li>mean-variance objective: maximize expected mean return</li>
<li>CVaR objective: minimize expected conditional loss at a given confidence level<br>—&gt; Optimization: portfolio weights minimizing CVaR<br>—&gt; find the lowest expected loss in worst (1-confidence) of possible outcomes<br>在给定的置信度下，可能出现的结果中，达到最低的损失</li>
</ul>
<h2 id="CVaR-minimization-using-PyPortfolioOpt"><a href="#CVaR-minimization-using-PyPortfolioOpt" class="headerlink" title="CVaR minimization using PyPortfolioOpt"></a>CVaR minimization using PyPortfolioOpt</h2><ol>
<li>Create an <code>EfficientFrontier</code> object with an efficient covariance matrix <code>e_cov</code></li>
<li>Import built-in objective function that minimizes CVaR, <code>negative_cvar()</code> from <code>pypopt.objective_functions</code> module</li>
<li>Comput optimal portfolio weights using <code>.custom_objective()</code> method<br>(Arguements of <code>.negative_cvar()</code> added to <code>.custom_objective</code>).</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ef = pypopt.objective_frontier.EfficientFrontier(<span class="literal">None</span>, e_cov)</span><br><span class="line"><span class="keyword">from</span> pypopt.objective_functions <span class="keyword">import</span> negative_cvar</span><br><span class="line">optimal_weights = ef.custom_objective(negative_cvar, returns)</span><br></pre></td></tr></table></figure>
<h2 id="Negative-CVaR"><a href="#Negative-CVaR" class="headerlink" title="Negative CVaR?"></a>Negative CVaR?</h2><p>Seek minimum CVaR portfolio at given significance level 1-alpha<br><strong>Same as</strong> finding portfolio that maximizes returns in worst 1-alpha cases</p>
<p>Question: expect objective function to return positive number, or negative?</p>
<p>Optimization can be either:</p>
<ul>
<li>maximize someting or </li>
<li>minimize the <strong>negative</strong> of someting</li>
</ul>
<p>PyPortfolioOpt solver: <strong>minimizes</strong> by default</p>
<ul>
<li>so objective function needs to be negative of CVaR <strong>returns</strong></li>
<li>Give same answer as minimizing CVaR <strong>losses</strong></li>
</ul>
<p>Term “negative CVaR” is a misnormer: CVaR is an expected <strong>loss </strong></p>
<h2 id="Mean-variance-vs-CVaR-risk-management"><a href="#Mean-variance-vs-CVaR-risk-management" class="headerlink" title="Mean-variance vs. CVaR risk management"></a>Mean-variance vs. CVaR risk management</h2><p>Mean-variance risk management: minimize <strong>volatility</strong> </p>
<ul>
<li>We compute the minimum volatility portfolio weights in the usual fashion, by creating an EfficientFrontier instance and using the ‘min volatility’ method.<br>CVaR risk management: minimize <strong>negative CVaR</strong></li>
<li>The CVaR-minimizing portfolio is created using the ‘custom objective’ and ‘negative cvar’ methods. The result is a roughly equally-weighted portfolio. </li>
<li>This creates more volatility than the minimum volatility mean-variance portfolio, but with the benefit that the worst 5% cases of loss are minimized.</li>
</ul>
<h2 id="Excercies"><a href="#Excercies" class="headerlink" title="Excercies"></a>Excercies</h2><h2 id="VaR-from-a-fitted-distribution"><a href="#VaR-from-a-fitted-distribution" class="headerlink" title="VaR from a fitted distribution"></a>VaR from a fitted distribution</h2><p>Minimizing CVaR requires calculating the VaR at a confidence level, say 95%. Previously you derived the VaR as a quantile from a Normal (or Gaussian) distribution, but minimizing the CVaR more generally requires computing the quantile from a distribution that best <strong>fits</strong> the data.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Visualize the fitted distribution with a plot</span></span><br><span class="line">x = np.linspace(<span class="number">-0.25</span>,<span class="number">0.25</span>,<span class="number">1000</span>)</span><br><span class="line">plt.plot(x,fitted.evaluate(x))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a random sample of 100,000 observations from the fitted distribution</span></span><br><span class="line">sample = fitted.resample(<span class="number">100000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute and display the 95% VaR from the random sample</span></span><br><span class="line">VaR_95 = np.quantile(sample, <span class="number">0.95</span>)</span><br><span class="line">print(VaR_95)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/13.%20VaR%20from%20a%20fitted%20distribution.svg" alt="VaR from a fitted distribution"></p>
<h3 id="Minimizing-CVaR"><a href="#Minimizing-CVaR" class="headerlink" title="Minimizing CVaR"></a>Minimizing CVaR</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the EfficientFrontier class</span></span><br><span class="line"><span class="keyword">from</span> pypfopt.efficient_frontier <span class="keyword">import</span> EfficientFrontier</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import the negative_cvar objective function</span></span><br><span class="line"><span class="keyword">from</span> pypfopt.objective_functions <span class="keyword">import</span> negative_cvar</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the efficient frontier instance</span></span><br><span class="line">ef = EfficientFrontier(<span class="literal">None</span>, e_cov)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the cVar-minimizing portfolio weights at the default 95% confidence level</span></span><br><span class="line">optimal_weights = ef.custom_objective(negative_cvar, returns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the optimal weights</span></span><br><span class="line">print(optimal_weights)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&apos;Citibank&apos;: 0.24991481239515553, &apos;Morgan Stanley&apos;: 0.2497894497565988, &apos;Goldman Sachs&apos;: 0.25013519444333526, &apos;J.P. Morgan&apos;: 0.2501605434049105&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="CVaR-risk-management-and-the-crisis"><a href="#CVaR-risk-management-and-the-crisis" class="headerlink" title="CVaR risk management and the crisis"></a>CVaR risk management and the crisis</h3><p>Derive the 95% CVaR-minimizing portfolio for 2005-2006, 2007-2008, and 2009-2010.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Initialize the dictionary of optimal weights</span></span><br><span class="line">optimal_weights_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find and display the CVaR-minimizing portfolio weights at the default 95% confidence level</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'before'</span>, <span class="string">'during'</span>, <span class="string">'after'</span>]:</span><br><span class="line">    optimal_weights_dict[x] = ef_dict[x].custom_objective(negative_cvar, returns_dict[x])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compare the CVaR-minimizing weights to the minimum volatility weights for the 'before' epoch</span></span><br><span class="line">print(<span class="string">"CVaR:\n"</span>, pd.DataFrame.from_dict(optimal_weights_dict[<span class="string">'before'</span>]), <span class="string">"\n"</span>)</span><br><span class="line">print(<span class="string">"Min Vol:\n"</span>, pd.DataFrame.from_dict(min_vol_dict[<span class="string">'before'</span>]), <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure></p>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CVaR:</span><br><span class="line">                   Weight</span><br><span class="line">Citibank        0.248754</span><br><span class="line">Morgan Stanley  0.249111</span><br><span class="line">Goldman Sachs   0.250973</span><br><span class="line">J.P. Morgan     0.251162 </span><br><span class="line"></span><br><span class="line">Min Vol:</span><br><span class="line">                   Weight</span><br><span class="line">Citibank        0.655621</span><br><span class="line">Morgan Stanley  0.059033</span><br><span class="line">Goldman Sachs   0.029725</span><br><span class="line">J.P. Morgan     0.255621</span><br></pre></td></tr></table></figure></p>
<h1 id="Portfolio-hedging-offsetting-risk"><a href="#Portfolio-hedging-offsetting-risk" class="headerlink" title="Portfolio hedging: offsetting risk"></a>Portfolio hedging: offsetting risk</h1><h2 id="Portfolio-statbility"><a href="#Portfolio-statbility" class="headerlink" title="Portfolio statbility"></a>Portfolio statbility</h2><p>VaR/CVaR: potential portfolio loss for given confidence level<br>Portfolio optimization: “best” portfolio weights</p>
<ul>
<li>But volatility is still presents!<br>Institutional investors: stability of portforlio against volatile changes</li>
<li>pension funds: c. USD 20 trillion</li>
</ul>
<h2 id="Example-raning-days-and-sunny-days"><a href="#Example-raning-days-and-sunny-days" class="headerlink" title="Example: raning days and sunny days"></a>Example: raning days and sunny days</h2><p><strong>Investors portfolio</strong>: sunglasses company</p>
<ul>
<li><strong>Risk factor</strong>: weather (rain)</li>
<li>More rain -&gt; lower company value</li>
<li>Lower campany value -&gt; lower stock price</li>
<li>lower stock price -&gt; lower portfolio value</li>
</ul>
<p>Second opportunity: umbrella company </p>
<ul>
<li>more rain -&gt; more value</li>
</ul>
<p>Portfolio: sunglasses &amp; unbrella, more <strong>stable</strong> —&gt; risk reduced</p>
<p>—-&gt; <strong>Hedging</strong>: offset volatility with another asset</p>
<h2 id="Hudging-instrumentes-options-（期权）"><a href="#Hudging-instrumentes-options-（期权）" class="headerlink" title="Hudging instrumentes: options （期权）"></a>Hudging instrumentes: options （期权）</h2><p>derivative hedging strategies (衍生对冲策略)</p>
<p>Hedging is often performed using <strong>derivatives</strong> to offset a risky asset position. </p>
<p>One of the most basic derivatives is the <strong>European option</strong>. </p>
<ul>
<li>A European <strong>‘call’</strong> option gives the holder the right (but not the obligation) to _purchase_ a stock for a fixed price X at a particular time M. </li>
<li>A European <strong>‘put’</strong> option gives the holder the right (but not the obligation) to _sell_ a stock for a fixed price X at a particular time M. </li>
</ul>
<p>The stock is called the ‘underlying’ of the option. The market price of the underlying is called the ‘spot’ price ‘S’. The fixed price is called the ’strike’ price ‘X’ and the time ‘M’ is the ‘maturity’.</p>
<h2 id="Exercises-1"><a href="#Exercises-1" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="Black-Scholes-options-pricing"><a href="#Black-Scholes-options-pricing" class="headerlink" title="Black-Scholes options pricing"></a>Black-Scholes options pricing</h3><p><a href="https://wiki.mbalib.com/wiki/Black-Scholes%E6%9C%9F%E6%9D%83%E5%AE%9A%E4%BB%B7%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener">Black-Scholes 期权定价模型</a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute the volatility as the annualized standard deviation of IBM returns</span></span><br><span class="line">sigma = np.sqrt(<span class="number">252</span>) * IBM_returns.std() </span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the Black-Scholes option price for this volatility</span></span><br><span class="line">value_s = black_scholes(S = <span class="number">90</span>, X = <span class="number">80</span>, T = <span class="number">0.5</span>, r = <span class="number">0.02</span>, </span><br><span class="line">                        sigma = sigma, option_type = <span class="string">"call"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the Black-Scholes option price for twice the volatility</span></span><br><span class="line">value_2s = black_scholes(S = <span class="number">90</span>, X = <span class="number">80</span>, T = <span class="number">0.5</span>, r = <span class="number">0.02</span>, </span><br><span class="line">                sigma = <span class="number">2</span>*sigma, option_type = <span class="string">"call"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display and compare both values</span></span><br><span class="line">print(<span class="string">"Option value for sigma: "</span>, value_s, <span class="string">"\n"</span>,</span><br><span class="line">      <span class="string">"Option value for 2 * sigma: "</span>, value_2s)</span><br></pre></td></tr></table></figure></p>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Option value for sigma:  12.129167513536352 </span><br><span class="line">Option value for 2 * sigma:  16.24149623118327</span><br></pre></td></tr></table></figure></p>
<h3 id="Options-pricing-and-the-underlying-asset"><a href="#Options-pricing-and-the-underlying-asset" class="headerlink" title="Options pricing and the underlying asset"></a>Options pricing and the underlying asset</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Select the first 100 observations of IBM data</span><br><span class="line">IBM_spot = IBM[:100]</span><br><span class="line"></span><br><span class="line"># Initialize the European put option values array</span><br><span class="line">option_values = np.zeros(IBM_spot.size)</span><br><span class="line"></span><br><span class="line"># Iterate through IBM&apos;s spot price and compute the option values</span><br><span class="line">for i,S in enumerate(IBM_spot.values):</span><br><span class="line">    option_values[i] = black_scholes(S = S, X = 140, T = 0.5, r = 0.02, </span><br><span class="line">                        sigma = sigma, option_type = &quot;put&quot;)</span><br><span class="line"></span><br><span class="line"># Display the option values array</span><br><span class="line">option_axis.plot(option_values, color = &quot;red&quot;, label = &quot;Put Option&quot;)</span><br><span class="line">option_axis.legend(loc = &quot;upper left&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/14.%20Options%20pricing%20and%20the%20underlying%20asset.svg" alt="Options pricing and the underlying asset"></p>
<h3 id="Using-options-for-hedging"><a href="#Using-options-for-hedging" class="headerlink" title="Using options for hedging"></a>Using options for hedging</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute the annualized standard deviation of `IBM` returns</span></span><br><span class="line">sigma = np.sqrt(<span class="number">252</span>) * IBM_returns.std()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the Black-Scholes value at IBM spot price 70</span></span><br><span class="line">value = black_scholes(S = <span class="number">70</span>, X = <span class="number">80</span>, T = <span class="number">0.5</span>, r = <span class="number">0.02</span>, </span><br><span class="line">                      sigma = sigma, option_type = <span class="string">"put"</span>)</span><br><span class="line"><span class="comment"># Find the delta of the option at IBM spot price 70</span></span><br><span class="line">delta = bs_delta(S = <span class="number">70</span>, X = <span class="number">80</span>, T = <span class="number">0.5</span>, r = <span class="number">0.02</span>, </span><br><span class="line">                 sigma = sigma, option_type = <span class="string">"put"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the option value change when the price of IBM falls to 69.5</span></span><br><span class="line">value_change = black_scholes(S = <span class="number">69.5</span>, X = <span class="number">80</span>, T = <span class="number">0.5</span>, r = <span class="number">0.02</span>, </span><br><span class="line">                             sigma = sigma, option_type = <span class="string">"put"</span>) - value</span><br><span class="line"></span><br><span class="line">print( (<span class="number">69.5</span> - <span class="number">70</span>) + (<span class="number">1</span>/delta) * value_change )</span><br></pre></td></tr></table></figure>
<p>结果为<code>0.00459428051019628</code></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Quantative Risk Management 1/4 - Risk and Return</title>
    <url>/2021/01/09/Quantative-Risk-Management-1-4-Risk-and-Return/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p><strong>Datacamp:</strong> <a href="https://campus.datacamp.com/courses/quantitative-risk-management-in-python" target="_blank" rel="noopener">https://campus.datacamp.com/courses/quantitative-risk-management-in-python</a></p>
<p><strong>Course Description</strong><br>Managing risk using Quantitative Risk Management is a vital task across the banking, insurance, and asset management industries. It’s essential that financial risk analysts, regulators, and actuaries can quantitatively balance rewards against their exposure to risk. This course introduces you to financial portfolio risk management through an examination of the 2007—2008 financial crisis and its effect on investment banks such as Goldman Sachs and J.P. Morgan. You’ll learn how to use Python to calculate and mitigate risk exposure using the Value at Risk and Conditional Value at Risk measures, estimate risk with techniques like Monte Carlo simulation, and use cutting-edge technologies such as neural networks to conduct real time portfolio rebalancing.</p>
</blockquote>
<p><strong>1/4 Object: </strong></p>
<ol>
<li>understanding of risk and return</li>
<li>how risk and return are related to each other, </li>
<li>identify risk factors, and use them to re-acquaint ourselves with Modern Portfolio Theory applied to the global financial crisis of 2007-2008.</li>
</ol>
<hr>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>Quantitative Risk Management: Study of quantifiable <strong>uncertainty</strong></li>
<li>Uncertainty: (1) Future outcome (2) Outcomes impact planning decisions</li>
<li>Risk Management: mitigate (reduce effects of) adverse outcomes</li>
<li>Quantifiable uncertainty: identify <strong>fators to measure risk</strong> (what factors can cause the uncertainty)</li>
<li>This project: Focus upon risk associated with a <em>financial portfolio</em></li>
</ul>
<h2 id="This-project"><a href="#This-project" class="headerlink" title="This project"></a>This project</h2><p><strong>The Great Recession (2007-2010)</strong></p>
<ul>
<li>Global growth loss more than $2 trillion</li>
<li>United States: nearly $10 trillion lost in household wealth</li>
<li>U.S. stock markets lost c. $8 trillion in value</li>
</ul>
<p><strong>Global Finacial Crisis (2007-2009)</strong></p>
<ul>
<li>Large-scale changes in fundamental asset values</li>
<li>Massive uncertainty about future returns</li>
<li>High asset returns volatility</li>
<li>Risk management critical to success or failure</li>
</ul>
<a id="more"></a>
<h2 id="Financial-portpolios"><a href="#Financial-portpolios" class="headerlink" title="Financial portpolios"></a>Financial portpolios</h2><ul>
<li>Collection of assets with uncertain future returns</li>
<li>Stocks</li>
<li>Bonds</li>
<li>Foreign exchange holdings (‘forex’)</li>
<li>Stock options</li>
</ul>
<p>Challenge: Quantify risk to manage uncertainty</p>
<ul>
<li>Make optimal investment decisions</li>
<li>Maximize portfolio return, conditional on risk appetite</li>
</ul>
<h2 id="Quantifying-return"><a href="#Quantifying-return" class="headerlink" title="Quantifying return"></a>Quantifying return</h2><p>Portfolio return: weighted sum of individual asset returns</p>
<ul>
<li><code>pandas</code> data analysis library</li>
<li>DataFrame <code>prices</code></li>
<li><code>.pct_change()</code> method</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">prices = pandas.read_csv(<span class="string">"portfolio.csv"</span>)</span><br><span class="line">returns = prices.pct_change()</span><br><span class="line">weights = (weight_1, weight_2, ...)</span><br><span class="line">portfolio_returns = returns.dot(weights)</span><br></pre></td></tr></table></figure>
<h2 id="Quantifying-risk"><a href="#Quantifying-risk" class="headerlink" title="Quantifying risk"></a>Quantifying risk</h2><ul>
<li>Portfolio return volatility = risk </li>
<li>Calculate volatility(波动率) via <strong>covariance matrix</strong>（协方差矩阵）</li>
<li>Use <code>.cov()</code> DataFrame method of <code>returns</code> and anaualize</li>
<li><em>Diagonal</em> of <code>covariance</code> is individual assets variances</li>
<li><em>Off-diagonal</em> of <code>covariance</code> are covariances between assets</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right"></th>
<th style="text-align:right">Assets 1</th>
<th style="text-align:right">Assets 2</th>
<th style="text-align:right">Assets 3</th>
<th style="text-align:right">Assets 4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">Assets 1</td>
<td style="text-align:right">Diagonal</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Off-diagonal</td>
</tr>
<tr>
<td style="text-align:right">Assets 2</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Diagonal</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Off-diagonal</td>
</tr>
<tr>
<td style="text-align:right">Assets 3</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Diagonal</td>
<td style="text-align:right">Off-diagonal</td>
</tr>
<tr>
<td style="text-align:right">Assets 4</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Off-diagonal</td>
<td style="text-align:right">Diagonal</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">covariance = returns.cov()*<span class="number">252</span></span><br><span class="line"><span class="comment"># 252 is the number of trading days</span></span><br><span class="line">print(covariance)</span><br></pre></td></tr></table></figure>
<h2 id="Portfolio-risk"><a href="#Portfolio-risk" class="headerlink" title="Portfolio risk"></a>Portfolio risk</h2><p>The portfolio variance is a quadratic function of the <strong>weights</strong> given the covariance matrix, which can be computed in Python using the “At” operator. The variance is usually then transformed into the standard deviation, resulting in the portfolio’s volatility. Both variance and standard deviation are used as measures of volatility.</p>
<ul>
<li>Depends upon asset weights in portfolio</li>
<li>Portfolio variance (方差) = weight矩阵转置 <em> covariance 协方差 </em> weight</li>
<li>Matrix multiplication can be computed using <code>@</code> operator in python</li>
<li>Standard deviation (标准差) is usually used instead of variance （方差）,  标准差是方差的平方根</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights = [<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>]</span><br><span class="line">portfolio_variance = np.transpose(weights) @ covariance @ weights</span><br><span class="line">portfolio_volatility = np.sart(protforlio_variance)</span><br></pre></td></tr></table></figure>
<h2 id="Volotility-time-series（时间序列）"><a href="#Volotility-time-series（时间序列）" class="headerlink" title="Volotility time series（时间序列）"></a>Volotility time series（时间序列）</h2><ul>
<li>Can also calculate portfolio volatility over time</li>
<li>Use a ‘window’ to comput volatiity over a fixed time period (e.g. a week, 30-day ‘month’)</li>
<li><code>series.rolling()</code> creates a window</li>
<li>Observe volatility <strong>trend</strong> and possible <strong>extreme</strong> events</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">windowed = portfolio_returns.rolling(<span class="number">30</span>)</span><br><span class="line">volotility = windowed.std()*np.sqrt(<span class="number">252</span>)</span><br><span class="line">volatility.plot().set.ylable(<span class="string">"Standard Deviation, 20-day window"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Excercises"><a href="#Excercises" class="headerlink" title="Excercises"></a>Excercises</h2><p>quantifying the effects of uncertainty on a financial portfolio</p>
<h3 id="examine-the-portfolio’s-return"><a href="#examine-the-portfolio’s-return" class="headerlink" title="examine the portfolio’s return"></a>examine the portfolio’s return</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Select portfolio asset prices for the middle of the crisis, 2008-2009</span></span><br><span class="line">asset_prices = portfolio.loc[<span class="string">'2008-01-01'</span>:<span class="string">'2009-12-31'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot portfolio's asset prices during this time</span></span><br><span class="line">asset_prices.plot().set_ylabel(<span class="string">"Closing Prices, USD"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/1.%20closing%20price.svg" alt="closing price"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Compute the portfolio&apos;s daily returns</span><br><span class="line">asset_returns = asset_prices.pct_change()</span><br><span class="line">portfolio_returns = asset_returns.dot(weights)</span><br><span class="line"></span><br><span class="line"># Plot portfolio returns</span><br><span class="line">portfolio_returns.plot().set_ylabel(&quot;Daily Return, %&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/1.5%20daily%20returns.svg" alt="daily returns"></p>
<h3 id="assess-the-riskiness-of-the-portfolio-using-the-covariance-matrix-to-determine-the-portfolio’s-volatility"><a href="#assess-the-riskiness-of-the-portfolio-using-the-covariance-matrix-to-determine-the-portfolio’s-volatility" class="headerlink" title="assess the riskiness of the portfolio using the covariance matrix to determine the portfolio’s volatility"></a>assess the riskiness of the portfolio using the covariance matrix to determine the portfolio’s volatility</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Generate the covariance matrix from portfolio asset&apos;s returns</span><br><span class="line">covariance = asset_returns.cov()</span><br><span class="line"></span><br><span class="line"># Annualize the covariance using 252 trading days per year</span><br><span class="line">covariance = covariance * 252</span><br><span class="line"></span><br><span class="line"># Display the covariance matrix</span><br><span class="line">print(covariance)</span><br><span class="line">                Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan</span><br><span class="line">Citibank        1.475195        0.821707       0.573790     0.724639</span><br><span class="line">Morgan Stanley  0.821707        1.298341       0.658895     0.560523</span><br><span class="line">Goldman Sachs   0.573790        0.658895       0.500807     0.426979</span><br><span class="line">J.P. Morgan     0.724639        0.560523       0.426979     0.685584</span><br></pre></td></tr></table></figure>
<p>Q: Which portfolio asset has the highest annualized volatility over the time period 2008 - 2009?<br>A: Citibank<br>(the highest along the diagonal of the covariance matrix.)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute and display portfolio volatility for 2008 - 2009</span></span><br><span class="line">portfolio_variance = np.transpose(weights) @ covariance @ weights</span><br><span class="line">portfolio_volatility = np.sqrt(portfolio_variance)</span><br><span class="line">print(portfolio_volatility)</span><br><span class="line"><span class="number">0.8475328513962702</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Calculate the 30-day rolling window of portfolio returns</span></span><br><span class="line">returns_windowed = portfolio_returns.rolling(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the annualized volatility series</span></span><br><span class="line">volatility_series = returns_windowed.std()*np.sqrt(<span class="number">252</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the portfolio volatility</span></span><br><span class="line">volatility_series.plot().set_ylabel(<span class="string">"Annualized Volatility, 30-day Window"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/2.%20series%20volatility.svg" alt="series volatility"></p>
<h1 id="Risk-factors-and-financial-crisis"><a href="#Risk-factors-and-financial-crisis" class="headerlink" title="Risk factors and financial crisis"></a>Risk factors and financial crisis</h1><h2 id="Risk-factors"><a href="#Risk-factors" class="headerlink" title="Risk factors"></a>Risk factors</h2><ul>
<li>Valatility: measure of <strong>dispersion</strong>(离散程度) of resturns around expected value</li>
<li>Time series: expected value = sample average</li>
<li>What drives expectation and dispersion?</li>
<li><strong>Risk factors</strong>: variables or events driving portfolio return and volatility</li>
</ul>
<h2 id="Risk-exposure"><a href="#Risk-exposure" class="headerlink" title="Risk exposure"></a>Risk exposure</h2><p><strong>Risk exposure</strong>: meausre of possible portfolio loss<br><strong>Risk factors</strong> determine risk exposure</p>
<h2 id="Risk-Factors"><a href="#Risk-Factors" class="headerlink" title="Risk Factors"></a>Risk Factors</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Type of risk</th>
<th style="text-align:left">definition</th>
<th style="text-align:left">example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Systematic risk （系统性风险）</td>
<td style="text-align:left">affect volatility of all portfolio assets</td>
<td style="text-align:left">e.g. airplane engine failure</td>
</tr>
<tr>
<td style="text-align:left">Market risk</td>
<td style="text-align:left">systematic risk from general financial market movements</td>
<td style="text-align:left">price level changes, i.e. inflation; interest rate changes; Economic climate changes</td>
</tr>
<tr>
<td style="text-align:left">Idiosyncratic risk （特殊风险，非系统性）</td>
<td style="text-align:left">risk specific to a particular asset/asset class</td>
<td style="text-align:left">terbulence and the unfastened seatbelt; Bond portfolio: issuer risk of default（违约风险）; Firm/sector characteristics: Firm size （market captalization, 市值）, Book-to-market(股价净值比) issue, Sector shocks (冲击)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Factor-models"><a href="#Factor-models" class="headerlink" title="Factor models"></a>Factor models</h2><p><strong>Factor model</strong>: assessment of risk factors affecting portfolio return<br><strong>Satistical regression</strong> (统计回归)：e.g. Ordinary Least Squares (普通最小二乘法/线性回归)<br>_ dependent variable （因变量）: return (or volatility)</p>
<ul>
<li>independent variable （自变量）: systemic and/or idosyncratice risk factors<br><strong>Fama-French factor model</strong>: combination of</li>
<li>market risk and</li>
<li>idiosycratic risk (firm size, firm value)</li>
</ul>
<h2 id="Crisis-risk-factor-mortgage-backed-securities-（MBS-不动产抵押贷款证券）"><a href="#Crisis-risk-factor-mortgage-backed-securities-（MBS-不动产抵押贷款证券）" class="headerlink" title="Crisis risk factor: mortgage-backed securities （MBS 不动产抵押贷款证券）"></a>Crisis risk factor: mortgage-backed securities （MBS 不动产抵押贷款证券）</h2><p><strong>Investment banks:</strong> borrowed heavily just before the crisis （金融危机前大量发债）<br><strong>Collateral</strong>: mortgage-backed securities<br><strong>MBS</strong>: supposed to siversify risk by holdings</p>
<ul>
<li>Flaw: mortgage default risk in fact was highly correlated （违约风险高度相关）</li>
<li>Avalanche of delinquencies （拖延雪崩）/ default destroyed collateral value(抵押价值被破坏)<br><strong>90-day mortgage delinquency</strong> (90天抵押贷款拖欠): risk factor for investment bank portfolio during the crisis</li>
</ul>
<p><strong>Factor model regression</strong>: portfolio returns vs. mortagage delinquency<br>Import <code>statsmodels.api</code> library for regression tools<br>Fit regression using <code>.OLS()</code> object and its <code>.fit()</code> method<br>Display results using regression’s <code>.summary</code> method</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">regression = sm.OLS(<span class="keyword">return</span>, delinquencies).fit()</span><br><span class="line">print(regression.summary())</span><br></pre></td></tr></table></figure>
<p>It is the statistical significance of the <strong>regression coefficient</strong> (回归系数) for mortgage delinquencies that concerns us most. </p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><h3 id="Frequency-resampling-primer"><a href="#Frequency-resampling-primer" class="headerlink" title="Frequency resampling primer"></a>Frequency resampling primer</h3><p>Risk factor models often rely upon <strong>data that is of different frequencies</strong>. A typical example is when using quarterly macroeconomic data, such as prices, unemployment rates, etc., with financial data, which is often daily (or even intra-daily). To use both data sources in the same model, higher frequency data needs to be <strong>resampled to match the lower frequency data.</strong></p>
<p>The <code>DataFrame</code> and <code>Series</code> Pandas objects have a built-in <code>.resample()</code> method that specifies the lower frequency. This method is chained with a method to create the lower-frequency statistic, such as <code>.mean()</code> for the average of the data within the new frequency period, or <code>.min()</code> for the minimum of the data.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Convert daily returns data to weekly and quarterly frequency</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Convert daily returns to quarterly average returns</span></span><br><span class="line">returns_q = returns.resample(<span class="string">'Q'</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Examine the beginning of the quarterly series</span></span><br><span class="line">print(returns_q.head)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Convert daily returns to weekly minimum returns</span></span><br><span class="line">returns_w = returns.resample(<span class="string">'W'</span>).min()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Examine the beginning of the weekly series</span></span><br><span class="line">print(returns_w.head)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;bound method NDFrame.head of Date</span><br><span class="line">2004-12-31         NaN</span><br><span class="line">2005-03-31   -0.000367</span><br><span class="line">2005-06-30   -0.000366</span><br><span class="line">2005-09-30    0.000615</span><br><span class="line">2005-12-31    0.001323</span><br><span class="line">2006-03-31    0.001384</span><br><span class="line">2006-06-30    0.000084</span><br><span class="line">2006-09-30    0.001654</span><br><span class="line">2006-12-31    0.001717</span><br><span class="line">2007-03-31   -0.000200</span><br><span class="line">2007-06-30    0.000509</span><br><span class="line">2007-09-30   -0.001446</span><br><span class="line">2007-12-31   -0.002300</span><br><span class="line">2008-03-31   -0.002337</span><br><span class="line">2008-06-30   -0.002166</span><br><span class="line">2008-09-30    0.000943</span><br><span class="line">2008-12-31   -0.003480</span><br><span class="line">2009-03-31    0.002415</span><br><span class="line">2009-06-30    0.004946</span><br><span class="line">2009-09-30    0.004516</span><br><span class="line">2009-12-31   -0.001940</span><br><span class="line">2010-03-31    0.001330</span><br><span class="line">2010-06-30   -0.002688</span><br><span class="line">2010-09-30    0.001088</span><br><span class="line">2010-12-31    0.002328</span><br><span class="line">Freq: Q-DEC, dtype: float64&gt;</span><br><span class="line">&lt;bound method NDFrame.head of Date</span><br><span class="line">2005-01-02         NaN</span><br><span class="line">2005-01-09   -0.011152</span><br><span class="line">2005-01-16   -0.007643</span><br><span class="line">2005-01-23   -0.011076</span><br><span class="line">2005-01-30   -0.000443</span><br><span class="line">                ...   </span><br><span class="line">2010-12-05   -0.009894</span><br><span class="line">2010-12-12    0.001379</span><br><span class="line">2010-12-19   -0.016622</span><br><span class="line">2010-12-26   -0.005974</span><br><span class="line">2011-01-02   -0.007729</span><br><span class="line">Freq: W-SUN, Length: 314, dtype: float64&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="Visualizing-risk-factor-correlation"><a href="#Visualizing-risk-factor-correlation" class="headerlink" title="Visualizing risk factor correlation"></a>Visualizing risk factor correlation</h3><p>Investment banks heavily invested in mortgage-backed securities (MBS) before and during the financial crisis. This makes MBS a likely risk factor for the investment bank portfolio. </p>
<p>Assess this using scatterplots between <code>portfolio_returns</code> and an MBS risk measure, the 90-day mortgage delinquency rate <code>mort_del</code>.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Transform the daily portfolio_returns into quarterly average returns</span></span><br><span class="line">portfolio_q_average = portfolio_returns.resample(<span class="string">'Q'</span>).mean().dropna()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a scatterplot between delinquency and quarterly average returns</span></span><br><span class="line">plot_average.scatter(mort_del, portfolio_q_average)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform daily portfolio_returns returns into quarterly minimum returns</span></span><br><span class="line">portfolio_q_min = portfolio_returns.resample(<span class="string">'Q'</span>).min().dropna()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a scatterplot between delinquency and quarterly minimum returns</span></span><br><span class="line">plot_min.scatter(mort_del, portfolio_q_min)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/3.%20visualizing%20risk%20factor%20correlation.svg" alt="visualize correlation"></p>
<h3 id="Least-squares-factor-model"><a href="#Least-squares-factor-model" class="headerlink" title="Least-squares factor model"></a>Least-squares factor model</h3><p>As we can see, there is a negative correlation between minimum quarterly returns and mortgage delinquency rates from 2005 - 2010. This can be made more precise with an OLS regression factor model.</p>
<p>Dependent variables: <strong>average returns</strong>, <strong>minimum returns</strong>, and <strong>average volatility</strong>.<br>Independent variable: <strong>the mortgage delinquency rate</strong>. </p>
<p>In the regression summary, examine the coefficients’ t-statistic for statistical significance, as well as the overall R-squared for goodness of fit.</p>
<p>The statsmodels.api library is available as sm.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Add a constant to the regression</span></span><br><span class="line">mort_del = sm.add_constant(mort_del)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the regression factor model and fit it to the data</span></span><br><span class="line">results = sm.OLS(port_q_mean, mort_del).fit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print a summary of the results</span></span><br><span class="line">print(results.summary())</span><br></pre></td></tr></table></figure>
<p>分别比较三个因变量的回归系数</p>
<ol>
<li><code>results = sm.OLS(port_q_mean, mort_del).fit()</code></li>
<li><code>results = sm.OLS(port_q_min, mort_del).fit()</code></li>
<li><code>results = sm.OLS(vol_q_mean, mort_del).fit()</code></li>
</ol>
<p><code>results = sm.OLS(port_q_mean, mort_del).fit()</code> 结果：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                            OLS Regression Results                            </span><br><span class="line">==============================================================================</span><br><span class="line">Dep. Variable:                      y   R-squared:                       0.021</span><br><span class="line">Model:                            OLS   Adj. R-squared:                 -0.023</span><br><span class="line">Method:                 Least Squares   F-statistic:                    0.4801</span><br><span class="line">Date:                Sat, 09 Jan 2021   Prob (F-statistic):              0.496</span><br><span class="line">Time:                        05:15:21   Log-Likelihood:                 113.89</span><br><span class="line">No. Observations:                  24   AIC:                            -223.8</span><br><span class="line">Df Residuals:                      22   BIC:                            -221.4</span><br><span class="line">Df Model:                           1                                         </span><br><span class="line">Covariance Type:            nonrobust                                         </span><br><span class="line">=============================================================================================</span><br><span class="line">                                coef    std err          t      P&gt;|t|      [0.025      0.975]</span><br><span class="line">---------------------------------------------------------------------------------------------</span><br><span class="line">const                        -0.0001      0.001     -0.175      0.862      -0.002       0.002</span><br><span class="line">Mortgage Delinquency Rate     0.0083      0.012      0.693      0.496      -0.016       0.033</span><br><span class="line">==============================================================================</span><br><span class="line">Omnibus:                        0.081   Durbin-Watson:                   1.604</span><br><span class="line">Prob(Omnibus):                  0.960   Jarque-Bera (JB):                0.293</span><br><span class="line">Skew:                          -0.071   Prob(JB):                        0.864</span><br><span class="line">Kurtosis:                       2.477   Cond. No.                         26.7</span><br><span class="line">==============================================================================</span><br><span class="line"></span><br><span class="line">Warnings:</span><br><span class="line">[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</span><br></pre></td></tr></table></figure></p>
<p><code>results = sm.OLS(port_q_min, mort_del).fit()</code>结果：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">OLS Regression Results                            </span><br><span class="line">==============================================================================</span><br><span class="line">Dep. Variable:                      y   R-squared:                       0.178</span><br><span class="line">Model:                            OLS   Adj. R-squared:                  0.141</span><br><span class="line">Method:                 Least Squares   F-statistic:                     4.761</span><br><span class="line">Date:                Sat, 09 Jan 2021   Prob (F-statistic):             0.0401</span><br><span class="line">Time:                        05:17:56   Log-Likelihood:                 39.937</span><br><span class="line">No. Observations:                  24   AIC:                            -75.87</span><br><span class="line">Df Residuals:                      22   BIC:                            -73.52</span><br><span class="line">Df Model:                           1                                         </span><br><span class="line">Covariance Type:            nonrobust                                         </span><br><span class="line">=============================================================================================</span><br><span class="line">                                coef    std err          t      P&gt;|t|      [0.025      0.975]</span><br><span class="line">---------------------------------------------------------------------------------------------</span><br><span class="line">const                        -0.0279      0.017     -1.611      0.121      -0.064       0.008</span><br><span class="line">Mortgage Delinquency Rate    -0.5664      0.260     -2.182      0.040      -1.105      -0.028</span><br><span class="line">==============================================================================</span><br><span class="line">Omnibus:                       13.525   Durbin-Watson:                   0.513</span><br><span class="line">Prob(Omnibus):                  0.001   Jarque-Bera (JB):               12.333</span><br><span class="line">Skew:                          -1.534   Prob(JB):                      0.00210</span><br><span class="line">Kurtosis:                       4.710   Cond. No.                         26.7</span><br><span class="line">==============================================================================</span><br><span class="line"></span><br><span class="line">Warnings:</span><br><span class="line">[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</span><br></pre></td></tr></table></figure></p>
<p><code>results = sm.OLS(vol_q_mean, mort_del).fit()</code>结果：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                            OLS Regression Results                            </span><br><span class="line">==============================================================================</span><br><span class="line">Dep. Variable:                      y   R-squared:                       0.190</span><br><span class="line">Model:                            OLS   Adj. R-squared:                  0.154</span><br><span class="line">Method:                 Least Squares   F-statistic:                     5.174</span><br><span class="line">Date:                Sat, 09 Jan 2021   Prob (F-statistic):             0.0330</span><br><span class="line">Time:                        05:22:24   Log-Likelihood:                 60.015</span><br><span class="line">No. Observations:                  24   AIC:                            -116.0</span><br><span class="line">Df Residuals:                      22   BIC:                            -113.7</span><br><span class="line">Df Model:                           1                                         </span><br><span class="line">Covariance Type:            nonrobust                                         </span><br><span class="line">=============================================================================================</span><br><span class="line">                                coef    std err          t      P&gt;|t|      [0.025      0.975]</span><br><span class="line">---------------------------------------------------------------------------------------------</span><br><span class="line">const                         0.0100      0.007      1.339      0.194      -0.006       0.026</span><br><span class="line">Mortgage Delinquency Rate     0.2558      0.112      2.275      0.033       0.023       0.489</span><br><span class="line">==============================================================================</span><br><span class="line">Omnibus:                       19.324   Durbin-Watson:                   0.517</span><br><span class="line">Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.053</span><br><span class="line">Skew:                           1.814   Prob(JB):                     9.87e-06</span><br><span class="line">Kurtosis:                       6.145   Cond. No.                         26.7</span><br><span class="line">==============================================================================</span><br><span class="line"></span><br><span class="line">Warnings:</span><br><span class="line">[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</span><br></pre></td></tr></table></figure></p>
<h1 id="Morden-portforlio-throry"><a href="#Morden-portforlio-throry" class="headerlink" title="Morden portforlio throry"></a>Morden portforlio throry</h1><h2 id="The-risk-return-trade-off"><a href="#The-risk-return-trade-off" class="headerlink" title="The risk-return trade-off"></a>The risk-return trade-off</h2><p>Risk factors: sources of uncertainty affecting return<br>Intuitively(直觉): greater undcertainty (more risk) compensated by greater return<br>Cannot guarantee return: need some meaure of expected return</p>
<ul>
<li>average (mean) historical return: proxy for expected future return</li>
</ul>
<h2 id="Investor-risk-appetite"><a href="#Investor-risk-appetite" class="headerlink" title="Investor risk appetite"></a>Investor risk appetite</h2><p>Investor survey: minimum return required for given level of risk?<br>Survey response creates (risk. return) risk profile “data point”<br>Vary risk level =&gt; set of (risk, return) points<br>Investor <strong>risk appetite</strong> (风险偏好): defines one quantified relationship between risk and return</p>
<h2 id="Choosing-portfolio-weights"><a href="#Choosing-portfolio-weights" class="headerlink" title="Choosing portfolio weights"></a>Choosing portfolio weights</h2><p>Vary <strong>portforlio weights</strong> of given portforlio =&gt; creates set of (risk, return) pairs<br>Changing weights = beginning of risk management!<br><strong>Goal</strong>: change weights to maximize expected return, given risk level</p>
<ul>
<li>Eyuivalently: minimize risk, given expected return level<br>Changing weights = adjusting investors’ risk exposure</li>
</ul>
<h2 id="Morden-portforlio-throry-MPT"><a href="#Morden-portforlio-throry-MPT" class="headerlink" title="Morden portforlio throry (MPT)"></a>Morden portforlio throry (MPT)</h2><p><strong>Efficient portfolio</strong>: portfolio with weights generating <em>highest expected return</em> pf <em>given level of risk</em></p>
<h2 id="The-efficient-frontier-（有效前沿-效率前沿模型）"><a href="#The-efficient-frontier-（有效前沿-效率前沿模型）" class="headerlink" title="The efficient frontier （有效前沿/效率前沿模型）"></a>The efficient frontier （有效前沿/效率前沿模型）</h2><ul>
<li>Compute many efficient portfolios for different levels of risk </li>
<li>Efficient frontier（有效边界）: locus (轨迹) of (risk, return) pairs created by efficient portfolios</li>
<li>有效边界是在收益—风险约束条件下能够以最小的风险取得最大的收益的各种证券的集合</li>
<li>处于有效边界上的组合称为有效组合（Efficient Portfolio）</li>
</ul>
<p><strong><code>PyPortfolioOpt</code> library:</strong> optimized tools for MPT<br><strong><code>EfficientFrontier</code> class</strong>: generates one optimal portfolio at a time<br><strong>Constrained Line Algorithm (边界算法) class</strong>: generate the entire efficient frontier </p>
<ul>
<li>Requires covariance matrix of returns)</li>
<li>Requires proxy for expected future returns: mean historical returns</li>
</ul>
<h2 id="Invesrment-bank-portfolio-2005-2010"><a href="#Invesrment-bank-portfolio-2005-2010" class="headerlink" title="Invesrment bank portfolio 2005-2010"></a>Invesrment bank portfolio 2005-2010</h2><p><strong>Expected returns</strong>: historical data<br><strong>Covariance matrix</strong>: <code>Covariance Shrinkage</code> improved efficiency of estimate<br><strong>Constrained Line Algorithm </strong>object <code>CLA</code><br><strong>Minimum variance portfolio</strong>: <code>cla.min_volatility()</code><br><strong>Efficient frontier</strong>: <code>cla.efficient_frontier()</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">expected returns = mean_historical_return(prices)</span><br><span class="line">efficient_cov = CovarianceShrinkage(prices).ledoit_wolf()</span><br><span class="line">cla = CLA(expected_returns, efficient_cov)</span><br><span class="line">minimum_variance = cla,min_volatility()</span><br><span class="line">(ret, vol. weights) = cla.efficient_frontier()</span><br></pre></td></tr></table></figure>
<h2 id="Visualizing-the-efficient-frontier"><a href="#Visualizing-the-efficient-frontier" class="headerlink" title="Visualizing the efficient frontier"></a>Visualizing the efficient frontier</h2><p>scatter plot of (vol, ret) pairs<br><strong>Minimum variance portfolio</strong> （最小方差投资组合）: smallest volatility of all possible efficient portfolios<br>Increase risk appetite (增加风险承受能力): move along the frontier<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/4.%20efficient%20frontier.png" alt="Efficient frontier"></p>
<h2 id="Excercises-1"><a href="#Excercises-1" class="headerlink" title="Excercises"></a>Excercises</h2><h3 id="Practice-with-PyPortfolioOpt-returns"><a href="#Practice-with-PyPortfolioOpt-returns" class="headerlink" title="Practice with PyPortfolioOpt: returns"></a>Practice with PyPortfolioOpt: returns</h3><p>Modern Portfolio Theory is the cornerstone of portfolio risk management, because the efficient frontier is a standard method of assessing both investor risk appetite and market risk-return tradeoffs. In this exercise you’ll develop powerful tools to explore a portfolio’s efficient frontier, using the PyPortfolioOpt <code>pypfopt</code> Python library.</p>
<p>To compute the efficient frontier, both expected returns and the covariance matrix of the portfolio are required.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load the investment portfolio price data into the price variable.</span></span><br><span class="line">prices = pd.read_csv(<span class="string">"portfolio.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the 'Date' column to a datetime index</span></span><br><span class="line">prices[<span class="string">'Date'</span>] = pd.to_datetime(prices[<span class="string">'Date'</span>], format=<span class="string">'%d/%m/%Y'</span>)</span><br><span class="line">prices.set_index([<span class="string">'Date'</span>], inplace = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import the mean_historical_return method</span></span><br><span class="line"><span class="keyword">from</span> pypfopt.expected_returns <span class="keyword">import</span> mean_historical_return</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the annualized average historical return</span></span><br><span class="line">mean_returns = mean_historical_return(prices, frequency = <span class="number">252</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the annualized average historical return</span></span><br><span class="line">plt.plot(mean_returns, linestyle = <span class="string">'None'</span>, marker = <span class="string">'o'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/5.%20PyPortfolioOpt_return.svg" alt="PyPortfolioOpt_return"></p>
<h3 id="Practice-with-PyPortfolioOpt-covariance"><a href="#Practice-with-PyPortfolioOpt-covariance" class="headerlink" title="Practice with PyPortfolioOpt: covariance"></a>Practice with PyPortfolioOpt: covariance</h3><p>Portfolio optimization relies upon an unbiased and efficient estimate of asset covariance. Although sample covariance is unbiased, it is not efficient—extreme events tend to be overweighted.</p>
<p>One approach to alleviate this is through “covariance shrinkage”, where large errors are reduced (‘shrunk’) to improve efficiency. In this exercise, you’ll use <code>pypfopt.risk_models</code>‘s <code>CovarianceShrinkage</code> object to transform sample covariance into an efficient estimate. The textbook error shrinkage method, <code>.ledoit_wolf()</code>, is a method of this object.</p>
<p>Asset <code>prices</code> are available in your workspace. Note that although the <code>CovarianceShrinkage</code> object takes <code>prices</code> as input, it actually calculates the covariance matrix of asset <strong>returns</strong>, not prices.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the CovarianceShrinkage object</span></span><br><span class="line"><span class="keyword">from</span> pypfopt.risk_models <span class="keyword">import</span> CovarianceShrinkage</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the CovarianceShrinkage instance variable</span></span><br><span class="line">cs = CovarianceShrinkage(prices)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the sample covariance matrix of returns</span></span><br><span class="line">sample_cov = prices.pct_change().cov() * <span class="number">252</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the efficient covariance matrix of returns</span></span><br><span class="line">e_cov = cs.ledoit_wolf()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display both the sample covariance_matrix and the efficient e_cov estimate</span></span><br><span class="line">print(<span class="string">"Sample Covariance Matrix\n"</span>, sample_cov, <span class="string">"\n"</span>)</span><br><span class="line">print(<span class="string">"Efficient Covariance Matrix\n"</span>,e_cov, <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sample Covariance Matrix</span><br><span class="line">                 Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan</span><br><span class="line">Citibank        0.536214        0.305045       0.217993     0.269784</span><br><span class="line">Morgan Stanley  0.305045        0.491993       0.258625     0.218310</span><br><span class="line">Goldman Sachs   0.217993        0.258625       0.217686     0.170937</span><br><span class="line">J.P. Morgan     0.269784        0.218310       0.170937     0.264315 </span><br><span class="line"></span><br><span class="line">Efficient Covariance Matrix</span><br><span class="line">                 Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan</span><br><span class="line">Citibank        0.527505        0.288782       0.206371     0.255401</span><br><span class="line">Morgan Stanley  0.288782        0.485642       0.244837     0.206671</span><br><span class="line">Goldman Sachs   0.206371        0.244837       0.225959     0.161823</span><br><span class="line">J.P. Morgan     0.255401        0.206671       0.161823     0.270102</span><br></pre></td></tr></table></figure></p>
<h3 id="Breaking-down-the-financial-crisis"><a href="#Breaking-down-the-financial-crisis" class="headerlink" title="Breaking down the financial crisis"></a>Breaking down the financial crisis</h3><p>n the video you saw the efficient frontier for the portfolio of investment banks over the entire period <strong>2005 - 2010</strong>, which includes time before, during and after the global financial crisis.</p>
<p>Here you’ll break down this period into three sub-periods, or <code>epochs</code>: <strong>2005-2006</strong> (<em>before</em>), <strong>2007-2008</strong> (<em>during</em>) and <strong>2009-2010</strong> (<em>after</em>). For each period you’ll compute the efficient covariance matrix, and compare them to each other.</p>
<p>The portfolio’s <code>prices</code> for <strong>2005 - 2010</strong> are available in your workspace, as is the <code>CovarianceShrinkage</code> object from PyPortfolioOpt.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a dictionary of time periods (or 'epochs')</span></span><br><span class="line">epochs = &#123; <span class="string">'before'</span> : &#123;<span class="string">'start'</span>: <span class="string">'1-1-2005'</span>, <span class="string">'end'</span>: <span class="string">'31-12-2006'</span>&#125;,</span><br><span class="line">           <span class="string">'during'</span> : &#123;<span class="string">'start'</span>: <span class="string">'1-1-2007'</span>, <span class="string">'end'</span>: <span class="string">'31-12-2008'</span>&#125;,</span><br><span class="line">           <span class="string">'after'</span>  : &#123;<span class="string">'start'</span>: <span class="string">'1-1-2009'</span>, <span class="string">'end'</span>: <span class="string">'31-12-2010'</span>&#125;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the efficient covariance for each epoch</span></span><br><span class="line">e_cov = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> epochs.keys():</span><br><span class="line">  sub_price = prices.loc[epochs[x][<span class="string">'start'</span>]:epochs[x][<span class="string">'end'</span>]]</span><br><span class="line">  e_cov[x] = CovarianceShrinkage(sub_price).ledoit_wolf()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the efficient covariance matrices for all epochs</span></span><br><span class="line">print(<span class="string">"Efficient Covariance Matrices\n"</span>, e_cov)</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Efficient Covariance Matrices</span><br><span class="line"> &#123;&apos;before&apos;:                 Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan</span><br><span class="line">Citibank        0.018149        0.013789       0.013183     0.013523</span><br><span class="line">Morgan Stanley  0.013789        0.043021       0.030559     0.016525</span><br><span class="line">Goldman Sachs   0.013183        0.030559       0.044482     0.018237</span><br><span class="line">J.P. Morgan     0.013523        0.016525       0.018237     0.024182, &apos;during&apos;:                 Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan</span><br><span class="line">Citibank        0.713035        0.465336       0.323977     0.364848</span><br><span class="line">Morgan Stanley  0.465336        0.994390       0.434874     0.298613</span><br><span class="line">Goldman Sachs   0.323977        0.434874       0.408773     0.224668</span><br><span class="line">J.P. Morgan     0.364848        0.298613       0.224668     0.422516, &apos;after&apos;:                 Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan</span><br><span class="line">Citibank        0.841156        0.344939       0.252684     0.356788</span><br><span class="line">Morgan Stanley  0.344939        0.388839       0.231624     0.279727</span><br><span class="line">Goldman Sachs   0.252684        0.231624       0.244539     0.223740</span><br><span class="line">J.P. Morgan     0.356788        0.279727       0.223740     0.382494&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="The-efficient-frontier-and-the-financial-crisis"><a href="#The-efficient-frontier-and-the-financial-crisis" class="headerlink" title="The efficient frontier and the financial crisis"></a>The efficient frontier and the financial crisis</h3><p>Previously we examined the covariance matrix of the investment bank portfolio before, during and after the financial crisis. Now we will visualize the changes that took place in the efficient frontier, showing how the crisis created a much higher baseline risk for any given return.</p>
<p>Using the PyPortfolioOpt <code>pypfopt</code> library’s Critical Line Algorithm (<code>CLA</code>) object, we can derive and visualize the efficient frontier during the crisis period, and add it to a scatterplot already displaying the efficient frontiers before and after the crisis.</p>
<p>Expected returns <code>returns_during</code> and the efficient covariance matrix <code>ecov_during</code> are available, as is the <code>CLA</code> object from <code>pypfopt</code>. (Remember that DataCamp plots can be expanded to their own window, which can increase readability.)<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Initialize the Crtical Line Algorithm object</span></span><br><span class="line">efficient_portfolio_during = CLA(returns_during, ecov_during)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the minimum volatility portfolio weights and display them</span></span><br><span class="line">print(efficient_portfolio_during.min_volatility())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the efficient frontier</span></span><br><span class="line">(ret, vol, weights) = efficient_portfolio_during.efficient_frontier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the frontier to the plot showing the 'before' and 'after' frontiers</span></span><br><span class="line">plt.scatter(vol, ret, s = <span class="number">4</span>, c = <span class="string">'g'</span>, marker = <span class="string">'.'</span>, label = <span class="string">'During'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/risk%20management/6.%20The%20efficient%20frontier.svg" alt="The efficient frontier"></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Data &amp; AI</title>
    <url>/2020/11/26/Data-AI/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Unlock-Value-of-Disparate-and-Complex-Data"><a href="#Unlock-Value-of-Disparate-and-Complex-Data" class="headerlink" title="Unlock Value of Disparate and Complex Data"></a>Unlock Value of Disparate and Complex Data</h1><blockquote>
<p>Azure Databricks: <a href="https://www.youtube.com/watch?v=RatIt99GwRc" target="_blank" rel="noopener">Unlock Value of Disparate and Complex Data Powered by Azure Databricks Luke Pritchard Avanade, Inc</a></p>
</blockquote>
<h2 id="Vision-of-Avanade-Inc"><a href="#Vision-of-Avanade-Inc" class="headerlink" title="Vision of Avanade Inc."></a>Vision of Avanade Inc.</h2><p>To be the leading digital innovator realizing results for our clients through the power of people and the Microsoft ecosystem</p>
<h2 id="The-market-and-clients"><a href="#The-market-and-clients" class="headerlink" title="The market and clients"></a>The market and clients</h2><ul>
<li>Unlock the <strong>value of data at scale</strong></li>
<li>Get off <strong>restrictive legacy systems</strong> and create <strong>new business models</strong></li>
<li>Differentiate in the market</li>
</ul>
<h2 id="The-approach"><a href="#The-approach" class="headerlink" title="The approach"></a>The approach</h2><ol>
<li>Value and design led approach</li>
<li>Outcome-based experiments using fast flexible technology </li>
<li>Once value is proven, scale and industrialize</li>
<li>Continue to expand to multiple value</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">Database and Data Factory</th>
<th style="text-align:left">Data Engineering and Data Analytics</th>
<th style="text-align:left">Business Insight</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">System</td>
<td style="text-align:left">Azure SQL DB</td>
<td style="text-align:left">Azure Analysis Service</td>
<td style="text-align:left">Visualization</td>
</tr>
<tr>
<td style="text-align:left">Implementation</td>
<td style="text-align:left">Python, Databricks, Cloud</td>
<td style="text-align:left">Power BI, Excel</td>
<td style="text-align:left">PPT</td>
</tr>
</tbody>
</table>
</div>
<a id="more"></a>
<h1 id="The-real-impact-of-AI"><a href="#The-real-impact-of-AI" class="headerlink" title="The real impact of AI"></a>The real impact of AI</h1><h2 id="Define-AI"><a href="#Define-AI" class="headerlink" title="Define AI"></a>Define AI</h2><blockquote>
<p>Avanade: <a href="https://www.avanade.com/en/thinking/research-and-insights/artificial-intelligence-podcast" target="_blank" rel="noopener">The real impact of AI</a></p>
</blockquote>
<ul>
<li>Linguistic / Spacial intelligence — Natural Language Processing / Image Processing</li>
<li>Align with the existing workforce: separate skills and tasks, and work and tell what part is good for people to do, what is good for machine to do</li>
<li>Empower human to build their digital coworkers -&gt; People and robots work together</li>
</ul>
<p>Technologies are responsible for simple <strong>standardized</strong> problems (e.g. chatbot) -&gt; Humans are responsible for <strong>complex</strong> tasks</p>
<p>AI takes the job that people don’t want to do.</p>
<h2 id="Data-x-Power-x-Context-intelligence-driven-innovation"><a href="#Data-x-Power-x-Context-intelligence-driven-innovation" class="headerlink" title="Data x Power x Context = intelligence-driven innovation"></a>Data x Power x Context = intelligence-driven innovation</h2><p>Understanding data is more important than the data itself -&gt; So many factors (context) around -&gt; Understanding the context is a human skill</p>
<ul>
<li>There not a lot enormous brand-new technologies in the AI field today. (Neural Networks and some other algorithms have all been around since 90s) </li>
<li>The exponential curve of data being produced is the second half of the chess board</li>
<li>We are in the world where all the exciting algorithms need to be applied!</li>
</ul>
<p>Business practitioners are talking about the applications of advanced technologies.</p>
<p>Before we talk about technologies, data is a huge problem (quality!). And… IoT (sensors) data? </p>
<h2 id="The-reality-of-AI"><a href="#The-reality-of-AI" class="headerlink" title="The reality of AI"></a>The reality of AI</h2><p>Concerns:</p>
<ul>
<li><strong>Over-sale</strong> of AI?</li>
<li>Customer and employee experience and their <strong>confidence</strong></li>
<li>AI is taking jobs away? Technologies are doing robotic jobs and this is helping people as a <strong>digital coworker</strong>!</li>
</ul>
<p>Challenges:</p>
<ul>
<li>Technology fatigue, Necessity, Security</li>
<li>Can we apply it in a enterprise context? </li>
<li>Productivity of IT</li>
</ul>
<h2 id="AI-and-the-changing-role-of-the-CIO"><a href="#AI-and-the-changing-role-of-the-CIO" class="headerlink" title="AI and the changing role of the CIO"></a>AI and the changing role of the CIO</h2><ul>
<li>Integrate IT Infrastructure with Business Operations</li>
<li>Maslow’s Hierarchy of Needs</li>
</ul>
<h2 id="AI-and-HR"><a href="#AI-and-HR" class="headerlink" title="AI and HR"></a>AI and HR</h2><ul>
<li>Measure work, productivity and recruitment</li>
<li>Automation of the first step and to focus more on understanding the candidates</li>
</ul>
<h2 id="The-real-impact-of-AI-on-jobs"><a href="#The-real-impact-of-AI-on-jobs" class="headerlink" title="The real impact of AI on jobs"></a>The real impact of AI on jobs</h2><p>Human do things that machines can’t do</p>
<h2 id="The-augumented-human"><a href="#The-augumented-human" class="headerlink" title="The augumented human"></a>The augumented human</h2><p>How to use technology in a reasonable way?</p>
<ul>
<li>Robotic process and automation.</li>
<li>Digital workers rather than robots. They are a part of the workforce and also the coworker of people.</li>
<li>AI is enhancing what people are doing</li>
</ul>
<h2 id="The-rules-of-engagements"><a href="#The-rules-of-engagements" class="headerlink" title="The rules of engagements"></a>The rules of engagements</h2><ol>
<li>Ethicness (addictiveness of mobile phone, opaqueness of algorithms)</li>
<li>Bias and testing — How to validate the dicisions made by machine (give the reason)</li>
</ol>
<h1 id="Microsoft-Azure-Ecosystem"><a href="#Microsoft-Azure-Ecosystem" class="headerlink" title="Microsoft Azure Ecosystem"></a>Microsoft Azure Ecosystem</h1><blockquote>
<p>Microsoft Azure - Products:<br><a href="https://azure.microsoft.com/en-us/overview/ai-platform/" target="_blank" rel="noopener">AI + Machine Learning</a><br><a href="https://azure.microsoft.com/en-us/product-categories/iot/" target="_blank" rel="noopener">IoT</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Tech</category>
      </categories>
  </entry>
  <entry>
    <title>Digital Marketing 2/2 - Inbounding Marketing</title>
    <url>/2020/11/25/Digital-Marketing-2-2-Inbounding-Marketing/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Inbound-Marketing"><a href="#Inbound-Marketing" class="headerlink" title="Inbound Marketing"></a>Inbound Marketing</h1><p>Inbound marketing position the company as a target that consumers are searching for.</p>
<p>Why Inbound Marketing:</p>
<ol>
<li>the diminished influence of advertising</li>
<li>the rise of consumer search</li>
</ol>
<p>Inbound marketing is a way to <strong>engage consumers</strong> by creating content, including blogs, podcasts, white papers, and search engine optimization (SEO), so that a company - its brand, products, and services - <strong>is found when consumers search for information</strong>.</p>
<a id="more"></a>
<h2 id="Getting-Found"><a href="#Getting-Found" class="headerlink" title="Getting Found"></a>Getting Found</h2><p>Achine higher ranking in search engines - How google works?</p>
<ol>
<li>Index page on the internet</li>
<li>Ranks web pages on the bases of relavence</li>
</ol>
<p>Two key factors for ranking:</p>
<ol>
<li><strong>Relevance</strong>: Match with consumer’s search query</li>
<li><strong>Authority</strong>: The number of web pages that link to it</li>
</ol>
<p>Two kay actions for inbound marketing:</p>
<ol>
<li>Ensure its website has the content, keywords, and meta tags that improves its relevance to a particular search query.</li>
<li>Find ways to garner inbound links from other websites to build its autority.</li>
</ol>
<h2 id="Creating-Content"><a href="#Creating-Content" class="headerlink" title="Creating Content"></a>Creating Content</h2><p>Goals and solution:</p>
<ol>
<li>Answer consumers’ questions and needs beyond basic product information -&gt; <strong>Customer-centric view</strong> of the world</li>
<li>Create Trustworthy, original, and interesting content that improves its authority -&gt; Create <strong>original contents</strong> that encourages other websites to provide links to it</li>
</ol>
<h2 id="Optimizing-Land-Page"><a href="#Optimizing-Land-Page" class="headerlink" title="Optimizing Land Page"></a>Optimizing Land Page</h2><p>User experience (Design: colors, button shapes, position, wording, fonts, images, and logos)</p>
<p>Also need to consider devices (mobile-first mentality for website design)</p>
<h1 id="Social-Media"><a href="#Social-Media" class="headerlink" title="Social Media"></a>Social Media</h1><ol>
<li>Listening to social conversations</li>
<li>Paticipating in social discussions</li>
<li>Leveraging and amplifying messages</li>
<li>Measuring social media effectiveness</li>
<li>Managing the impact of social media</li>
</ol>
<h1 id="Mobile-Technology"><a href="#Mobile-Technology" class="headerlink" title="Mobile Technology"></a>Mobile Technology</h1><ol>
<li>The size matters. Smaller screen -&gt; less long-period reading.Mobile devices are most suitable for <strong>visually rich content</strong>, such as video, maps, video, and games.</li>
<li><strong>Location infromation</strong> provided by mobile devices</li>
<li>Easy access to <strong>competitors’ prices</strong>. Customers may look up for prices online when they shop offline</li>
<li><strong>Apps</strong> instead of browsing the internet</li>
</ol>
<h1 id="Key-Terms"><a href="#Key-Terms" class="headerlink" title="Key Terms"></a>Key Terms</h1><h2 id="A-B-testing"><a href="#A-B-testing" class="headerlink" title="A/B testing"></a>A/B testing</h2><p>Experiments in which the impact of single variable is tested. A/B tests are commonly used to test ad copy and landing page copy or designs to determine which version better drives the desired result.</p>
<h2 id="click-through-rate-CTR"><a href="#click-through-rate-CTR" class="headerlink" title="click-through rate (CTR)"></a>click-through rate (CTR)</h2><p>Click-through is the process of clicking through an online advertisement to the advertiser’s destination. Click-through rate (CTR) is the average number of click-throughs per hundred ad impressions, expressed as a percentage. The CTR is a way of measuring the success of an online advertising campaign for a particular website as well as the effectiveness of an email campaign.</p>
<h2 id="content-curation-website"><a href="#content-curation-website" class="headerlink" title="content-curation website"></a>content-curation website</h2><p>A type of website that supports the gathering, organizing, and online presentation of content related to a particular theme or topic. For most companies, content curation is being used to drive search engine optimization (SEO). A company that links multiple pieces of content about a specific subject increases its exposure when that topic is searched. A particularly collaborative subtype of content curation is called social curation.</p>
<h2 id="content-sharing-website"><a href="#content-sharing-website" class="headerlink" title="content-sharing website"></a>content-sharing website</h2><p>A type of website that supports the posting or publishing of a user’s own material (content). Content sharing can be used as a way to target an audience with a specific niche interest or professional expertise.</p>
<h2 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h2><p>Information stored on a computer by a website that remembers user’s preferences. Cookies enable marketers to customize web pages for identified users, but privacy advocates raise concerns about tracking cookies that compile long-term records of individuals’ browsing histories.</p>
<h2 id="cost-per-click-CPC"><a href="#cost-per-click-CPC" class="headerlink" title="cost per click (CPC)"></a>cost per click (CPC)</h2><p>An Internet advertising metric that can be defined simply as “the amount spent to get an advertisement clicked.” Cost per click is used as a billing mechanism in the pay-per-click advertising model.</p>
<h2 id="customer-lifetime-value-CLV"><a href="#customer-lifetime-value-CLV" class="headerlink" title="customer lifetime value (CLV)"></a>customer lifetime value (CLV)</h2><p>The dollar value of a customer relationship, based on the present value (PV) of the projected future cash flows from the customer relationship. It represents an upper limit on spending to acquire new customers.</p>
<h2 id="display-ad"><a href="#display-ad" class="headerlink" title="display ad"></a>display ad</h2><p>Graphic advertising on the Internet that appears next to content on web pages, instant messaging (IM) applications, email, and so forth. These ads come in standardized ad sizes and can include text, logos, pictures, or, more recently, rich media (videos).</p>
<h2 id="earned-media"><a href="#earned-media" class="headerlink" title="earned media"></a>earned media</h2><p>Media spread when customers, the press, and the public share a company’s content or discuss a company’s brand through word of mouth. It is stimulated by viral and social media marketing.</p>
<h2 id="going-viral"><a href="#going-viral" class="headerlink" title="going viral"></a>going viral</h2><p>The rapid spread of a popular image, video, or link through a population by its being frequently shared with a number of individuals through electronic mail and social networking sites. Virality refers to the degree to which a piece of Internet content has been or might be shared in a short amount of time. Viral marketing refers to a marketing approach that facilitates and encourages people to pass along a marketing message.</p>
<h2 id="impression"><a href="#impression" class="headerlink" title="impression"></a>impression</h2><p>A single instance of an online advertisement being displayed. Many websites sell advertising space by the number of impressions displayed to users. Also known as view.</p>
<h2 id="micro-moments"><a href="#micro-moments" class="headerlink" title="micro moments"></a>micro moments</h2><p>Google coined this term to describe an intent-rich moment when a person turns to a device to act on a need—to know, go, do, or buy. This identifies moments of decision making, often in just a few seconds, throughout the consumer journey (e.g., a search such as “find a restaurant near me”).</p>
<h2 id="mobile-technologies"><a href="#mobile-technologies" class="headerlink" title="mobile technologies"></a>mobile technologies</h2><p>Technologies that are not desktop/laptop based, such as web-enabled phones, smartphones, tablets, wearable technology (e.g., Google Glass and smart watches), and hybrid devices (e.g., phablets).</p>
<h2 id="moment-based-marketing-or-moment-marketing"><a href="#moment-based-marketing-or-moment-marketing" class="headerlink" title="moment-based marketing (or moment marketing)"></a>moment-based marketing (or moment marketing)</h2><p>The strategy of sending appropriate ads or messages at the moment when the consumer is about to make a decision about a relevant product or service. For example, some airlines include ads for Uber in their mobile boarding passes.</p>
<h2 id="offline-conversions"><a href="#offline-conversions" class="headerlink" title="offline conversions"></a>offline conversions</h2><p>A metric that tracks the transactions that occur in a physical business or retail location, and in other offline channels (e.g., phone orders), after a customer sees or engages with offline or online campaigns.</p>
<h2 id="owned-media"><a href="#owned-media" class="headerlink" title="owned media"></a>owned media</h2><p>Media or channels created and controlled by the brand, such as its websites, blogs, and mobile apps, or its social presence on Facebook, LinkedIn, or Twitter.</p>
<h2 id="paid-media"><a href="#paid-media" class="headerlink" title="paid media"></a>paid media</h2><p>The media for which a company pays an online search engine or publisher to attract potential customers.</p>
<h2 id="perceptual-map"><a href="#perceptual-map" class="headerlink" title="perceptual map"></a>perceptual map</h2><p>A map that shows consumers’ perception of various brands. Brands that are close to each other in this map are pereceived by consumers as substitutes for one another, and therefore these brands compete more intensly with each other.</p>
<h2 id="review-website"><a href="#review-website" class="headerlink" title="review website"></a>review website</h2><p>A website on which reviews and ratings can be posted about people, businesses, products, or services by either website users or writers employed by the website.</p>
<h2 id="search-ad"><a href="#search-ad" class="headerlink" title="search ad"></a>search ad</h2><p>A type of contextual advertising through which website owners pay an advertising fee, usually based on click-through rate or ad views, to have their ad shown on search result pages.</p>
<h2 id="search-engine-optimization-SEO"><a href="#search-engine-optimization-SEO" class="headerlink" title="search engine optimization (SEO)"></a>search engine optimization (SEO)</h2><p>The process of using features that make a company website rank higher in the organic link on a search engine without paying any money.</p>
<h2 id="search-engines"><a href="#search-engines" class="headerlink" title="search engines"></a>search engines</h2><p>Programs that search the web for documents containing specified keywords and return a list of findings. A search engine is really a general class of programs; however, the term is often used to describe specific systems such as Google, Bing, and Yahoo!</p>
<h2 id="tags"><a href="#tags" class="headerlink" title="tags"></a>tags</h2><p>Labels or categories that describe the content of a website, bookmark, photo, or blog post. Tags provide a useful way of organizing, retrieving, and discovering information.</p>
<h2 id="test-control-methodology"><a href="#test-control-methodology" class="headerlink" title="test-control methodology"></a>test-control methodology</h2><p>A controlled experiment in which subjects are randomized into either test or control groups.</p>
<h2 id="word-of-mouth-marketing"><a href="#word-of-mouth-marketing" class="headerlink" title="word-of-mouth marketing"></a>word-of-mouth marketing</h2><p>A marketing method that relies on consumers spreading information about a product or service.</p>
]]></content>
      <categories>
        <category>Business</category>
      </categories>
  </entry>
  <entry>
    <title>Digital Marketing 1/2 - Outbound Marketing</title>
    <url>/2020/10/30/Digital-Marketing-1-2-Outbounding-Marketing/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>Harvard Business Review </p>
</blockquote>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>How do new entrants in consumer product industry rise?</p>
<ul>
<li>Distribution</li>
<li>Advertising</li>
</ul>
<p>Digital technologies like <strong>digital cookies</strong>, <strong>content-curation websites</strong> (Reddit, BuzzFeed) and <strong>content-sharing websites</strong> (Slideshare, LinkedIn, Medium) lead to a new level of self-expression of individuals. Thus companies can better understand customers’ decision journey and subsequent word-of-mouth.</p>
<p>Digital Marketing landscape:</p>
<ul>
<li>Paid Media: TV commercial and Google Ads</li>
<li>Owned Media: Official Websites</li>
<li>Earned Media: Influncial customers, word-of-mounth</li>
<li>Review Websites: Lyft…</li>
</ul>
<p>Digital Marketing Framework:</p>
<ul>
<li><strong>Outbound Marketing</strong>: company -&gt; customer —&gt; Search Enginee Maerketing (SEM)</li>
<li><strong>Inbound Markeying</strong>: customer -&gt; product and service —&gt; Search Enginee Optimization (SEO)</li>
<li><strong>Social Media</strong>: customers create contents</li>
<li><strong>Mobile Technology</strong>: the way customers search for and biut products and services</li>
</ul>
<a id="more"></a>
<h1 id="Outbound-Marketing"><a href="#Outbound-Marketing" class="headerlink" title="Outbound Marketing"></a>Outbound Marketing</h1><h2 id="Search-Ads"><a href="#Search-Ads" class="headerlink" title="Search Ads"></a>Search Ads</h2><p><strong>Search Enginee Maerketing (SEM)</strong> - To create search advertisement:</p>
<ol>
<li>Keywords: what keywords? How much to bid per keyword? Total budgeting?</li>
<li>Design Search Ads</li>
<li>Rank higher in the result page</li>
<li>Prepare land page</li>
</ol>
<h3 id="Buying-Keywords"><a href="#Buying-Keywords" class="headerlink" title="Buying Keywords"></a>Buying Keywords</h3><ul>
<li>The Same Theme</li>
<li>Different Demographic (Languages)</li>
<li>Misspellings and Typos</li>
<li>Rule out negative/unrealated words</li>
</ul>
<h3 id="Branded-Keywords"><a href="#Branded-Keywords" class="headerlink" title="Branded Keywords"></a>Branded Keywords</h3><p>Bid on one’s own brand - to defend against competitors</p>
<h3 id="Generic-Keywords"><a href="#Generic-Keywords" class="headerlink" title="Generic Keywords"></a>Generic Keywords</h3><p>generic and category keywords </p>
<h3 id="Paying-for-keywords"><a href="#Paying-for-keywords" class="headerlink" title="Paying for keywords"></a>Paying for keywords</h3><p>Golden Triangle - Upper left</p>
<h4 id="Cost-Per-Click-CPC-bid"><a href="#Cost-Per-Click-CPC-bid" class="headerlink" title="Cost-Per-Click (CPC) bid"></a>Cost-Per-Click (CPC) bid</h4><blockquote>
<p>Google uses the “generalized second-price auction”, which is based on the extension of the Nobel-prize winning research of Willian Vickery, where the highest bidder get the first ad position but pays the bid amount of the second bidder, who in turn get the second place but pays the bid amount of the third-highest bidder, and so on. Research shows that this mechanism leads to “truth telling” whereby advertisers bid the maximum amount on the basis of their own willingness to pay.</p>
</blockquote>
<ol>
<li><strong>The top position != The most profitable</strong></li>
<li>CTR descrease with a lower position, but the conversion rate may increase because consumers who click on links at lower positions implicitly express higher interest in those companies.</li>
<li><strong>Continuous testing, measurement, and analytics</strong> -&gt; find the best position </li>
</ol>
<h4 id="Quality-Score"><a href="#Quality-Score" class="headerlink" title="Quality Score"></a>Quality Score</h4><p>Factors:</p>
<ol>
<li>Potential CTR of an ad</li>
<li>Relevence to consumers</li>
<li>Quality of the landing page</li>
</ol>
<h3 id="Assesing-the-Effectiveness"><a href="#Assesing-the-Effectiveness" class="headerlink" title="Assesing the Effectiveness"></a>Assesing the Effectiveness</h3><p>Matrics used for search ads:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Site</th>
<th style="text-align:center">Media</th>
<th style="text-align:center">Impressions</th>
<th style="text-align:center">Clicks</th>
<th style="text-align:center">Applications Completed</th>
<th style="text-align:center">Click-Through Rate (CTR)</th>
<th style="text-align:center">Conversion Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Google</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
</tr>
<tr>
<td style="text-align:center">MSN</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
</tr>
<tr>
<td style="text-align:center">SuperPages</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
</tr>
<tr>
<td style="text-align:center">Yahoo</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
</tr>
<tr>
<td style="text-align:center">Unified Marktplace</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
</tr>
<tr>
<td style="text-align:center">Total</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
<td style="text-align:center">.</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li>[Brand Awareness] <strong>Impressions (Impr.)</strong>: Each time your ad shows on a search results page or other site on the Google Network, an impression is counted. Impressions are most important if your goal is to raise brand awareness.</li>
<li><strong>Clicks</strong>: When someone clicks your ad, a click is counted. Clicks can help you understand how well your ad appeals to people who see it. Relevant ads are more likely to receive clicks.</li>
<li>[Traffic] <strong>Click-through Rate (CTR)</strong>: <code>CTR=Click/Impression</code>(Impression: # of times seen by consumers)</li>
<li><strong>Convertion Rate</strong>: <code>Convertion Rate = Applicationc Completed / Click</code> </li>
<li><strong>Cost per Click (CPC)</strong>: <code>CPC = ost / Click</code></li>
<li><strong>Search Ad Profit</strong> = <code>(impressions x click-through-rate x conversion rate x margin) - search ad cost</code></li>
<li>[ROI] <strong>Return of Investment (ROI)</strong>: <code>ROI = Profit / Cost</code><br>Supplemental Reading: <a href="https://support.google.com/google-ads/answer/9451527?hl=en&amp;ref_topic=3121936" target="_blank" rel="noopener">Use data to optimize your search campaigns</a></li>
</ol>
<h2 id="Display-Ads"><a href="#Display-Ads" class="headerlink" title="Display Ads"></a>Display Ads</h2><ol>
<li><strong>Banner Ads</strong></li>
<li><strong>Insertitial Ads</strong>: capture greater user attention but also more intrusive</li>
<li><strong>Expandable Ads</strong>: banner ads that automatically expand to a large portion</li>
</ol>
<p>Impact: Bannner &lt; Expandable &lt; Insertial</p>
<h3 id="Display-Ads-Industry"><a href="#Display-Ads-Industry" class="headerlink" title="Display Ads Industry"></a>Display Ads Industry</h3><ol>
<li><strong>Content Publishers</strong>: e.g. New York Times, small blogs</li>
<li><strong>Ad Networks</strong>: e.g. AdSense by Google (aggregate supply on multiple advertising space and optimally place ads on various websites)</li>
<li><strong>Ad Exchange</strong>: e.g. Rubicon (automate the matching between advertiser and publishers i.e. a programming buying using real-time biding ~ “RTB”) </li>
</ol>
<h3 id="Assessing-the-Effectiveness-of-Displayed-Ads"><a href="#Assessing-the-Effectiveness-of-Displayed-Ads" class="headerlink" title="Assessing the Effectiveness of Displayed Ads"></a>Assessing the Effectiveness of Displayed Ads</h3><p>2 ways to buy displayed ads:</p>
<ol>
<li>Based on <strong>Impressions</strong>, using the Cost Per Thousand Impressions (CPM) matric. The Goal is to <strong><em>build brand awareness or brand image</em></strong></li>
<li>Based on <strong>Clicks</strong>. The goal is to <strong><em>maximize clicks and conversion rates</em></strong>.</li>
</ol>
<p>Measurements:<br>Same as search ads, CTR and Conversion Rate</p>
<ol>
<li>CPM display ad profit = impressions <em> [(click-through-rate </em> conversion rate * margin) - cost per thousand impressions or CPM/1000]</li>
<li>CPC display ad profit = impressions * click-through-rate x [(conversion rate x margin) - cost per click] …Facebook</li>
</ol>
<h2 id="Video-Ads"><a href="#Video-Ads" class="headerlink" title="Video Ads"></a>Video Ads</h2><ol>
<li>Digital platforms like Youtube or Facebook</li>
<li>Smart TV and streaming devices like Hulu</li>
</ol>
<p>Formats on Youtube:</p>
<ol>
<li>Skippable in-stream ad: before/during/after the main video</li>
<li>Non-skippable in-stream ad: 15-20 seconds</li>
<li>Bumper ad: non-skippable, 6 seconds</li>
</ol>
<h3 id="Measure-the-effectiveness"><a href="#Measure-the-effectiveness" class="headerlink" title="Measure the effectiveness"></a>Measure the effectiveness</h3><p>CPM<br>Social Shares (only on digital platform)<br>Post-view engagement (only on digital platform)<br>Impressions<br>Completed views<br>Sales !!!</p>
<h2 id="Measuring-the-Effectiveness-of-Outbound-Marketing"><a href="#Measuring-the-Effectiveness-of-Outbound-Marketing" class="headerlink" title="Measuring the Effectiveness of Outbound Marketing"></a>Measuring the Effectiveness of Outbound Marketing</h2><h3 id="Correlations-versus-Causation"><a href="#Correlations-versus-Causation" class="headerlink" title="Correlations versus Causation"></a>Correlations versus Causation</h3><ul>
<li>Online advertising <strong><em>cause</em></strong> an increase in sales?</li>
<li><strong><em>Corellate</em></strong> clicks and sales?<br>Too mant factors -&gt; Need experiments </li>
</ul>
<h3 id="Attribution"><a href="#Attribution" class="headerlink" title="Attribution"></a>Attribution</h3><p>Influnce in different stages of a purchase decision<br><img src="https://2.bp.blogspot.com/--vU0x_9IAOU/UXjbWXIZ9-I/AAAAAAAABaA/6UnslTQ7B1E/s1600/BLOG_POST_Channels_US.png" alt="Google"><br>Source: <a href="https://adwords.googleblog.com/2013/04/the-customer-journey-to-online-purchase.html" target="_blank" rel="noopener">Google Adwords</a><br>Advertising channels (like display ads and search ads) do not work in isolation. The attribution model need to take their interaction into account.</p>
<p>Extented reading of models: <a href="https://support.google.com/analytics/answer/1662518?hl=en" target="_blank" rel="noopener">Google Analytics</a></p>
<h3 id="Dynamics-Delayed-Impact-of-Advertising"><a href="#Dynamics-Delayed-Impact-of-Advertising" class="headerlink" title="Dynamics (Delayed Impact of Advertising)"></a>Dynamics (Delayed Impact of Advertising)</h3><p>How to measure long-term effects?<br>Factors change over time<br>Ignoring dynamic or long term effects -&gt; <strong>Underestimate ROI</strong> by up to 40%<br>Dynamic effects are stronger for <strong>search ads</strong> than display ads</p>
<h3 id="Online-Offline-Interation"><a href="#Online-Offline-Interation" class="headerlink" title="Online-Offline Interation"></a>Online-Offline Interation</h3><p>Key challenges:</p>
<ol>
<li><strong>Interation or potential synergy between online and offline marketing</strong>: Costomer base purchase dicsions on both online and offline information. Offline shopping -&gt; personal fit and real-life experience.</li>
<li><strong>Assessing the impact of online marketing on offline marketing and vice versa</strong> (also called <em>omnichannel shopping</em>)</li>
</ol>
<p>Need to plan together!</p>
<h3 id="Omnichannel-Shopping"><a href="#Omnichannel-Shopping" class="headerlink" title="Omnichannel Shopping"></a>Omnichannel Shopping</h3><p>Different distribution channels (retailers)<br>Online ads -&gt; offline shopping</p>
<h3 id="Customer-Lifetime-Value"><a href="#Customer-Lifetime-Value" class="headerlink" title="Customer Lifetime Value"></a>Customer Lifetime Value</h3><p>CTR (click-through-rate) and CPI (cost per install)?<br>-&gt; <strong>Long-term paying customers</strong>?</p>
<p>Online customers are more price sensitive and like to shop around -&gt; lower retention rate -&gt; lower CLV </p>
<p>Focus on the <strong>CLV (customer life value)</strong> to evaluate the effetiveness of digital campaigns, and change the budget allocation to various advertising channels.</p>
]]></content>
      <categories>
        <category>Business</category>
      </categories>
  </entry>
  <entry>
    <title>Leadership Reflections </title>
    <url>/2020/09/20/Leadership-Reflections/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Customer-facing mission and vision bring effectiveness to the leadership. During our class of Leadeship, we learnt about the Five Questions Plan for businesses. </p>
<blockquote>
<ol>
<li>What is our mission?</li>
<li>Who is our customer?</li>
<li>What does the customer value?</li>
<li>What are our results?</li>
<li>What is our plan?</li>
</ol>
</blockquote>
<p>I consider identifying customers and their needs the most important. </p>
<a id="more"></a>
<p>I am recently watching a TV series called “Silicon Valley”. It’s a parody of Silicon Valley culture, focusing on Richard Hendricks, a programmer who founded a startup company based on his algorithm, and his struggles trying to run his company. One impressive clip is the new CEO Jack Barker, who replaced Richard, argued: “Sales and engineering are the two pillars of the Conjoined Triangles of Success. Engineering and sales must work together to decide what to build.”. This is very true. Without input from customers, Richard and his engineering colleagues produced a very “engineered” product. The technology is fantastic and brings breakthroughs to the industry. But customers don’t buy it. Normal people can’t understand how it works, because the product’s novelty exceeded their common sense. Terrible user experiences can never maintain users.</p>
<p>According to our courses and what I have seen from Silicon Valley, I am more aware that I should value customer needs as our mission and thus make our strategy effective and efficient. I am going to start interviews for my capstone project next week. We have a good vision of automating officers’ daily work by a virtual assistant on our software. But the first step should be understanding officers’ work and finding what they value most from our product. </p>
]]></content>
      <categories>
        <category>Reflections</category>
      </categories>
  </entry>
  <entry>
    <title>KPI and Matrix</title>
    <url>/2020/09/09/KPI-and-Matrix/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="General-mobile-app-KPIs"><a href="#General-mobile-app-KPIs" class="headerlink" title="General mobile app KPIs"></a>General mobile app KPIs</h1><ul>
<li>User engagement KPIs</li>
<li>Revenue KPIs</li>
<li>UX KPIs</li>
<li>Marketing KPIs</li>
<li>App store category ranking</li>
</ul>
<p>While all six categories are important, you first need to establish the most relevant KPIs and then focus on tracking them. Below are the top three indicators to look for in each category.</p>
 <a id="more"></a>
<h2 id="General-mobile-app-KPIs-1"><a href="#General-mobile-app-KPIs-1" class="headerlink" title="General mobile app KPIs"></a>General mobile app KPIs</h2><p>Most people working on the app development team can track these general mobile KPIs. However, how much emphasis to put on each KPI depends on the product so it may vary from one mobile app to another. These indicators are:</p>
<h3 id="Mobile-downloads"><a href="#Mobile-downloads" class="headerlink" title="Mobile downloads"></a>Mobile downloads</h3><p>The most obvious measurement of success for an app entrepreneur is the number of downloads over a given period. An example of this would be a million users over a two-year span after launch. This KPI measures the app’s popularity.</p>
<p>The interpretation of the figures might vary from one product to another. For example, one person may consider attracting a million app users over the course of a year to be a success while others may think that’s too slow. Whatever the case, the number of mobile downloads will point you to the areas for improvements, such as UX, or bigger marketing budgets.</p>
<h3 id="Subscriptions"><a href="#Subscriptions" class="headerlink" title="Subscriptions"></a>Subscriptions</h3><p>If one of the features you offer is content or upgrades subscription, then you should track the number of subscription signups. Unsubscribing helps you monitor the features to be updated or find out about errors that you may not have noticed before. It tells how people find the price/value ratio of the subscription. You can also monitor how long it takes for a person to subscribe after installing your app.</p>
<h3 id="Upgrades"><a href="#Upgrades" class="headerlink" title="Upgrades"></a>Upgrades</h3><p>If you offer basic and premium versions of your mobile app, then this KPI comes in handy. You need to track the number of people who use the premium version, what percentage of the total they constitute, how long it takes for users to upgrade as well as whether the paid versions get higher ratings than the basic ones. This will help you evaluate whether you have a successful app or not.</p>
<p>Get a free consultation<br>Would you like to better understand how you can improve the performance of your mobile application? We can set up a quick call with one of our experts who can get you started.We will call you back.<br>Your Name (required)</p>
<h3 id="Growth-rate"><a href="#Growth-rate" class="headerlink" title="Growth rate"></a>Growth rate</h3><p>You need to know how your base is growing, and whether it is a steady or a spiky growth. For example, does it spike during certain events such as following updates or advertisements, or is the growth slow but steady?</p>
<h2 id="User-Engagement-KPIs"><a href="#User-Engagement-KPIs" class="headerlink" title="User Engagement KPIs"></a>User Engagement KPIs</h2><p>Another KPI involves measuring engagement. This requires answering questions such as when, how, and where they engage with your product and collect details about it.</p>
<h3 id="Retention-rate"><a href="#Retention-rate" class="headerlink" title="Retention rate"></a>Retention rate</h3><p>Your retention rate is the number those who return to your app after a specified period. How long does it take for a person to come back? The concept behind this is that if you create a valuable product, people tend to come back to it.</p>
<p>The monitoring process might help create ideas on how to grow the product. As a general formula, you can calculate the retention rate with the formula below:</p>
<p>Retention Rate = ((CE — CN) / CS)) X 100</p>
<p>Where:</p>
<p>CE = number of customers at the end of a period</p>
<p>CN = number of new customers acquired during a given period</p>
<p>CS = number of customers at the beginning of a period</p>
<h3 id="Sessions-App-Open-Rate"><a href="#Sessions-App-Open-Rate" class="headerlink" title="Sessions (App Open Rate)"></a>Sessions (App Open Rate)</h3><p>Sessions measures how many times someone opened the app and indicates its popularity. Keep in mind that in digital analytics, a session is when a person or device-specific group of interactions that occur within a given period. Of course, it’s important to define what a session means for your app before you start counting.</p>
<h3 id="Daily-active-users"><a href="#Daily-active-users" class="headerlink" title="Daily active users"></a>Daily active users</h3><p>One of the ways to predict a successful app’s future growth is to calculate the number of daily active users. A DAU is a person who created an account and logged in for any interaction. Web and mobile app businesses typically consider DAU as their primary measure of growth and engagement in successful apps.</p>
<h3 id="Churn-rate"><a href="#Churn-rate" class="headerlink" title="Churn rate"></a>Churn rate</h3><p>Despite its negative effect, measuring the rate at which people unsubscribe from or uninstall your product will help you improve it. The most common reasons might be the lack of updates or of new content, crash issues as well as general functionality problems. Finding out at what point a person has unsubscribed or uninstalled your app might give you an idea of how to make it better.</p>
<h2 id="Revenue-KPIs"><a href="#Revenue-KPIs" class="headerlink" title="Revenue KPIs"></a>Revenue KPIs</h2><p>An app is not only built with end-users in mind, but it is also built with money in mind. Therefore, you can measure how your application generates money in the following ways:</p>
<h3 id="Average-revenue-per-user-ARPU"><a href="#Average-revenue-per-user-ARPU" class="headerlink" title="Average revenue per user (ARPU)"></a>Average revenue per user (ARPU)</h3><p>There are very many forms of monetization such as paid downloads, ad impressions or clicks, in-app purchases as well as subscriptions. The average amount of money or value generated per person multiplied by the size of the total base, could give you a rough idea of your product’s monetary value.</p>
<h3 id="Customer-acquisition-cost-CAC"><a href="#Customer-acquisition-cost-CAC" class="headerlink" title="Customer acquisition cost (CAC)"></a>Customer acquisition cost (CAC)</h3><p>Customers come at a cost. This might be the cost of advertising, labor as well as other resources. The costs can be determined by dividing the gross revenue by the cost of advertisement and other related costs.</p>
<h3 id="Customer-lifetime-value-CLC"><a href="#Customer-lifetime-value-CLC" class="headerlink" title="Customer lifetime value (CLC)"></a>Customer lifetime value (CLC)</h3><p>This measures the net profit customers generate, which includes customers in and on the platform in ratio to the cost of acquiring them. The most successful apps tend to have a higher CLC to CAC ratio.</p>
<p>A general formula for calculating CLC is as follows:</p>
<p>Avg value of a conversion x avg # of conversions in a time frame x avg customer lifetime.</p>
<h3 id="Return-on-investment-ROI"><a href="#Return-on-investment-ROI" class="headerlink" title="Return on investment (ROI)"></a>Return on investment (ROI)</h3><p>When you spend money and other resources on the app, such as paid ads you expect to make profits out of it. Therefore, return on investment is measured by dividing the number of gains in customers or revenue that you have generated by how much you have spent on marketing, including the time spent or any other expenses incurred.</p>
<p>In simple terms:</p>
<p>(Gain from Investment — Cost of Investment) / Cost of Investment</p>
<h2 id="UX-KPIs"><a href="#UX-KPIs" class="headerlink" title="UX KPIs"></a>UX KPIs</h2><p>No matter how good you think your app is, the UX wraps it all up. It’s good to remember that you do not create the app for yourself but for other people. Therefore, you should track and measure user experience in order to know the areas that require improvement.</p>
<p>This can be done by measuring the following elements:</p>
<h3 id="Load-time"><a href="#Load-time" class="headerlink" title="Load time"></a>Load time</h3><p>Isn’t it annoying when you wait for an app to load? Fast loading speed is key to keeping people’s attention. Some people uninstall an app not because it lacks the features they need, but because they consider it unusable. This is often a symptom of slow loading speeds.</p>
<p>This includes the transition times from one activity to another within your mobile app. Build the fastest app possible if you want to see app success.</p>
<h3 id="Devices"><a href="#Devices" class="headerlink" title="Devices"></a>Devices</h3><p>How do people access your app? Which devices do they use: phones, tablets, or laptops? Knowing which devices your customers use to access the app will help you target and improve on the app’s performance.</p>
<h3 id="Operating-system"><a href="#Operating-system" class="headerlink" title="Operating system"></a>Operating system</h3><p>Your app should be able to work both on Android and iOS. However, if either of them has a high crash rate or high uninstall rate, then you should look into the reasons behind the situation as well as work on a remedy for it.</p>
<p>A successful mobile app should have a balance between Android and iOS users. If it tends to attract one type over others, you should look into why this is so. This could signal that the experience on one operating system is not performing correctly and you’ll have to fix it.</p>
<h2 id="Mobile-App-Marketing-KPIs"><a href="#Mobile-App-Marketing-KPIs" class="headerlink" title="Mobile App Marketing KPIs"></a>Mobile App Marketing KPIs</h2><p>There are many effective ways to market your app. Measuring how effective a chosen method is, will help you establish the driving force for the downloads and in result focus on it and maybe get rid of the ones that do not bring in more users.</p>
<p>You can, therefore, monitor your app store analytics. Some of the best KPIs in this area include:</p>
<h3 id="Install-source"><a href="#Install-source" class="headerlink" title="Install source"></a>Install source</h3><p>Where did your customers find your app in order to install it? This knowledge is essential and can become a driving force for your campaign. Which sources attract more people to download your app?</p>
<p>Which sources have better performance and which poor? Are they paid or organic? Such information will allow you to focus on the right marketing strategies.</p>
<h3 id="Channel-breakdown"><a href="#Channel-breakdown" class="headerlink" title="Channel breakdown"></a>Channel breakdown</h3><p>Channel breakdown involves details concerning the type of channels your customers use to arrive at your mobile app. It involves analyzing their behavior once they start using your app. How do people from a certain channel behave once they land? How does it differ from users who came through other channels? Good mobile apps take this vital data and fold it into the business culture as a whole.</p>
<h3 id="Geometrics"><a href="#Geometrics" class="headerlink" title="Geometrics"></a>Geometrics</h3><p>Although geometrics is most often ignored, it is important to know your user’s location. It affects the revenues collected from different locations. Analyzing behavior patterns from the different locations will help you understand and specifically focus your sales efforts. You will also know which areas are saturated and are in need of fresh demand-generation ideas.</p>
<h3 id="Demographics"><a href="#Demographics" class="headerlink" title="Demographics"></a>Demographics</h3><p>Do you know the gender of your target audience? What is their ethnicity and age? By comparing such information to the actual demographics of your customer base will help you analyze the success of your app. If your app was initially targeted for men and you find that a higher percentage of users are female, then it shows that you should re-evaluate your app.</p>
<h2 id="App-store-category-ranking"><a href="#App-store-category-ranking" class="headerlink" title="App store category ranking"></a>App store category ranking</h2><p>Generally, the higher your rankings in the app store, the better your performance. You should make an effort to monitor and analyze your rankings there. Bear in mind that the category ranking is directly affected by the following elements:</p>
<h3 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h3><p>Tracing how people found your app from the keywords they have typed while searching your app before arriving and downloading your app will shed light on which phrases generate revenue and which don’t.</p>
<p>The process might even give an idea on which features to update. For example, if someone searched for ‘voice book reader’ then you might provide an update to include voice recognition in your app.</p>
<h3 id="Reviews"><a href="#Reviews" class="headerlink" title="Reviews"></a>Reviews</h3><p>A customer who takes time to write a review about your app, no matter how long or short it may be, is a sign of being engaged with your app. Note the number of reviews your app has received and what users are saying. Compliments make you feel good about your app also listen to the complaints as they may be more informative.</p>
<p>Both complaints and positive criticism are key to knowing what to improve or what to include in your app. It will help you get to know the users’ needs. What’s more, it is important not to get discouraged by the extremely negative reviews. For example ‘very useless app.’ with no further comment.</p>
<h3 id="Ratings"><a href="#Ratings" class="headerlink" title="Ratings"></a>Ratings</h3><p>Just like reviews, the more the ratings you have, the better. However, ratings take less time and effort to fill in, so it does not necessarily show people’s engagement as far as your app goes.</p>
<p>Sometimes people who rate also write a review. Therefore, it is advisable to check the reviews after the ratings. You might find reasons to introduce premium versions of the app if the ratings are positive, or find a way to bridge the gap if the ratings are poor.</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Measuring mobile app success is vital to any mobile app development project. Setting up KPIs and sticking to them will give you a trustworthy base for your app optimization and growth plans. Getting an accurate picture of exactly how your customers use your mobile app will be an invaluable step to continuously delivering valuable, usable tools to your users. If you’d like for one of our experts to take a look at your app, drop us a line and chat with us for a free 15-minute consultation. It can set you on a path toward getting an accurate picture of how successful your app is — and where to improve it to make it even better.</p>
]]></content>
      <categories>
        <category>Business</category>
      </categories>
  </entry>
  <entry>
    <title>Writing Efficient Python Code</title>
    <url>/2020/09/05/Writing-Efficient-Python-Code/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Foundations-for-efficiencies"><a href="#Foundations-for-efficiencies" class="headerlink" title="Foundations for efficiencies"></a>Foundations for efficiencies</h1><ol>
<li><p>Pythonic: Code that executes quickly for the task at hand, minimizes the memory footprint and follows Python’s coding style principles.</p>
</li>
<li><p>Example:</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Collect the names in the above list that have six letters or more.</span></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> names:</span><br><span class="line">    <span class="keyword">if</span> len(name) &gt;= <span class="number">6</span>:</span><br><span class="line">        better_list.append(name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pythonic Way</span></span><br><span class="line">best_list = [name <span class="keyword">for</span> name <span class="keyword">in</span> names <span class="keyword">if</span> len(name) &gt;= <span class="number">6</span>]</span><br></pre></td></tr></table></figure>
<ol>
<li>Python Standard Library<br>(1) Built-in types: <code>list</code>, <code>tuple</code>, <code>set</code>, <code>dict</code>, and others<br>(2) Built-in functions: <code>print()</code>, <code>len()</code>, <code>range()</code>, <code>round()</code>, <code>enumerate()</code>, <code>map()</code>, <code>zip()</code>, and others<br>(3) Built-in modules: <code>os</code>, <code>sys</code>, <code>itertools</code>, <code>collections</code>, <code>math</code> and others</li>
</ol>
<a id="more"></a>
<p>Examples:</p>
<ul>
<li>range() </li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a range object that goes from 0 to 5</span></span><br><span class="line">nums = range(<span class="number">6</span>)</span><br><span class="line">print(type(nums))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert nums to a list</span></span><br><span class="line">nums_list = list(nums)</span><br><span class="line">print(nums_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new list of odd numbers from 1 to 11 by unpacking a range object</span></span><br><span class="line">nums_list2 = [*range(<span class="number">1</span>,<span class="number">12</span>,<span class="number">2</span>)]</span><br><span class="line">print(nums_list2)</span><br></pre></td></tr></table></figure>
<ul>
<li>enumerate()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Rewrite the for loop to use enumerate</span></span><br><span class="line">indexed_names = []</span><br><span class="line"><span class="keyword">for</span> i,name <span class="keyword">in</span> enumerate(names):</span><br><span class="line">    index_name = (i,name)</span><br><span class="line">    indexed_names.append(index_name) </span><br><span class="line">print(indexed_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rewrite the above for loop using list comprehension</span></span><br><span class="line">indexed_names_comp = [(i,name) <span class="keyword">for</span> i,name <span class="keyword">in</span> enumerate(names)]</span><br><span class="line">print(indexed_names_comp)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Unpack an enumerate object with a starting index of one</span></span><br><span class="line">indexed_names_unpack = [*enumerate(names, <span class="number">1</span>)]</span><br><span class="line">print(indexed_names_unpack)</span><br></pre></td></tr></table></figure>
<ul>
<li>map()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use map to apply str.upper to each element in names</span></span><br><span class="line">names_map  = map(str.upper, names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the type of the names_map</span></span><br><span class="line">print(type(names_map))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Unpack names_map into a list</span></span><br><span class="line">names_uppercase = [*names_map]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the list created above</span></span><br><span class="line">print(names_uppercase)</span><br></pre></td></tr></table></figure>
<ul>
<li>zip()<br>combine multiple objects together. It allows us to easily combine two or more objects. If we provide zip() with objects of differing lengths, it will only combine until the smallest lengthed object is exhausted.</li>
</ul>
<h1 id="NumPy-arrays"><a href="#NumPy-arrays" class="headerlink" title="NumPy arrays"></a>NumPy arrays</h1><ol>
<li>Numpy array makes every element the same type</li>
<li>Mathematical operations are broadcasted to each element of a numpy array by default.<br><strong>NumPy’s broadcasting concept</strong>: broadcasting refers to a numpy array’s ability to vectorize operations, so they are performed on all elements of an object at once.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Print second row of nums</span></span><br><span class="line">print(nums[<span class="number">1</span>,:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print all elements of nums that are greater than six</span></span><br><span class="line">print(nums[nums &gt; <span class="number">6</span>])</span><br><span class="line"><span class="comment"># nums &gt; 6 create a boolean index for all items in nums that are greater than 6.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Double every element of nums</span></span><br><span class="line">nums_dbl = nums * <span class="number">2</span></span><br><span class="line">print(nums_dbl)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Replace the third column of nums</span></span><br><span class="line">nums[:,<span class="number">2</span>] = nums[:,<span class="number">2</span>] + <span class="number">1</span></span><br><span class="line">print(nums)</span><br></pre></td></tr></table></figure>
<p>Exercise:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Create a list of arrival times</span><br><span class="line">arrival_times = [*range(10,60,10)]</span><br><span class="line"></span><br><span class="line"># Convert arrival_times to an array and update the times</span><br><span class="line">arrival_times_np = np.array(arrival_times)</span><br><span class="line">new_times = arrival_times_np - 3</span><br><span class="line"></span><br><span class="line"># Use list comprehension and enumerate to pair guests to new times</span><br><span class="line">guest_arrivals = [(names[i],time) for i,time in enumerate(new_times)]</span><br><span class="line"></span><br><span class="line"># Map the welcome_guest function to each (guest,time) pair</span><br><span class="line">welcome_map = map(welcome_guest, guest_arrivals)</span><br><span class="line"># The function provided to map() shouldn&apos;t contain closing parenthesis (i.e., use welcome_guest instead of welcome_guest()).</span><br><span class="line"></span><br><span class="line">guest_welcomes = [*welcome_map]</span><br><span class="line">print(*guest_welcomes, sep=&apos;\n&apos;)</span><br></pre></td></tr></table></figure>
<h1 id="Examing-the-runtime"><a href="#Examing-the-runtime" class="headerlink" title="Examing the runtime"></a>Examing the runtime</h1><ol>
<li>Unpacking the range object was faster than list comprehension.</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Create a list of integers (0-50) using list comprehension</span><br><span class="line">nums_list_comp = [num for num in range(51)]</span><br><span class="line">print(nums_list_comp)</span><br><span class="line"></span><br><span class="line"># Create a list of integers (0-50) by unpacking range</span><br><span class="line">nums_unpack = [*range(51)]</span><br><span class="line">print(nums_unpack)</span><br></pre></td></tr></table></figure>
<ol>
<li><p>Using Python’s literal syntax to define a data structure can speed up your runtime. Consider using the literal syntaxes (like [] instead of list(), {} instead of dict(), or () instead of tuple()), where applicable, to gain some speed.</p>
</li>
<li><p>Numpy is more efficient than Array</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Tech</category>
      </categories>
  </entry>
  <entry>
    <title>22 Years Old: Reflection on myself</title>
    <url>/2020/09/03/22-Years-Old-Reflection-on-myself/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><iframe allow="autoplay *; encrypted-media *;" frameborder="0" height="150" style="width:100%;max-width:660px;overflow:hidden;background:transparent;" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation" src="https://embed.music.apple.com/us/album/reflection-mandarin/1529680349?i=1529681056"></iframe>

<p><a href="https://www.disneyplus.com/welcome/new?cid=DSS-Search-Google-71700000071028144-&amp;gclid=EAIaIQobChMIp_DywdjO6wIVzsDACh1SEgHvEAAYASAAEgJg3_D_BwE&amp;gclsrc=aw.ds" target="_blank" rel="noopener">Mulan</a> is available today at Disney Plus. The first time <a href="https://en.wikipedia.org/wiki/Mulan_(1998_film" target="_blank" rel="noopener">Mulan was produced as an American animated film</a>) was in 1998, the same year as I was born. And the main actress <a href="https://en.wikipedia.org/wiki/Liu_Yifei" target="_blank" rel="noopener">Liu Yifei</a> has been my idol for many years. We have the same hometown - <a href="https://en.wikipedia.org/wiki/Wuhan" target="_blank" rel="noopener">Wuhan</a>.</p>
<p>This year has been extremely crazy for me. I was back from Beijing to Wuhan for Chinese New Year. However, 2020 started with a night of no sleep instead of the traditional festival. During that night, I was writing my application essay to <a href="https://esteem.nd.edu/" target="_blank" rel="noopener">ESTEEM</a> :) The lucky thing was I got accepeted later. But the happiness only lasted for a short time. Because my hometown was in lockdown due to COVID-19. The first half year of quarantine was tough. Even though we were free after a 76 days of quarantine, my suffering did not end. I went through an exclusively long journey: Wuhan -&gt; Shanghai -&gt; Phnom Penh (Cambodia) -&gt; Soul (South Korea) -&gt; New York, NY -&gt; Chicago, IL -&gt; South Bend, IN in order to go back to Notre Dame.</p>
<p>Now I am sitting in my room at Fischer Graduate Residents. This midnight is quiet and suitable for writing. It’s also a good time to look back and reflect on what I have done to get here (besides the phycial move). <a id="more"></a> I do not have clear memories about my stories before 18. If there is anything, that must be problem sets and exams :) So I’ll start with my time in Beijing (since 2016 Summer).</p>
<p>I had a great ambition when I was a freshman. After more than 10 interview with different student organizations and departments of Students’ Union, I got 5 jobs. This is too overwheelming, so I only kept two similar jobs which was to work for the publicy of student activities. One was in the technology department of Students’ Union. Another one was in the news and media department of Student Clubs’ Union. I learnt how to use Adobe Photoshop, to make posters, banners and flyers. My final position was a Vice President, responsible for training and staffing new freshman kids. My job at student organization was merely a foreshadowing of my later professional development.</p>
<p>My determination for entrepreneurship was ignited early in 2017 Spring with the WIN (We Innovate Now) spirit of <a href="https://english.bupt.edu.cn/" target="_blank" rel="noopener">BUPT (Beijing University of Posts and Telecommunications)</a>. The <a href="https://win.bupt.edu.cn" target="_blank" rel="noopener">BUPT WIN Innovation Center</a> has been supporting university students’ innovative practice activities for twelve years, and some of these projects have been realized, attracting considerable venture capital. I attended the National Undergraduate Innovation and Entrepreneurship Competition twice for entrepreneurship. In my team’s first attempt, we put up drones to inspect and supervise tasks in building construction. I led a five-member group in assembling a drone that could be programmed to fly in a pre-set routine. We tested the drone on a construction project led by my father. In bringing this project to fruition, I learned how to organize and negotiate with institutions, and we successfully raised 1200 dollars to build our drone – the highest amount allowed by our university for undergraduate projects.</p>
<p>For my second time in the competition, I played a consultant role, leaving behind the engineering zone and focusing on the customer’s needs as well as technical support and finance. Entrepreneurship requires talent in multiple areas. As such, I pulled together a group of schoolmates from different majors: internet of things engineering, telecommunications, and management. Remote-sensing satellite imagery requires real-time detection and recognition of time-sensitive targets. We considered aggregating computer vision with mobile platforms like satellites and drones, writing a proposal to establish our project – the “Eagle” Remote Sensing Reconnaissance System. In this project, our team developed a system on the mobile terminal that could process the remote-sensing images to detect objects. Our objective was to compete with a product belonging to <a href="http://www.otitan.com/n10502201/index.html" target="_blank" rel="noopener">Beijing Aerospace Titan Technology CO., Ltd</a>. We used <a href="https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006" target="_blank" rel="noopener">YOLO algorithms</a> on the <a href="https://developer.nvidia.com/embedded/jetson-tx2" target="_blank" rel="noopener">NVIDIA Jetson TX2</a> platform to implement functions of object detection and semantic segmentation. In this case, financial and equipment challenges were minimized by developing algorithms and software.</p>
<p>Through the “Eagle” project, we attended a series of innovation and entrepreneurship competitions, including “Internet +” and “AI+”. Along the way, we utilized the strengths of various institutions. In terms of technical aspects, existing enterprises have strong and competitive national research departments and technical support. Therefore, we consulted several scientists from the National Space Science Center at <a href="http://english.cas.cn/" target="_blank" rel="noopener">CAS (Chinese Academy of Sciences)</a> and the <a href="http://www.pris.net.cn/en/" target="_blank" rel="noopener">P.r.i.s Laboratory at BUPT</a> to prepare us for project execution. For finance, we successively raised  about 1500 dollars for the 2018 <a href="https://www.google.com/intl/en_cn/university/china/" target="_blank" rel="noopener">Google - China MoE University-Industry Collaboration Program</a>, as well as the traditional 1000 dollars fund from BUPT. These funds assisted us in renting servers as our computing resource and in publishing our paper. To pitch our project, we attended exhibitions and gave speeches at other universities. Ultimately, we won the National Second-Class Award for Undergraduate Innovation and Entrepreneurship Competition at the 2019 BUPT Undergraduate Innovation and Entrepreneurship Exhibition. The <a href="https://ieeexplore.ieee.org/document/8900281" target="_blank" rel="noopener">paper</a> of my group members was published on <a href="https://igarss2019.org/Papers/ViewPapers.asp?PaperNum=4321" target="_blank" rel="noopener">IGARSS19</a>. </p>
<p>As these projects illustrate, my previous entrepreneurship experiences have focused on R&amp;D (research and development). In the future, I expect to bring our product to customers in real markets. Although I am not ready to lunch entrepreneurship soon, I believe ESTEEM will equipt me with the basic business sense and lead me into career tracks outside of narrow technical roles, taking positions of leadership at the intersection of business and technology.</p>
<p>Fun Stuff:<br>I am watching <a href="https://en.wikipedia.org/wiki/Silicon_Valley_(TV_series" target="_blank" rel="noopener">Silicon Valley</a>) recently. It really resonates with me because I have seen a lot of smart engineers. What happened to Richard Hendricks (the CEO of Pied Pipper in Silicon Valley) are also troubling my engineer friends. Products produced by engineers are too engineered and do not meet the needs of normal people. The show introduced a fictional business philosophy based on compromise among the sales, manufacturing and engineering departments, and that too has roots of truth — provided you substitute the word “respect” for “compromise.”</p>
<p>As the subtitles in Silicon Valley said:</p>
<blockquote>
<p>Sales and engineering are the two pillars of the Conjoined Triangles of Success.<br>Engineering and sales must work together to decide what to build.<br>Who knows better what the customers need than the people who actually deal with the customers every single day?</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/Conjoined%20Triangles%20of%20Success.jpg" alt="Subtitles"></p>
]]></content>
      <categories>
        <category>Reflections</category>
      </categories>
  </entry>
  <entry>
    <title>JPMorgan Chase Software Engineering Virtual Internship 4/4</title>
    <url>/2020/08/31/JPMorgan-Chase-Software-Engineering-Virtual-Internship-4-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>My tasks have been all finished now. Here is my certificate:<br>

	<div class="row">
    <embed src="https://insidesherpa.s3.amazonaws.com/completion-certificates/JP%20Morgan/R5iK7HMxJGBgaSbvk_JPMorgan%20Chase_bzbExnMRauXGApThB_completion_certificate.pdf" width="100%" height="550" type="application/pdf">
	</div>


</p>
<p>But If I get free time, I would be very happy to contribute to the open source repo on GitHub~</p>
<p>Resources:</p>
<ol>
<li><a href="https://github.com/jpmorganchase" target="_blank" rel="noopener">JPMorgan Chase’s Open Source Projects</a> View the various projects at JPMC, from blockchain projects to perspective</li>
<li><a href="https://perspective.finos.org/" target="_blank" rel="noopener">Perspective</a></li>
<li><a href="https://github.com/finos/perspective/projects/2" target="_blank" rel="noopener">Perspective’s roadmap</a></li>
<li><a href="https://github.com/finos/perspective/issues" target="_blank" rel="noopener">Perspective’s issue list</a></li>
</ol>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>JPMorgan Chase Software Engineering Virtual Internship 3/4</title>
    <url>/2020/08/31/JPMorgan-Chase-Software-Engineering-Virtual-Internship-3-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Task-3-Display-data-visually-for-traders"><a href="#Task-3-Display-data-visually-for-traders" class="headerlink" title="Task 3: Display data visually for traders"></a>Task 3: Display data visually for traders</h1><p><em>Use Perspective to create the chart for the trader’s dashboard </em></p>
<p>Being able to access and  adjust data feeds is critical to any trading analysis and stock price monitoring. From the previous tasks, we now have the adjusted data set up on your systems and being piped into Perspective.</p>
<p>For traders to have a complete picture of all the trading strategies being monitored, several screens typically display an assortment of live and historical data at their workstation.</p>
<p>Given there is a lot of information and data being produced at once, visualizing data in a clear manner with <strong>UI/UX considerations</strong> accounted for is critical to providing traders with the tools to improve their performance.</p>
<a id="more"></a>
<h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>Clone Repository<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/insidesherpa/JPMC-tech-task-3-PY3.git</span><br></pre></td></tr></table></figure></p>
<p>Server<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd JPMC-tech-task-3-py3</span><br><span class="line">python3 datafeed/server3.py</span><br></pre></td></tr></table></figure></p>
<p>Client<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd JPMC-tech-task-3-py3</span><br><span class="line">nvm use v11.0.0</span><br><span class="line"></span><br><span class="line">npm install</span><br><span class="line">npm start</span><br></pre></td></tr></table></figure></p>
<p>First Run:<br>Similar to Task 2, two stocks are displayed and their top_ask_price changes being tracked through a timeline.<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/JPMC/Task3FirstRun.png" alt="Task3 First Run"></p>
<h2 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h2><p>(1) We now want to make this graph more useful to traders by making it track the ratio between two stocks over time and NOT the two stocks’ top_ask_price over time.</p>
<p>(2) As mentioned before, traders want to monitor the ratio of two stocks against a historical correlation with upper and lower thresholds/bounds. This can help them determine a trading opportunity.That said, we also want to make this graph plot those upper and lower thresholds and show when they get crossed by the ratio of the stock</p>
<h2 id="Code-Changes"><a href="#Code-Changes" class="headerlink" title="Code Changes"></a>Code Changes</h2><p>(1) Making changes in <strong>Graph.tsx</strong></p>
<p>The changes we’ve made to schema:</p>
<ul>
<li>Since we don’t want to distinguish between two stocks now, but instead want to track their ratios, we made sure to add the <code>ratio</code> field. </li>
<li>Since we also wanted to track <code>upper_bound</code>, <code>lower_bound</code>, and the moment when these bounds are crossed i.e. <code>trigger_alert</code>, we had to add those fields too.</li>
<li>Finally, the reason we added <code>price_abc</code> and <code>price_def</code> is just because these were necessary to get the ratio as you will see later. We won’t be configuring the graph to show them anyway.</li>
<li>Of course since we’re tracking all of this with respect to time, <code>timestamp</code> is going to be there.</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">componentDidMount() &#123;</span><br><span class="line">  <span class="comment">// Get element from the DOM.</span></span><br><span class="line">  <span class="keyword">const</span> elem = <span class="built_in">document</span>.getElementsByTagName(<span class="string">'perspective-viewer'</span>)[<span class="number">0</span>] <span class="keyword">as</span> unknown <span class="keyword">as</span> PerspectiveViewerElement;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> schema = &#123;</span><br><span class="line">    price_abc: <span class="string">'float'</span>,</span><br><span class="line">    price_def: <span class="string">'float'</span>,</span><br><span class="line">    ratio: <span class="string">'float'</span>,</span><br><span class="line">    timestamp: <span class="string">'date'</span>,</span><br><span class="line">    upper_bound: <span class="string">'float'</span>,</span><br><span class="line">    lower_bound: <span class="string">'float'</span>,</span><br><span class="line">    trigger_alert: <span class="string">'float'</span>,</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">window</span>.perspective &amp;&amp; <span class="built_in">window</span>.perspective.worker()) &#123;</span><br><span class="line">    <span class="keyword">this</span>.table = <span class="built_in">window</span>.perspective.worker().table(schema);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.table) &#123;</span><br><span class="line">    <span class="comment">// Load the `table` in the `&lt;perspective-viewer&gt;` DOM reference.</span></span><br><span class="line">    elem.load(<span class="keyword">this</span>.table);</span><br><span class="line">    elem.setAttribute(<span class="string">'view'</span>, <span class="string">'y_line'</span>);</span><br><span class="line">    elem.setAttribute(<span class="string">'row-pivots'</span>, <span class="string">'["timestamp"]'</span>);</span><br><span class="line">    elem.setAttribute(<span class="string">'columns'</span>, <span class="string">'["top_ask_price"]'</span>);</span><br><span class="line">    elem.setAttribute(<span class="string">'aggregates'</span>, <span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">    <span class="comment">// To configure our graph, modify/add more attributes to the element. </span></span><br><span class="line">      price_abc: <span class="string">'avg'</span>,</span><br><span class="line">      price_def: <span class="string">'avg'</span>,</span><br><span class="line">      ratio: <span class="string">'avg'</span>,</span><br><span class="line">      timestamp: <span class="string">'distinct count'</span>,</span><br><span class="line">      upper_bound: <span class="string">'avg'</span>,</span><br><span class="line">      lower_bound: <span class="string">'avg'</span>,</span><br><span class="line">      trigger_alert: <span class="string">'avg'</span>,</span><br><span class="line">    &#125;));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Make a slight update in the componentDidUpdate method.<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">  componentDidUpdate() &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.table) &#123;</span><br><span class="line">      <span class="keyword">this</span>.table.update([</span><br><span class="line">          DataManipulator.generateRow(<span class="keyword">this</span>.props.data),</span><br><span class="line">      ]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>(2) Making changes in <strong>DataManipulator.ts</strong><br>The DataManipulator.ts file is responsible for processing the raw stock data we’ve received from the server before it throws it back to the Graph component’s table to render. </p>
<p>Update  the Row interface to match the new schema.<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> interface Row &#123;</span><br><span class="line">  price_abc: number,</span><br><span class="line">  price_def: number,</span><br><span class="line">  ratio: number,</span><br><span class="line">  timestamp: <span class="built_in">Date</span>,</span><br><span class="line">  upper_bound: number,</span><br><span class="line">  lower_bound: number,</span><br><span class="line">  trigger_alert: number | <span class="literal">undefined</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Update the generateRow function of the <code>DataManipulator</code><br>class to properly process the raw server data passed to it so that it can return the processed data which will be rendered by the Graph component’s table.</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="class"><span class="keyword">class</span> <span class="title">DataManipulator</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> generateRow(serverResponds: ServerRespond[]): Row &#123;</span><br><span class="line">    <span class="keyword">const</span> priceABC = (serverResponds[<span class="number">0</span>].top_ask.price + serverResponds[<span class="number">0</span>].top_bid.price) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">const</span> priceDEF = (serverResponds[<span class="number">1</span>].top_ask.price + serverResponds[<span class="number">1</span>].top_bid.price) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">const</span> ratio = priceABC / priceDEF;</span><br><span class="line">    <span class="keyword">const</span> uperBound = <span class="number">1</span> + <span class="number">0.05</span>;</span><br><span class="line">    <span class="keyword">const</span> lowerBound = <span class="number">1</span> - <span class="number">0.05</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">      price_abc: priceABC,</span><br><span class="line">      price_def: priceDEF,</span><br><span class="line">      ratio,</span><br><span class="line">      timestamp: serverResponds[<span class="number">0</span>].timestamp &gt; serverResponds[<span class="number">1</span>].timestamp ?</span><br><span class="line">          serverResponds[<span class="number">0</span>].timestamp : serverResponds[<span class="number">1</span>].timestamp,</span><br><span class="line">      upper_bound: uperBound,</span><br><span class="line">      lower_bound: lowerBound,</span><br><span class="line">      trigger_alert: (ratio &gt; uperBound || ratio &lt; lowerBound) ? ratio : <span class="literal">undefined</span>,</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Finished:<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/JPMC/Task3Final.png" alt><br>with configurations as below:<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/JPMC/Task3Config.png" alt></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Node 14 Caused Trouble in Deployment of Hexo</title>
    <url>/2020/08/30/Node-14-Caused-Trouble-in-Deployment-of-Hexo/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>It’s been a long time since I updated my blog on the old Macbook I had. So I am updating it now and found this problem. </p>
<a id="more"></a>
<h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp hexo % hexo d</span><br><span class="line">INFO  Deploying: git</span><br><span class="line">INFO  Clearing .deploy_git folder...</span><br><span class="line">INFO  Copying files from public folder...</span><br><span class="line">FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">TypeError [ERR_INVALID_ARG_TYPE]: The &quot;mode&quot; argument must be integer. Received an instance of Object</span><br><span class="line">    at copyFile (fs.js:1924:10)</span><br><span class="line">    at tryCatcher (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/util.js:16:23)</span><br><span class="line">    at ret (eval at makeNodePromisifiedEval (/Users/xiaxii/.config/yarn/global/node_modules/bluebird/js/release/promisify.js:184:12), &lt;anonymous&gt;:13:39)</span><br><span class="line">    at /Users/xiaxii/Documents/GitHub/hexo/node_modules/hexo-deployer-git/node_modules/hexo-fs/lib/fs.js:144:39</span><br><span class="line">    at tryCatcher (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/util.js:16:23)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:512:31)</span><br><span class="line">    at Promise._settlePromise (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:569:18)</span><br><span class="line">    at Promise._settlePromise0 (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:614:10)</span><br><span class="line">    at Promise._settlePromises (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:694:18)</span><br><span class="line">    at Promise._fulfill (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:638:18)</span><br><span class="line">    at Promise._resolveCallback (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:432:57)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:524:17)</span><br><span class="line">    at Promise._settlePromise (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:569:18)</span><br><span class="line">    at Promise._settlePromise0 (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:614:10)</span><br><span class="line">    at Promise._settlePromises (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:694:18)</span><br><span class="line">    at Promise._fulfill (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:638:18)</span><br><span class="line">    at Promise._resolveCallback (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:432:57)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:524:17)</span><br><span class="line">    at Promise._settlePromise (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:569:18)</span><br><span class="line">    at Promise._settlePromise0 (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:614:10)</span><br><span class="line">    at Promise._settlePromises (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:694:18)</span><br><span class="line">    at Promise._fulfill (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:638:18)</span><br><span class="line">    at Promise._resolveCallback (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:432:57)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:524:17)</span><br><span class="line">    at Promise._settlePromise (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:569:18)</span><br><span class="line">    at Promise._settlePromise0 (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:614:10)</span><br><span class="line">    at Promise._settlePromises (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:694:18)</span><br><span class="line">    at Promise._fulfill (/Users/xiaxii/Documents/GitHub/hexo/node_modules/bluebird/js/release/promise.js:638:18)</span><br></pre></td></tr></table></figure>
<h1 id="Solution-1"><a href="#Solution-1" class="headerlink" title="Solution 1"></a>Solution 1</h1><p>The reason the version of Node is to high (14+) in my new Macbook. I need to downgrade it to 12 or 13 in order to render Hexo.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ brew uninstall node</span><br><span class="line"></span><br><span class="line">$ brew search node</span><br><span class="line">==&gt; Formulae</span><br><span class="line">libbitcoin-node      node                 node-sass            node@12 ✔            nodebrew             nodenv</span><br><span class="line">llnode               node-build           node@10              node_exporter        nodeenv</span><br><span class="line">==&gt; Casks</span><br><span class="line">nodebox                                                         nodeclipse</span><br><span class="line"></span><br><span class="line">If you meant &quot;node&quot; specifically:</span><br><span class="line">It was migrated from homebrew/cask to homebrew/core.</span><br><span class="line">$ brew install node@12</span><br><span class="line">...</span><br><span class="line">$ brew link node@12</span><br><span class="line">$ echo &quot;\n&quot; &gt;&gt; ~/.zshrc; export PATH=&quot;/usr/local/opt/node@12/bin:$PATH&quot;</span><br></pre></td></tr></table></figure></p>
<h1 id="Solution-2"><a href="#Solution-2" class="headerlink" title="Solution 2"></a>Solution 2</h1><ol>
<li>Ppgrade hexo by changing the hexo version in package.json</li>
<li>Run <code>npm update</code> in terminal</li>
</ol>
]]></content>
      <categories>
        <category>Maintainance</category>
      </categories>
  </entry>
  <entry>
    <title>JPMorgan Chase Software Engineering Virtual Internship 2/4</title>
    <url>/2020/08/30/JPMorgan-Chase-Software-Engineering-Virtual-Internship-2-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Task-2-Use-JPMorgan-Chase-frameworks-and-tools"><a href="#Task-2-Use-JPMorgan-Chase-frameworks-and-tools" class="headerlink" title="Task 2: Use JPMorgan Chase frameworks and tools"></a>Task 2: Use JPMorgan Chase frameworks and tools</h1><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Typically, traders monitor stock prices and trading strategies by having data displayed visually on their screens in chart form. Often these charts will be accompanied by alerts that notify users when certain events occur or when preset price thresholds are hit.</p>
<p>JPMorgan Chase created the Perspective tool over many years to allows users to present and manipulate data feeds visually in web applications.</p>
<p><a href="https://perspective.finos.org/" target="_blank" rel="noopener">Perspective</a> provides a set of flexible data transforms, such as pivots, filters, and aggregations. It utilizes bleeding-edge browser technology such as Web Assembly and Apache Arrow and is unmatched in browser performance. It is engineered for reliability and production-vetted on the JPMorgan Chase trading floor and is now available to the development community as Open Source. Chect it out on <a href="https://github.com/finos/perspective" target="_blank" rel="noopener">github</a> page of perspective.</p>
<a id="more"></a>
<h2 id="Set-Up"><a href="#Set-Up" class="headerlink" title="Set Up"></a>Set Up</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp JPMC % git --version</span><br><span class="line">git version 2.26.1</span><br><span class="line">xiaxii@cecilias-mbp JPMC % git clone https://github.com/insidesherpa/JPMC-tech-task-2-PY3.git</span><br><span class="line">Cloning into &apos;JPMC-tech-task-2-PY3&apos;...</span><br><span class="line">remote: Enumerating objects: 9, done.</span><br><span class="line">remote: Counting objects: 100% (9/9), done.</span><br><span class="line">remote: Compressing objects: 100% (9/9), done.</span><br><span class="line">remote: Total 57 (delta 4), reused 2 (delta 0), pack-reused 48</span><br><span class="line">Receiving objects: 100% (57/57), 231.98 KiB | 2.37 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (21/21), done.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % ls</span><br><span class="line">README.md		package.json		test.csv</span><br><span class="line">datafeed		public			tsconfig.json</span><br><span class="line">package-lock.json	src</span><br></pre></td></tr></table></figure>
<h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-py3 % python3 datafeed/server3.py</span><br><span class="line">HTTP server started on port 8080</span><br></pre></td></tr></table></figure>
<h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % nvm --version</span><br><span class="line">0.35.3</span><br><span class="line"></span><br><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % nvm install v11.0.0</span><br><span class="line">Downloading and installing node v11.0.0...</span><br><span class="line">Downloading https://nodejs.org/dist/v11.0.0/node-v11.0.0-darwin-x64.tar.xz...</span><br><span class="line">######################################################################### 100.0%</span><br><span class="line">Computing checksum with shasum -a 256</span><br><span class="line">Checksums matched!</span><br><span class="line">Now using node v11.0.0 (npm v6.4.1)</span><br><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % nvm use v11.0.0</span><br><span class="line">Now using node v11.0.0 (npm v6.4.1)</span><br><span class="line"></span><br><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % node -v</span><br><span class="line">v11.0.0</span><br><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-2-PY3 % npm -v</span><br><span class="line">6.4.1</span><br></pre></td></tr></table></figure>
<h3 id="First-Run"><a href="#First-Run" class="headerlink" title="First Run"></a>First Run</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install</span><br><span class="line">npm start</span><br></pre></td></tr></table></figure>
<p>Result<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/JPMC/startClientApp.png" alt="start the client application"></p>
<p><strong>Troubleshooting</strong><br>Error: type error: Cannot find module ‘@jpmorganchase/perspective’. TS2307<br>Solution:<br>go to the your project directory and just type the command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm i @finos/perspective</span><br></pre></td></tr></table></figure></p>
<p>this will install the required files in your project directory<br>and then goto your graph.tsx file and replace<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import &#123; Table &#125; from &apos;@jpmorganchase/perspective&apos;;</span><br></pre></td></tr></table></figure></p>
<p>with this below code<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import &#123; Table &#125; from &apos;@finos/perspective&apos;;</span><br></pre></td></tr></table></figure></p>
<p>Ref: <a href="https://github.com/insidesherpa/JPMC-tech-task-2/issues/47" target="_blank" rel="noopener">https://github.com/insidesherpa/JPMC-tech-task-2/issues/47</a></p>
<h2 id="Code-Changes"><a href="#Code-Changes" class="headerlink" title="Code Changes"></a>Code Changes</h2><h3 id="Prerequest"><a href="#Prerequest" class="headerlink" title="Prerequest"></a>Prerequest</h3><p>the app can run after <code>npm start</code>.<br>(1) Click on the botton <code>Start Streaming Data</code>, there is going to be a lot of stock records<br>(2) Click on the 3-dotted button on the upper left corner of the graph. The graph is configurable and there are different types of views we can use to visualize the data we have so far.<br>(3) But we can observe it’s just a bunch of duplicate data being printed for stocks ABC and DEF, instead ofnew data (i.e. different timestamp, ask_price and bid_price for ABC and DEF stocks).</p>
<h3 id="Obejective"><a href="#Obejective" class="headerlink" title="Obejective"></a>Obejective</h3><p>(1) Make the graph continuously update instead of having to click it a bunch of times. Also the kind of graph we want to serve as visual here is kind of a continuously updating line graph whose y axis is the stock’s top_ask_price and the x-axis is the timestamp of the stock<br>(2) Remove / disregard the duplicated data in ‘first run’</p>
<h3 id="Making-changes-to-the-src-code"><a href="#Making-changes-to-the-src-code" class="headerlink" title="Making changes to the src code"></a>Making changes to the src code</h3><p>(1) <strong>App.tsx</strong>, change the static table into a live / updating graph</p>
<p>Declare <code>showGraph</code> and include it in other methods</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * State declaration for &lt;App /&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">interface IState &#123;</span><br><span class="line">  data: ServerRespond[],</span><br><span class="line">  showGraph: boolean,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The parent element of the react app.</span></span><br><span class="line"><span class="comment"> * It renders title, button and Graph react element.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">App</span> <span class="keyword">extends</span> <span class="title">Component</span>&lt;</span>&#123;&#125;, IState&gt; &#123;</span><br><span class="line">  <span class="keyword">constructor</span>(props: &#123;&#125;) &#123;</span><br><span class="line">    <span class="keyword">super</span>(props);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.state = &#123;</span><br><span class="line">      <span class="comment">// data saves the server responds.</span></span><br><span class="line">      <span class="comment">// We use this state to parse data down to the child element (Graph) as element property</span></span><br><span class="line">      data: [],</span><br><span class="line">      showGraph: <span class="literal">false</span>,</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>To ensure that the graph doesn’t render until a user clicks the ‘Start Streaming’ button, I should also edit the <code>renderGraph</code> method of the App. In there, I must add a condition to only render the graph when the<br>state’s <code>showGraph</code> property of the App’s state is <code>true</code>.<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Render Graph react component with state.data parse as property data</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">renderGraph() &#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.state.showGraph)&#123;</span><br><span class="line">    <span class="keyword">return</span> (<span class="xml"><span class="tag">&lt;<span class="name">Graph</span> <span class="attr">data</span>=<span class="string">&#123;this.state.data&#125;/</span>&gt;</span>)</span></span><br><span class="line"><span class="xml">  &#125;</span></span><br><span class="line"><span class="xml">&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Finally, I must also modify the <code>getDataFromServer</code>method to contact the server and get data from it continuously instead of just getting data from it once every time you click the button.</p>
<p>Javascript has a way to do things in intervals and that is via the setInterval function. What we can do to make it continuous (at least up to an extended period of time) is to have a guard value that we can check against when to stop / clear the interval process we started.<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Get new data from server and update the state with the new data</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">getDataFromServer() &#123;</span><br><span class="line">  <span class="keyword">let</span> x = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">const</span> interval = setInterval(<span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    DataStreamer.getData(<span class="function">(<span class="params">serverResponds: ServerRespond[]</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="comment">// getData() gets the data from the server and when that process is complete</span></span><br><span class="line">      <span class="comment">// Update the state by creating a new array of data that consists of</span></span><br><span class="line">      <span class="comment">// Previous data in the state and the new data from server</span></span><br><span class="line">      <span class="keyword">this</span>.setState(&#123;</span><br><span class="line">        data: serverResponds,</span><br><span class="line">        showGraph: <span class="literal">true</span>,</span><br><span class="line">        <span class="comment">// set showGraph to true</span></span><br><span class="line">        <span class="comment">// as soon as the data from the server comes back to the requester</span></span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">    x++;</span><br><span class="line">    <span class="keyword">if</span> (x &gt; <span class="number">1000</span>)&#123;</span><br><span class="line">      clearInterval(interval);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,<span class="number">100</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>The line DataStreamer.getData(… =&gt; …) is an asynchronous process that gets the data from the server and when that process is complete, it then performs what comes after the =&gt; as a callback function.</p>
<p>(2) <strong>Graph.tsx</strong><br>To completely achieve the desired output, we must also make changes to the <code>Graph.tsx</code> file. This is the file that takes care of how the Graph component of our App will be rendered and react to the state changes that occur within the App.</p>
<p>Firstly, enable the <code>PerspectiveViewerElement</code> to behave like an HTMLElement. To do this, I should extend the <code>HTMLElement</code> class from the <code>PerspectiveViewerElement</code> interface.</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Perspective library adds load to HTMLElement prototype.</span></span><br><span class="line"><span class="comment"> * This interface acts as a wrapper for Typescript compiler.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">interface PerspectiveViewerElement extends HTMLElement&#123;</span><br><span class="line">  load: <span class="function">(<span class="params">table: Table</span>) =&gt;</span> <span class="keyword">void</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Since I’ve changed the <code>PerspectiveViewerElement</code> to extend the <code>HTMLElement</code> earlier, I can now make the definition of the <code>const elem</code> simpler, i.e. I can just assign it straight to the result of the result of the<br><code>document.getElementsByTagName</code>. </p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * React component that renders Perspective based on data</span></span><br><span class="line"><span class="comment"> * parsed from its parent through data property.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span> <span class="keyword">extends</span> <span class="title">Component</span>&lt;<span class="title">IProps</span>, </span>&#123;&#125;&gt; &#123;</span><br><span class="line">  <span class="comment">// Perspective table</span></span><br><span class="line">  table: Table | <span class="literal">undefined</span>;</span><br><span class="line"></span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> React.createElement(<span class="string">'perspective-viewer'</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  componentDidMount() &#123;</span><br><span class="line">    <span class="comment">// Get element to attach the table from the DOM.</span></span><br><span class="line">    <span class="comment">// the componentDidMount() method runs</span></span><br><span class="line">    <span class="comment">// after the component output has been rendered to the DOM.</span></span><br><span class="line">    <span class="keyword">const</span> elem = <span class="built_in">document</span>.getElementsByTagName(<span class="string">'perspective-viewer'</span>)[<span class="number">0</span>] <span class="keyword">as</span> unknown <span class="keyword">as</span> PerspectiveViewerElement;</span><br><span class="line">    <span class="keyword">const</span> schema = &#123;</span><br><span class="line">      stock: <span class="string">'string'</span>,</span><br><span class="line">      top_ask_price: <span class="string">'float'</span>,</span><br><span class="line">      top_bid_price: <span class="string">'float'</span>,</span><br><span class="line">      timestamp: <span class="string">'date'</span>,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">window</span>.perspective &amp;&amp; <span class="built_in">window</span>.perspective.worker()) &#123;</span><br><span class="line">      <span class="keyword">this</span>.table = <span class="built_in">window</span>.perspective.worker().table(schema);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.table) &#123;</span><br><span class="line">      <span class="comment">// Load the `table` in the `&lt;perspective-viewer&gt;` DOM reference.</span></span><br><span class="line">      <span class="comment">// Add more Perspective configurations here.</span></span><br><span class="line">      elem.load(<span class="keyword">this</span>.table);</span><br><span class="line">      elem.setAttribute(<span class="string">'view'</span>,<span class="string">'y_line'</span>);</span><br><span class="line">      elem.setAttribute(<span class="string">'column-pivots'</span>,<span class="string">'["stock"]'</span>);</span><br><span class="line">      elem.setAttribute(<span class="string">'row-pivots'</span>,<span class="string">'["timestamp"]'</span>);</span><br><span class="line">      elem.setAttribute(<span class="string">'columns'</span>,<span class="string">'["top_ask_price"]'</span>);</span><br><span class="line">      elem.setAttribute(<span class="string">'aggregates'</span>, <span class="string">`&#123;"stock":"distinct count","top_ask_price":"avg","top_bid_price":"avg","timestamp":"distinct count"&#125;`</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p><strong>Troubleshoting</strong><br>Problem:<br><a href="https://github.com/insidesherpa/JPMC-tech-task-2/issues/13" target="_blank" rel="noopener">Failed to Compile-Type Error TS2345</a><br>Solution:<br>in the aggregates property, the value should have been enclosed in back ticks i.e. <code>value</code>,<br>so it would look somethine like:<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">elem.setAttribute(<span class="string">'aggregates'</span>, <span class="string">`&#123;"stock":"distinct count","top_ask_price":"avg","top_bid_price":"avg","timestamp":"distinct count"&#125;`</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="Finished"><a href="#Finished" class="headerlink" title="Finished"></a>Finished</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/JPMC/taskFinal.png" alt="Final Task2"></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>JPMorgan Chase Software Engineering Virtual Internship 1/4</title>
    <url>/2020/08/30/JPMorgan-Chase-Software-Engineering-Virtual-Internship-1-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Task-1-Interface-with-a-stock-price-data-feed"><a href="#Task-1-Interface-with-a-stock-price-data-feed" class="headerlink" title="Task 1: Interface with a stock price data feed"></a>Task 1: Interface with a stock price data feed</h1><p>Background Information of the task:</p>
<p>This software is to add a chart to a trader’s dashboard allowing them to better identify under/over-valued stocks.</p>
<p>The trader would like to be able to monitor two historically correlated stocks and be able to visualize when the correlation between the two weakens (i.e. one stock moves proportionally more than the historical correlation would imply). This could indicate a potential trade strategy to simultaneously buy the relatively underperforming stock and sell the relatively outperforming stock. Assuming the two prices subsequently converge, the trade should be profitable.</p>
<p>Most data visualization for JPMorgan Chase’s traders is built on the data visualization software - <a href="https://perspective.finos.org/" target="_blank" rel="noopener">Perspective</a>, which is now open source. See: <a href="https://github.com/finos/perspective" target="_blank" rel="noopener">GitHub Repository of Perspective</a>. </p>
<p>Before implementing this request using perspective, the first need is to interface with the relevant <strong>financial data feed</strong> and make the necessary adjustments to facilitate the monitoring of potential trade opportunities.</p>
<a id="more"></a>
<h2 id="Local-Setup"><a href="#Local-Setup" class="headerlink" title="Local Setup"></a>Local Setup</h2><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a><strong>Python</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp ~ % which python</span><br><span class="line">/usr/bin/python</span><br><span class="line">xiaxii@cecilias-mbp ~ % which python2</span><br><span class="line">/usr/bin/python2</span><br><span class="line">xiaxii@cecilias-mbp ~ % which python3 </span><br><span class="line">/usr/local/bin/python3</span><br><span class="line"></span><br><span class="line">xiaxii@cecilias-mbp ~ % pip --version</span><br><span class="line">pip 20.0.2 from /Library/Python/2.7/site-packages/pip-20.0.2-py2.7.egg/pip (python 2.7)</span><br><span class="line">xiaxii@cecilias-mbp ~ % pip3 --version</span><br><span class="line">pip 20.1.1 from /usr/local/lib/python3.8/site-packages/pip (python 3.8)</span><br></pre></td></tr></table></figure>
<p>I am using Python3 for this project.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp ~ % pip3 list</span><br><span class="line">Package         Version</span><br><span class="line">--------------- -------</span><br><span class="line">pip             20.1.1</span><br><span class="line">python-dateutil 2.8.1</span><br><span class="line">setuptools      49.2.0</span><br><span class="line">six             1.15.0</span><br><span class="line">wheel           0.34.2</span><br></pre></td></tr></table></figure>
<h3 id="Clone-repository"><a href="#Clone-repository" class="headerlink" title="Clone repository"></a><strong>Clone repository</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/insidesherpa/JPMC-tech-task-1-py3.git</span><br></pre></td></tr></table></figure>
<h3 id="Run-the-script"><a href="#Run-the-script" class="headerlink" title="Run the script"></a><strong>Run the script</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python3 server3.py</span><br><span class="line">python3 client3.py</span><br></pre></td></tr></table></figure>
<h2 id="Code-Changes"><a href="#Code-Changes" class="headerlink" title="Code Changes"></a>Code Changes</h2><p>Interface with a stock price data feed and set up your system for analysis of the data</p>
<h3 id="Prerequest"><a href="#Prerequest" class="headerlink" title="Prerequest"></a><strong>Prerequest</strong></h3><p>Run server and client<br><em>Server</em><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-1-py3 % python3 server3.py   </span><br><span class="line">HTTP server started on port 8080</span><br><span class="line">Query received @ t2019-02-10 10:07:43.237974</span><br><span class="line">Query received @ t2019-02-11 18:12:31.763344</span><br><span class="line">Query received @ t2019-02-13 00:41:03.061658</span><br><span class="line">Query received @ t2019-02-13 19:37:03.654348</span><br><span class="line">Query received @ t2019-02-14 08:26:51.287677</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p><em>Client </em><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xiaxii@cecilias-mbp JPMC-tech-task-1-py3 % python3 client3.py</span><br><span class="line">Quoted ABC at (bid:118.13, ask:116.63, price:118.13)</span><br><span class="line">Quoted DEF at (bid:115.14, ask:117.87, price:115.14)</span><br><span class="line">Ratio 1</span><br><span class="line">Quoted ABC at (bid:118.13, ask:116.63, price:118.13)</span><br><span class="line">Quoted DEF at (bid:115.14, ask:117.87, price:115.14)</span><br><span class="line">Ratio 1</span><br><span class="line">Quoted ABC at (bid:118.13, ask:116.63, price:118.13)</span><br><span class="line">Quoted DEF at (bid:115.14, ask:117.87, price:115.14)</span><br><span class="line">Ratio 1</span><br><span class="line">Quoted ABC at (bid:118.13, ask:116.63, price:118.13)</span><br><span class="line">Quoted DEF at (bid:115.14, ask:117.51, price:115.14)</span><br><span class="line">Ratio 1</span><br><span class="line">Quoted ABC at (bid:118.13, ask:116.63, price:118.13)</span><br><span class="line">Quoted DEF at (bid:115.14, ask:117.51, price:115.14)</span><br><span class="line">Ratio 1</span><br></pre></td></tr></table></figure></p>
<p><strong>Troubleshooting</strong>:<br>AttributeError: module ‘urllib’ has no attribute ‘urlopen’<br><strong>Solution</strong>:<br>import urllib.<strong>request</strong><br>urllib.<strong>request</strong>.urlopen(…)</p>
<h3 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a><strong>Objectives</strong></h3><p>There are two incorrect things…</p>
<ol>
<li>Ratio is always 1</li>
<li>The price of each stock is always the same as its bid_price.</li>
</ol>
<p>Making changes to client3.py</p>
<p>(1) <strong>getDataPoint</strong>, change price<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">price = (bid_price + ask_price)/2.</span><br></pre></td></tr></table></figure></p>
<p>(2) <strong>getRatio</strong>, change the return<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if (price_b==0): # avoid ZeroDivisionError</span><br><span class="line">	return</span><br><span class="line">return price_a/price_b</span><br></pre></td></tr></table></figure></p>
<p>(3) <strong>main</strong>, change<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line"></span><br><span class="line">	# Query the price once every N seconds.</span><br><span class="line">	# Get a price directory where the key-value pair is stock name-price</span><br><span class="line">	for _ in range(N):</span><br><span class="line">		quotes = json.loads(urllib.request.urlopen(QUERY.format(random.random())).read())</span><br><span class="line"></span><br><span class="line">		prices = &#123;&#125;</span><br><span class="line">		&quot;&quot;&quot; ----------- Update to get the ratio --------------- &quot;&quot;&quot;</span><br><span class="line">		for quote in quotes:</span><br><span class="line">			stock, bid_price, ask_price, price = getDataPoint(quote)</span><br><span class="line">			prices[stock] = price</span><br><span class="line">			print (&quot;Quoted %s at (bid:%s, ask:%s, price:%s)&quot; % (stock, bid_price, ask_price, price))</span><br><span class="line"></span><br><span class="line">		print (&quot;Ratio %s&quot; % (getRatio(prices[&apos;ABC&apos;],prices[&apos;DEF&apos;])))</span><br></pre></td></tr></table></figure></p>
<h3 id="Finished"><a href="#Finished" class="headerlink" title="Finished"></a>Finished</h3><p>Run client3.py:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Quoted ABC at (bid:126.12, ask:125.84, price:125.98)</span><br><span class="line">Quoted DEF at (bid:124.66, ask:125.15, price:124.905)</span><br><span class="line">Ratio 1.008606540971138</span><br><span class="line">Quoted ABC at (bid:126.12, ask:125.84, price:125.98)</span><br><span class="line">Quoted DEF at (bid:124.66, ask:125.15, price:124.905)</span><br><span class="line">Ratio 1.008606540971138</span><br><span class="line">Quoted ABC at (bid:126.12, ask:125.05, price:125.58500000000001)</span><br><span class="line">Quoted DEF at (bid:124.66, ask:125.15, price:124.905)</span><br><span class="line">Ratio 1.005444137544534</span><br><span class="line">Quoted ABC at (bid:126.12, ask:125.05, price:125.58500000000001)</span><br><span class="line">Quoted DEF at (bid:124.66, ask:125.15, price:124.905)</span><br><span class="line">Ratio 1.005444137544534</span><br><span class="line">Quoted ABC at (bid:126.12, ask:125.05, price:125.58500000000001)</span><br><span class="line">Quoted DEF at (bid:124.66, ask:125.05, price:124.85499999999999)</span><br><span class="line">Ratio 1.0058467822674304</span><br></pre></td></tr></table></figure></p>
<h2 id="Bonus-Task-Unit-Test"><a href="#Bonus-Task-Unit-Test" class="headerlink" title="Bonus Task: Unit Test"></a>Bonus Task: Unit Test</h2><h2 id="Pattern-Build-Act-Assert"><a href="#Pattern-Build-Act-Assert" class="headerlink" title="Pattern - Build-Act-Assert:"></a>Pattern - <strong>Build-Act-Assert</strong>:</h2><ul>
<li><strong>Build</strong>: We first build a simulated test scenario e.g. instantiating the dummy data we will pass in the methods we’ll test, importing the class<br>whose methods we want to test, etc.</li>
<li><strong>Act</strong>: We then make some operations and call the method we want to test for</li>
<li><strong>Assert</strong>: We check if the output of the method we’re testing matches the expectation we have (e.g. dummy / static data of the outcome)</li>
</ul>
<h2 id="Unittest"><a href="#Unittest" class="headerlink" title="Unittest"></a>Unittest</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import unittest</span><br><span class="line"></span><br><span class="line">class xxxTest(unittest.TestCase):</span><br><span class="line"></span><br><span class="line">    def test1(self):</span><br><span class="line">        self.assertEqual(xx, xxxxx)</span><br><span class="line"></span><br><span class="line">    def test2(self):</span><br><span class="line">        self.assertTrue(xxxxx)</span><br><span class="line">        self.assertFalse(xxxxxx)</span><br><span class="line"></span><br><span class="line">    def test3(self):</span><br><span class="line">        self.assertEqual(xxx, xxxx)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    unittest.main()</span><br></pre></td></tr></table></figure>
<p>A testcase is created by subclassing <code>unittest.TestCase</code>. The three individual tests are defined with methods whose names start with the letters <code>test</code>. This naming convention informs the test runner about which methods represent tests.</p>
<h2 id="Submit-Patch-file"><a href="#Submit-Patch-file" class="headerlink" title="Submit Patch file"></a>Submit Patch file</h2><ol>
<li><p>git<br>git is a way for developers to manage code in a project especially if there’s other developers collaborating in that project too.</p>
</li>
<li><p>git patch<br>A git patch file is just a file that you can apply to a repository to get the changes / modifications / additions another developer did on his / her machine onto your local machine.<br>This isn’t the only way to do that ofcourse but this is a viable method for a head/lead developer to check your code first before merging it into the repository’s main/master branch.</p>
</li>
<li><p>Make a git patch file<br>Fire up a terminal, enter the repository via the terminal you opened (via the cd <repo_name_here> aka change directory command) and do the following commands: (one line, one command)</repo_name_here></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add -A</span><br><span class="line">git config user.email &quot;&lt;your_email_address&gt;&quot;</span><br><span class="line">git config user.name &quot;&lt;your_name&gt;&quot;</span><br><span class="line">git commit -m &apos;Create Patch File&apos;</span><br><span class="line">git format-patch -1 HEAD</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The final command, i.e. git format-patch -1 HEAD, should produce the .patch file you’d want to submit to complete this module. It will be located in the directory where you executed the command.</p>
<p>Other Assertions:<br>self.assertIsNone()<br>self.assertGreater(a, b)  …a&gt;b<br>self.assertLess(a, b)     …a&lt;b<br>self.assertRaises(TypeError)</p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>Product Questions</title>
    <url>/2020/05/10/Product-Questions/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Cracking-the-PM-interview-—-Product-Questions"><a href="#Cracking-the-PM-interview-—-Product-Questions" class="headerlink" title="Cracking the PM interview — Product Questions"></a>Cracking the PM interview — Product Questions</h1><p>Good framework have the following characteristics:</p>
<ol>
<li>Ask appropriate questions</li>
<li>Understand and assess a goal</li>
<li>Apply a structured approach to accomplish the goal<a id="more"></a>
</li>
</ol>
<h2 id="Type-1-Designing-a-product"><a href="#Type-1-Designing-a-product" class="headerlink" title="Type 1: Designing a product"></a>Type 1: Designing a product</h2><h3 id="Step-1-Ask-questions-to-understand-the-problem"><a href="#Step-1-Ask-questions-to-understand-the-problem" class="headerlink" title="Step 1: Ask questions to understand the problem."></a>Step 1: Ask questions to understand the problem.</h3><p>“What, who, why, where, how” For example, design a pen, what kind of pen? A pen for whom? Why do we need it (what’s the goal?) How is it special (special features)? Where to launch?</p>
<h3 id="Step-2-Provide-a-structure"><a href="#Step-2-Provide-a-structure" class="headerlink" title="Step 2: Provide a structure"></a>Step 2: Provide a structure</h3><p>“First, I’m going to talk about the goals. Then, I’m going to list out some potential features. Finally, I’m going to evaluate each of those features against the goals. Okay, starting with the goals…”</p>
<h3 id="Step-3-Identify-the-users-and-customers"><a href="#Step-3-Identify-the-users-and-customers" class="headerlink" title="Step 3: Identify the users and customers"></a>Step 3: Identify the users and customers</h3><p>In some cases, users and customers aren’t the same person. The customer is the person paying for the product; the user is the one using it. There also may be multiple users. (e.g. Design a calculator, the potential users or customers may be the child, the teacher and the parent. Design a better stove, the users may be novice cooks, advanced cooks, children, elderly or disabled.)<br>Think carefully about what makes this type of user special</p>
<h3 id="Step-4-What-are-the-use-cases-Why-are-they-using-this-product-What-are-their"><a href="#Step-4-What-are-the-use-cases-Why-are-they-using-this-product-What-are-their" class="headerlink" title="Step 4: What are the use cases? Why are they using this product? What are their"></a>Step 4: What are the use cases? Why are they using this product? What are their</h3><p>For each user, make a list of the use cases.<br>Then assess, which use cases to design for.</p>
<h3 id="Step-5-How-well-is-the-current-product-doing-for-their-use-cases-Are-there-obvious-weak-spots"><a href="#Step-5-How-well-is-the-current-product-doing-for-their-use-cases-Are-there-obvious-weak-spots" class="headerlink" title="Step 5: How well is the current product doing for their use cases? Are there obvious weak spots?"></a>Step 5: How well is the current product doing for their use cases? Are there obvious weak spots?</h3><p>Go through each use case and assess how well the current products or solutions address those.</p>
<h3 id="Step-6-What-features-or-changes-would-improve-those-weak-spots"><a href="#Step-6-What-features-or-changes-would-improve-those-weak-spots" class="headerlink" title="Step 6: What features or changes would improve those weak spots?"></a>Step 6: What features or changes would improve those weak spots?</h3><p>Name a few ideas and then ask the interviewer if they want you to dive deeper into any of them.<br>Explicitly tie your feature ideas to the use cases or goals. Make it really, really customer focused.</p>
<h3 id="Step-7-Wrap-things-up"><a href="#Step-7-Wrap-things-up" class="headerlink" title="Step 7: Wrap things up"></a>Step 7: Wrap things up</h3><p>Give the interviewer an overview of your solution.</p>
<h2 id="Type-2-Improving-a-product"><a href="#Type-2-Improving-a-product" class="headerlink" title="Type 2: Improving a product"></a>Type 2: Improving a product</h2><p>“Let me start first with understanding the goals of the product, then move on to the issues and how to solve those. Okay, so the goals of the product are…”</p>
<h3 id="Step-1-What-is-the-goal-of-the-product"><a href="#Step-1-What-is-the-goal-of-the-product" class="headerlink" title="Step 1: What is the goal of the product?"></a>Step 1: What is the goal of the product?</h3><p>What’s the product’s ultimate goal? What problem is it solving for the user?</p>
<h3 id="Step-2-What-problems-does-the-product-face"><a href="#Step-2-What-problems-does-the-product-face" class="headerlink" title="Step 2: What problems does the product face?"></a>Step 2: What problems does the product face?</h3><p>Need to expand user base? Increase revenue? Increase user engagement? Increase conversions?</p>
<h3 id="Step-3-How-would-you-solve-this-problem"><a href="#Step-3-How-would-you-solve-this-problem" class="headerlink" title="Step 3: How would you solve this problem?"></a>Step 3: How would you solve this problem?</h3><p>Brainstorm a few ways, discuss pros and cons, be open about the tradeoffs of each option<br>Can be bold, crazy ideas, or they might be small, iterative improvements. Consider company size, risk tolerance, budget, culture.<br>You can say like this: “We can make a few quick fixes that will help mitigate the issues. However, if we are willing to take a bigger gamble, some additional options are open to us.”</p>
<h3 id="Step-4-How-would-you-implement-these-solutions"><a href="#Step-4-How-would-you-implement-these-solutions" class="headerlink" title="Step 4: How would you implement these solutions?"></a>Step 4: How would you implement these solutions?</h3><p>What’s the plan to implement? What’s the challenges? How would you reduce costs and risks? (Maybe you want to roll out to a small group of users first).</p>
<h3 id="Step-5-How-would-you-validate-your-solution"><a href="#Step-5-How-would-you-validate-your-solution" class="headerlink" title="Step 5: How would you validate your solution?"></a>Step 5: How would you validate your solution?</h3><p>What metrics you would gather to see if your solution really worked.</p>
<h2 id="Type-3-Favourite-product"><a href="#Type-3-Favourite-product" class="headerlink" title="Type 3: Favourite product"></a>Type 3: Favourite product</h2><p>Step 1: What problems does the product solve for the user?<br>Step 2: How does the product accomplish these goals? What makes user fall in love with the product?<br>Step 3: How does it compare to alternatives?<br>Step 4: How would you improve it?</p>
<h1 id="Frameworks"><a href="#Frameworks" class="headerlink" title="Frameworks"></a>Frameworks</h1><h2 id="Personal-Experiences-–-STAR"><a href="#Personal-Experiences-–-STAR" class="headerlink" title="Personal Experiences – STAR"></a>Personal Experiences – STAR</h2><p>Situation, Task, Action, Result</p>
<h2 id="Marketing-–-4Ps"><a href="#Marketing-–-4Ps" class="headerlink" title="Marketing – 4Ps"></a>Marketing – 4Ps</h2><p>Product, Price, Promotion, Place</p>
<h2 id="Opportunity-amp-Strategy-SWOT"><a href="#Opportunity-amp-Strategy-SWOT" class="headerlink" title="Opportunity &amp; Strategy - SWOT"></a>Opportunity &amp; Strategy - SWOT</h2><p>(For a company or a product)<br>Internal: Strength, Weakness;<br>External: Opportunity, Threat</p>
<h2 id="Situation-–-5Cs"><a href="#Situation-–-5Cs" class="headerlink" title="Situation – 5Cs"></a>Situation – 5Cs</h2><p>company，competitor，customer，collaborators，climate</p>
<h2 id="Industrial-Environment-–-Porter’s-5-Forces"><a href="#Industrial-Environment-–-Porter’s-5-Forces" class="headerlink" title="Industrial Environment – Porter’s 5 Forces"></a>Industrial Environment – Porter’s 5 Forces</h2><p><img src="https://i2.wp.com/www.business-to-you.com/wp-content/uploads/2017/04/Five-Forces-Model-Porter.png" alt="Porter&#39;s 5 Forces"></p>
<ol>
<li>Threat of new entrants</li>
<li>Threat of substitutes</li>
<li>Bargaining power of customers</li>
<li>Bargaining power of suppliers</li>
<li>Competitive rivalry</li>
</ol>
<h2 id="Product-Design-–-CIRCLES"><a href="#Product-Design-–-CIRCLES" class="headerlink" title="Product Design – CIRCLES"></a>Product Design – CIRCLES</h2><p><img src="https://i1.wp.com/sattvainc.com/wp-content/uploads/2018/12/product-management-circles-method.png?w=602&amp;ssl=1" alt="CIRCLES"></p>
<h3 id="Comprehend"><a href="#Comprehend" class="headerlink" title="Comprehend:"></a>Comprehend:</h3><p>You’re entitled to ask the interviewer clarifying questions. What can or should you ask the interviewer? Here’s a list:</p>
<ul>
<li>What is it?</li>
<li>Who is it for?</li>
<li>Why do they need it?</li>
<li>When is it available?</li>
<li>Where is it available?</li>
<li>How does it work?</li>
</ul>
<p>This list of basic questions is frequently called the “5W’s and H.” However, the interviewer may not have patience for you to ask 101 questions about the product. To start the interview, you really just need answers for the four bolded questions: what is it, who is it for, why do they need it, and how does it work? So we’ll call our version the “3W’s and H.”<br>If the interviewer refuses to answer your clarifying questions, make an assumption based on what you know. Then, give the interviewer an opportunity to correct you, in the event he thinks differently about whom it is for or how the product works.</p>
<h3 id="Identify-customers"><a href="#Identify-customers" class="headerlink" title="Identify customers:"></a>Identify customers:</h3><p><strong>Product design questions</strong></p>
<ul>
<li>Define an objective for the product improvement</li>
<li>Choose and identify the most appropriate target customer</li>
<li>Empathize with the target customer</li>
<li>Articulate use cases (aka pain points)</li>
<li>Prioritize those use cases</li>
<li>Brainstorm creative ideas</li>
<li>Make a logical recommendation</li>
</ul>
<p><strong>Examples of product design questions</strong></p>
<ul>
<li>Redesign the Facebook Newsfeed for the Web.</li>
<li>How would you improve Pinterest?</li>
<li>Create an experience around Disney theme parks using your phone.</li>
<li>Design the next product that Nest will offer, focusing on mobile app design.</li>
<li>If you were the CEO of LEGO, what new product line would you come up with to increase revenues? Why? Who is the target customer? How do you reach them? How does the product function and what does it look like (UI/UX)? What’s the potential market size?</li>
</ul>
<p><strong>What are interviewers looking for?</strong></p>
<ul>
<li>Goals and metrics. Did the candidate define objectives before answering? Were the candidate’s selections reasonable?</li>
<li>Target Persona &amp; Pain Points. Did the candidate choose a target persona? Did the candidate explain the persona’s pain points to the extent that demonstrated true consumer insight?</li>
<li>Prioritization. Did the candidate demonstrate ability to prioritize competing use cases or pain points in a compelling way?</li>
<li>Creativity. Did the candidate demonstrate sufficient creativity? Or were the ideas copycats of competitive features and products?</li>
<li>Development Leadership. When asked, did the candidate have a reasonable explanation of how a proposed feature would be implemented?</li>
<li>Summary and Next Steps. Did the candidate summarize their main argument at the end, including clear next steps?</li>
</ul>
<h2 id="Product-Metrics-–-AARM"><a href="#Product-Metrics-–-AARM" class="headerlink" title="Product Metrics – AARM"></a>Product Metrics – AARM</h2><ol>
<li><strong>Acquisition</strong>: Tracking customer signups for a service. The bar for signing up for a service has gotten lower and lower, thanks to the popularity of free signup and pay later “freemium” models. The typical acquisition metric to track is lazy registrations or app downloads.</li>
<li><strong>Activation</strong>: Getting users that have completed a lazy registration to register fully. For a social networking site like Google+, this may include uploading a photo or completing their profile page.</li>
<li><strong>Retention</strong>: Getting users to use the service often and behave in a way that helps the user or business. Key metrics include adding more information to their profile page, checking the news feed frequently or inviting friends to try the service.</li>
<li><strong>Monetization</strong>: Collecting revenue from users. It could include the number of people who are paying for the service or the average revenue per user (ARPU).</li>
</ol>
]]></content>
      <categories>
        <category>Management</category>
      </categories>
  </entry>
  <entry>
    <title>Environment on server</title>
    <url>/2020/04/04/Environment-on-server/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Login to my server: </p>
<pre><code class="lang-bash">ssh xx306@login.student.eecs.qmul.ac.uk -A
</code></pre>
<a id="more"></a>
<h1 id="Installations"><a href="#Installations" class="headerlink" title="Installations"></a>Installations</h1><h2 id="Download-Anoconda"><a href="#Download-Anoconda" class="headerlink" title="Download Anoconda"></a>Download Anoconda</h2><pre><code class="lang-bash">wget https://repo.anaconda.com/Anaconda2-2019.10-Linux-x86_64.sh
</code></pre>
<p>Note: anoconda version xxx see <a href="https://repo.continuum.io/archive/" target="_blank" rel="noopener">Anaconda installer archive</a></p>
<h2 id="Install-Anoconda"><a href="#Install-Anoconda" class="headerlink" title="Install Anoconda"></a>Install Anoconda</h2><pre><code class="lang-bash">bash Anaconda2-2019.10-Linux-x86_64.sh
</code></pre>
<h2 id="Source-bash-file"><a href="#Source-bash-file" class="headerlink" title="Source bash file"></a>Source bash file</h2><pre><code class="lang-bash">source ~/.bashrc
</code></pre>
<h2 id="Install-Jupyter"><a href="#Install-Jupyter" class="headerlink" title="Install Jupyter"></a>Install Jupyter</h2><pre><code class="lang-bash">conda install jupyter notebook
</code></pre>
<h1 id="Configure-Jupyter"><a href="#Configure-Jupyter" class="headerlink" title="Configure Jupyter"></a>Configure Jupyter</h1><pre><code class="lang-bash">(base) -bash-4.2$ jupyter notebook --generate-config
Overwrite /homes/xx306/.jupyter/jupyter_notebook_config.py with default config? [y/N]y
Writing default config to: /homes/xx306/.jupyter/jupyter_notebook_config.py
</code></pre>
<h2 id="set-password"><a href="#set-password" class="headerlink" title="set password"></a>set password</h2><pre><code class="lang-bash">(base) -bash-4.2$ python
Python 3.7.4 (default, Aug 13 2019, 20:35:49) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
</code></pre>
<pre><code class="lang-python">&gt;&gt;&gt; from notebook.auth import passwd 
&gt;&gt;&gt; passwd()
Enter password: 
Verify password: 
&#39;sha1:eb021e5e0da0:57be9ff1fe2075e2afc8591cea27c286f75190d0&#39;
</code></pre>
<h2 id="copy-this-key-exit-python-then"><a href="#copy-this-key-exit-python-then" class="headerlink" title="copy this key, exit () python, then:"></a>copy this key, exit () python, then:</h2><pre><code class="lang-bash">vim /homes/xx306/.jupyter/jupyter_notebook_config.py
</code></pre>
<h2 id="modify-the-following-lines"><a href="#modify-the-following-lines" class="headerlink" title="modify the following lines:"></a>modify the following lines:</h2><pre><code class="lang-bash">c.NotebookApp.ip=&#39;*&#39; 
#设置访问notebook的ip，*表示所有IP

c.NotebookApp.password = u&#39;sha1:eb021e5e0da0:57be9ff1fe2075e2afc8591cea27c286f75190d0&#39; 
#填写刚刚复制的密钥 

c.NotebookApp.open_browser = False 
# 禁止notebook启动时自动打开浏览器

c.NotebookApp.allow_remote_access = True
#允许远程连接

c.NotebookApp.port =8889 
#指定访问的端口，默认是8888。
</code></pre>
<h1 id="Start-Jupyter"><a href="#Start-Jupyter" class="headerlink" title="Start Jupyter"></a>Start Jupyter</h1><pre><code class="lang-bash">(base) -bash-4.2$ jupyter notebook --no-browser --port=8889
</code></pre>
<pre><code class="lang-bash">[I 12:07:23.759 NotebookApp] JupyterLab extension loaded from /homes/xx306/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 12:07:23.759 NotebookApp] JupyterLab application directory is /homes/xx306/anaconda3/share/jupyter/lab
[I 12:07:23.762 NotebookApp] Serving notebooks from local directory: /homes/xx306
[I 12:07:23.762 NotebookApp] The Jupyter Notebook is running at:
[I 12:07:23.762 NotebookApp] http://localhost:8889/?token=1d84255f936647f2f642dbe9f89ac830d6ab9604770f8741
[I 12:07:23.762 NotebookApp]  or http://127.0.0.1:8889/?token=1d84255f936647f2f642dbe9f89ac830d6ab9604770f8741
[I 12:07:23.763 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 12:07:23.808 NotebookApp] 

    To access the notebook, open this file in a browser:
        file:///homes/xx306/.local/share/jupyter/runtime/nbserver-5513-open.html
    Or copy and paste one of these URLs:
        http://localhost:8889/?token=1d84255f936647f2f642dbe9f89ac830d6ab9604770f8741
     or http://127.0.0.1:8889/?token=1d84255f936647f2f642dbe9f89ac830d6ab9604770f8741
</code></pre>
<p>open a local Terminal and type in </p>
<pre><code class="lang-bash">ssh -N -f -L localhost:8888:localhost:8889 xx306@login.student.eecs.qmul.ac.uk
</code></pre>
<p>Now open web browser (google chrome, firefox, …) and type <code>localhost:8888</code><br>We can see the Jupyter Application Site.</p>
<p>Then we see on the server terminal </p>
<pre><code class="lang-bash">[I 12:10:06.006 NotebookApp] 302 GET / (::1) 1.09ms
...
...
...
</code></pre>
<p>Login to Jupyter Notebook with the token shown in the Server Terminal</p>
<h1 id="Change-Jupyter-Kernel"><a href="#Change-Jupyter-Kernel" class="headerlink" title="Change Jupyter Kernel"></a>Change Jupyter Kernel</h1><h2 id="list-current-kernels"><a href="#list-current-kernels" class="headerlink" title="list current kernels"></a>list current kernels</h2><pre><code class="lang-bash">jupyter kernelspec list
</code></pre>
<h2 id="New-environment"><a href="#New-environment" class="headerlink" title="New environment"></a>New environment</h2><pre><code class="lang-bash">conda create -n py27 python=2.7.
</code></pre>
<h2 id="Activate"><a href="#Activate" class="headerlink" title="Activate"></a>Activate</h2><pre><code class="lang-bash">source activate py27
</code></pre>
<h2 id="Install-the-kernel"><a href="#Install-the-kernel" class="headerlink" title="Install the kernel"></a>Install the kernel</h2><pre><code class="lang-bash">conda install ipykernel
</code></pre>
<h1 id="Install-Packages"><a href="#Install-Packages" class="headerlink" title="Install Packages"></a>Install Packages</h1><pre><code class="lang-bash">conda install pandas
</code></pre>
<p>or do </p>
<pre><code class="lang-bash">conda config --append channels conda-forge
</code></pre>
<p>before installing with </p>
<pre><code class="lang-bash">conda install pandas
</code></pre>
<h1 id="Usage-Routine"><a href="#Usage-Routine" class="headerlink" title="Usage Routine"></a>Usage Routine</h1><p>Login to server:</p>
<pre><code class="lang-bash">ssh xx306@login.student.eecs.qmul.ac.uk -A
jupyter notebook --no-browser --port=8889
</code></pre>
<p>open a local Terminal and type in </p>
<pre><code class="lang-bash">ssh -N -f -L localhost:8888:localhost:8889 xx306@login.student.eecs.qmul.ac.uk
</code></pre>
<p>Open <code>localhost:8888</code>  on browser and login to the Jypyter Notebook with the randomly generated tocken.</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p><a href="https://www.jianshu.com/p/a85bc2a8fa56" target="_blank" rel="noopener">Jupyter-NoteBook-你应该知道的N个小技巧</a></p>
<h1 id="Local-Environment"><a href="#Local-Environment" class="headerlink" title="Local Environment"></a>Local Environment</h1><p>similar but without ssh steps</p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>The Eagle Project</title>
    <url>/2020/02/09/The-Eagle-Project-Review/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://github.com/QT-Zhu/Eagle_System/raw/master/illustration/logo.png" alt="logo"></p>
<h1 id="“The-Eagle”-Remote-Sensing-Reconnaissance-System"><a href="#“The-Eagle”-Remote-Sensing-Reconnaissance-System" class="headerlink" title="“The Eagle” Remote Sensing Reconnaissance System"></a>“The Eagle” Remote Sensing Reconnaissance System</h1><p><strong>2018 Google - China MoE University-Industry Collaboration Program</strong></p>
<p>This project intends to adopt a <strong><em>light-weight compression deep learning algorithm</em></strong>, based on Google open source artificial intelligence learning system <strong>TensorFlow</strong>, to propose and implement a set of intelligent processing solutions for mobile remote sensing images (<strong>target detection and semantic segmentation</strong>) on the mobile artificial intelligence computing platform. </p>
<p>The mobile platform can be carried on the satellite to realize on-orbit <strong>real-time remote sensing</strong> image information extraction, which provides a basis for subsequent data classification and efficient retrieval, and can filter the target <strong>data of interest</strong> according to user instructions for downlink transmission, thereby greatly reducing data. The transmission volume, alleviating the bandwidth pressure of the network link, reducing the energy consumption of data transmission, improving the targeting of the downlink data and the timeliness of information acquisition.</p>
<p>Video Preview:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/C8QW7MbQf-g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<a id="more"></a>
<h2 id="Timeline-and-Outcomes"><a href="#Timeline-and-Outcomes" class="headerlink" title="Timeline and Outcomes"></a>Timeline and Outcomes</h2><p><strong>2018.05</strong> Project Started<br><strong>2018.06</strong> Attending in 2018 Internet+ Innovation &amp; Start-up Competition<br><strong>2018.07</strong> Won the Third-class award in 2018 Internet+ Innovation &amp; Start-up Competition<br><strong>2018.09</strong> Attending in 2018 AI+ Innovation &amp; Start-up Competition (report accessable on <a href="https://github.com/xiaxii/MarkdownMedia/blob/master/Project%20Report_%22Internet%2B%22%20Competition.pdf" target="_blank" rel="noopener">GitHub</a>)<br><strong>2018.10</strong> Won the Third-Class Most Innovative Award in 2018 AI+ Innovation &amp; Start-up Competition<br><strong>2019.05</strong> Won the National Second-Class Award in 2019 National College Student Innovation and Entrepreneurship Competition<br><strong>2019.08.02</strong> Oral presentation on <a href="https://igarss2019.org/Papers/ViewPapers.asp?PaperNum=4321" target="_blank" rel="noopener">IGARSS19</a><br><strong>2019.11.14</strong> Paper “Efficient Multi-Class Semantic Segmentation of High Resolution Aerial Imagery with Dilated LinkNet” was added to <a href="https://ieeexplore.ieee.org/document/8900281" target="_blank" rel="noopener">IEEE Xplore</a></p>
<p><strong>Code on <a href="https://github.com/QT-Zhu/Eagle_System" target="_blank" rel="noopener">GitHub</a></strong> (managed by <a href="https://qt-zhu.github.io/" target="_blank" rel="noopener">Qingtian Zhu</a>)</p>
<h2 id="Group-members"><a href="#Group-members" class="headerlink" title="Group members"></a>Group members</h2><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/The%20Eagle%20Group%20Pic.JPG" alt="Group"><br><strong>Xi XIA</strong>, Junli Yang(Supervisor), Xingyi Li, Qingtian Zhu(Leader), Haoran Cui, Yulai Jiang, Yuming Zheng (happen to be absent)</p>
<p>This photo was taken in the Innovation Center of Beijing University of Posts and Telecommunications.</p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
  </entry>
  <entry>
    <title>The Age of Social Sensing</title>
    <url>/2020/01/22/The-Age-of-Social-Sensing/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>Reference: <a href="https://www3.nd.edu/~sslab/pdf/computer-18.pdf" target="_blank" rel="noopener">The Age of Social Sensing</a><br>1st paper review for 2019 <a href="https://international.nd.edu/students-scholars/global-engagement-programs/summer-programs/isure/" target="_blank" rel="noopener">iSURE</a> @ <a href="https://www3.nd.edu/~sslab/" target="_blank" rel="noopener">Social Sensing Lab at University of Notre Dame</a>.</p>
</blockquote>
<p><strong><em>Social Sensing</em></strong> aims to better understand the <strong>physical world</strong> through <strong>social networks</strong>. The challenge is  how to extract information form the medium and find appropriate properties to characterize the extracted information and the world it represents.</p>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Technology:</strong> physical technological sensors and social media.<br><strong>Today’s challenge:</strong> find and understand the valuable and truthful messages in the much larger volume of social media content.</p>
<p><strong>Collective intelligence(群智):</strong><br>human intelligence is derived from reflexive reasoning, with language being the semantic indexing scheme into the arguments and results.<br><strong>Information Economy Meta Language (IEML):</strong><br>empower reflexivity, facilitate discovery of semantic ties, and document information provenance (using blockchain-like technologies) to keep track of the origins of ideas and preserve the collective reasoning behind them.</p>
<p><strong>Focus:</strong> physical (social) reality<br><strong>Better algorithms:</strong>  to curb misrepresentation of physical reality and help build smarter urban services.</p>
<p><strong>Two perspective of challenge:</strong></p>
<ol>
<li>challenge in the cyber-physical space </li>
<li>challenge in the social and linguistic space </li>
</ol>
<h2 id="Cyber-physical-challenges-in-social-spaces"><a href="#Cyber-physical-challenges-in-social-spaces" class="headerlink" title="Cyber-physical challenges in social spaces"></a>Cyber-physical challenges in social spaces</h2><p>Understanding attributes of social sensing systems requires modeling three interdependent components</p>
<ol>
<li>the humans in the loop and their cognitive models</li>
<li>the algorithms involved</li>
<li>the laws of nature that govern the underlying physical and engineered artifacts.This may  requires interdisciplinary approaches to address the complex <strong>interaction between cyber, physical and social components</strong> of the holistic system.</li>
</ol>
<h3 id="Modeling-instrument-distortion-4-broad-categories"><a href="#Modeling-instrument-distortion-4-broad-categories" class="headerlink" title="Modeling instrument distortion (4 broad categories)"></a>Modeling instrument distortion (4 broad categories)</h3><ul>
<li>Intentional disinformation.</li>
<li><strong>Personal conclusions not sufficiently supported by data or observations</strong>, which might resonate with other people’s biases and propagate further as facts.</li>
<li><strong>Biased interpretations by communities</strong> of people with similar opinions.</li>
<li>Genuine <strong>random mistakes</strong> by people processing information, such as misspelling and typos.</li>
</ul>
<h3 id="Understanding-the-signal"><a href="#Understanding-the-signal" class="headerlink" title="Understanding the signal"></a>Understanding the signal</h3><p>Physical events trigger responses in the social media.  <strong>Humans work as “sensors” in this process.</strong><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/The%20social%20sensing%20modality%3B%20an%20analogy.png" alt="The social sensing modality: an analogy"><br>e.g. Use Twitter as a data source viewed statements about physical reality as a binary signal.( 1 for truth, 0 for rumors)</p>
<h3 id="Quantifying-data-reliability-and-performance-bounds"><a href="#Quantifying-data-reliability-and-performance-bounds" class="headerlink" title="Quantifying data reliability and performance bounds"></a>Quantifying data reliability and performance bounds</h3><h4 id="Estimation-theory"><a href="#Estimation-theory" class="headerlink" title="Estimation theory"></a>Estimation theory</h4><p>To build the error of an optimal estimator:</p>
<ol>
<li>Represent social media as noisy binary communication channels.</li>
<li>Estimation-theoretical frameworks are applied to the reliability analysis of data cleaning system.</li>
</ol>
<p>e.g. exploit expressions of <strong>error bounds of maximum-likelihood estimators</strong> to assess <strong>the quality of estimation results on social media</strong>.</p>
<h4 id="Two-factors-complicates-the-analysis"><a href="#Two-factors-complicates-the-analysis" class="headerlink" title="Two factors complicates the analysis"></a>Two factors complicates the analysis</h4><ol>
<li><strong>Correlated errors</strong> that result from rumor-spreading behaviors — A person reports as their own observations from others without verification.</li>
<li><strong>The expressed degree</strong> of vagueness in humans observations. The degree of confidence is low when people use words like “possibly” and “might”.</li>
</ol>
<p>The conversion of <strong>natural language expressions</strong> of vagueness to <strong>quantifiable numbers</strong> is a very difficult problem that remains to be fully solved</p>
<h3 id="The-role-of-dependencies-between-sources"><a href="#The-role-of-dependencies-between-sources" class="headerlink" title="The role of dependencies between sources"></a>The role of dependencies between sources</h3><p>Dependency can be found in social networks. (e.g. follower-followee relationship on Twitter and friends relation-ship on Facebook.)The complex and dynamic source <strong>dependency graphs</strong> on social networks deserve more investigation.</p>
<h4 id="Recent-work"><a href="#Recent-work" class="headerlink" title="Recent work"></a>Recent work</h4><ol>
<li>develop source selection schemes to carefully <strong>select independent sources</strong> on social networks or </li>
<li>build reliable social sensing models to explicitly <strong>model the source dependency</strong> into the social signal processing engine</li>
</ol>
<h3 id="Understanding-communities-social-trust-and-polarization"><a href="#Understanding-communities-social-trust-and-polarization" class="headerlink" title="Understanding communities, social trust and polarization"></a>Understanding communities, social trust and polarization</h3><h4 id="Communities-and-social-Trust"><a href="#Communities-and-social-Trust" class="headerlink" title="Communities and social Trust"></a>Communities and social Trust</h4><p>Humans interact, operate, exchange and propagate information much more frequently within the communities than across them. Communities increase level of <strong>homophily</strong> among their members. People in the same community often <strong>share opinions and biases</strong>. It’s a key notion to understand information reliability.<br>People are likely to re-broadcast when:</p>
<ol>
<li>The information is from a source they trust.</li>
<li>They agree with the opinion.</li>
</ol>
<p>Thus, <strong>trust relations and biases of sources</strong> can be observed from the propagation patterns of information.</p>
<h4 id="Polarization"><a href="#Polarization" class="headerlink" title="Polarization"></a>Polarization</h4><p>When polarization is considered, the <strong>reconstruction</strong> from social observation tends to align more closely with <strong>ground truth in the physical world</strong>.</p>
<h3 id="Fusion-of-physical-and-social-sensors"><a href="#Fusion-of-physical-and-social-sensors" class="headerlink" title="Fusion of physical and social sensors"></a>Fusion of physical and social sensors</h3><p>Social networks can be viewd as an additional sensing resource of physical sensors.<br>Decision-makers will act on the data in ways that impact the physical state being observed. Hence, an interesting question is to understand what information to present to the decision-maker (and how) in order to offer the best decision-support despite the inherent noise in the underlying social channel.</p>
<h2 id="Challenges-in-the-linguistic-space"><a href="#Challenges-in-the-linguistic-space" class="headerlink" title="Challenges in the linguistic space"></a>Challenges in the linguistic space</h2><p>To understand social media content, we need to seek advances in rapid low-cost development of <strong>Information Extraction (IE) and Text Mining technologies</strong>.</p>
<p><strong>Basis of today’s language processing technologies</strong>:</p>
<ol>
<li>Supervised learning: suffers from high cost of large-scale manual annotation and limited predefined fact types.</li>
<li>Unsupervised learning: need to systematically discover and unify latent and expressed knowledge from <strong><em>traditional symbolic semantics and modern distributional semantics</em></strong> through advanced <strong>machine learning models</strong>.</li>
</ol>
<h3 id="Ambiguity-in-a-Sentence"><a href="#Ambiguity-in-a-Sentence" class="headerlink" title="Ambiguity in a Sentence"></a>Ambiguity in a Sentence</h3><p>Natural Language Processing (NLP) technologies currently rely heavily on surface processing. This makes it difficult to exploit <strong>deep structure, background knowledge and source information</strong>.</p>
<h3 id="The-Importance-of-Context"><a href="#The-Importance-of-Context" class="headerlink" title="The Importance of Context"></a>The Importance of Context</h3><p>With the growth of online social network- ing services, people rapidly invent new ways to communicate sensitive ideas. We call this phenomenon <strong>information morphing</strong>, which also existed in the traditional forms of communications. Morphing raises unique challenges for entity and event co-reference resolution.</p>
<h3 id="Discourse-Ambiguity"><a href="#Discourse-Ambiguity" class="headerlink" title="Discourse Ambiguity"></a>Discourse Ambiguity</h3><p>Besides sentence-level and subsentence-level ambiguities, there is yet one more level of ambiguity: super-sentential, or discourse level ambiguity which goes beyond sentence boundaries.This third level of ambiguity comes from two sources:</p>
<ol>
<li><strong>coreference ambiguity</strong>: pronouns often refer to entities outside of the current sentence and it is ambiguous to which entity they refer.</li>
<li><strong>discourse structural ambiguity</strong>: a discourse, like a sentence, has its own internal structure, often represented as a tree or graph. For deep understanding of the text, we need to know, for example, which sentence is the topic sentence, which sentence is the elaboration or contrast of another sentence, and the temporal structure between sentences (in a story line).</li>
</ol>
<h3 id="Expressions-of-Fuzziness-and-Vagueness"><a href="#Expressions-of-Fuzziness-and-Vagueness" class="headerlink" title="Expressions of Fuzziness and Vagueness"></a>Expressions of Fuzziness and Vagueness</h3><p>Human sources typically describe objects using <strong>fuzzy terms</strong>, e.g., “she is very tall” instead of precise terms, e.g., “she is 6’2’’ tall.” It is very difficult to convert fuzzy terms into numbers as the use of such terms varies wildly over different humans or societies. It is much easier to calibrate physical sensors whose noise performance can be consistently measured.</p>
<h2 id="Future-Directions"><a href="#Future-Directions" class="headerlink" title="Future Directions"></a>Future Directions</h2><p>The field of social sensing lacks a unified interdisciplinary problem formulation that takes a holistic approach to modeling humans as sensors, and modeling social media as noisy measuring instruments or channels.</p>
<h3 id="5-required-synergistic-disciplines"><a href="#5-required-synergistic-disciplines" class="headerlink" title="5 required synergistic disciplines"></a>5 required synergistic disciplines</h3><ol>
<li><strong>computational social scientists</strong>: to model human behavior and quantify its susceptibility to errors, omissions, deceit, and other irregularities.</li>
<li><strong>linguistics</strong>: to model strengths and imperfections of human communication and their compounding effects on reliability of information dissemination.</li>
<li><strong>information theorists</strong>: to model social networks as imperfect<br>communication media and derive fundamental capacity<br>limits and uncertainty envelopes.</li>
<li><strong>data mining experts</strong>: to investigate the impact of the underlying error models relying on knowledge extraction from imperfect information.</li>
<li><strong>cyber-physical experts</strong>: to develop estimation-theoretic observability and control limits and tools that offer closed-loop robustness guarantees in the face of derived capacity limits, uncertainty envelopes, and knowledge errors.</li>
</ol>
<p>Social Sensing is interdisciplinary research area which aims to bring about novel solutions for a better theoretical and systematic understanding of the future sensor and media-rich world.</p>
]]></content>
      <categories>
        <category>Literature review</category>
      </categories>
  </entry>
  <entry>
    <title>Is Social Media Hurting Your Mental Health?</title>
    <url>/2020/01/22/Is-Social-Media-Hurting-Your-Mental-Health/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><iframe width="560" height="315" src="https://www.youtube.com/embed/Czg_9C7gw0o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="four-of-the-most-common-stressors-on-social-media"><a href="#four-of-the-most-common-stressors-on-social-media" class="headerlink" title="four of the most common stressors on social media"></a>four of the most common stressors on social media</h2><a id="more"></a>
<h3 id="1-the-Highlight-Reel"><a href="#1-the-Highlight-Reel" class="headerlink" title="1. the Highlight Reel."></a>1. the Highlight Reel.</h3><p>Just like in sports, the highlight reel is a collection of the best and brightest moments. Social media is our personal highlight reel. It’s where we put up our wins, or when we look great, or when we are out with friends and family. But we struggle with insecurity because we compare our behind-the-scenes with everyone else’s highlight reels. We are constantly comparing ourselves to others.</p>
<p>Yes, this was happening before social media, with TV and celebrity, but now it’s happening all the time, and it’s directly linked to you. A perfect example I came across in preparation for this talk is my friend on vacation: ‘brb, nap’. ‘Wait, why can’t I afford a vacation? Why am I just sitting here in my PJ’s watching Netflix? I want to be on a beach.’</p>
<p>Here’s the thing, I know her very well. I knew this was out of the ordinary for her. I knew she was typically drowning in schoolwork. But we think, ‘Who wants to see that?’ The highlights are what people want to see. In fact, when your highlights do well, you encounter the second stressor on social media.</p>
<h3 id="2-Social-Currency"><a href="#2-Social-Currency" class="headerlink" title="2. Social Currency."></a>2. Social Currency.</h3><p>Just like the dollar, a currency is literally something we use to attribute value to a good or service. In social media, these likes, the comments, the shares have become this form of social currency by which we attribute value to something. In marketing, we call it the ‘Economy of Attention’. Everything is competing for your attention, and when you give something a like or a piece of that finite attention, it becomes a recorded transaction attributing value.</p>
<p>Which is great if you are selling albums or clothing. The problem is that in our social media, [WE are the product] We are letting others attribute value to us. You know someone or are someone that has taken down a photo because it didn’t take as many likes as you thought it would. I’ll admit, I’ve been right there with you.</p>
<p>We took our product off the shelf because it wasn’t selling fast enough. This is changing our sense of identity. We are tying up our self-worth of what others think about us and then we are quantifying it for everyone to see. And we are obsessed. We have to get that selfie just right, and we will take 300 photos to make sure.</p>
<p>Then we will wait for the perfect time to post. We are so obsessed we have biological responses when we can’t participate.</p>
<h3 id="3-FOMO"><a href="#3-FOMO" class="headerlink" title="3. FOMO"></a>3. FOMO</h3><p>It’s a light phrase we’ve all thrown around FOMO, or the ‘fear of missing out’, is an actual social anxiety from the fear that you are missing a potential connection, event, or opportunity. A collection of Canadian Universities found that 7/10 students said they would get rid of their social networking accounts if it were not for fear of being left ‘out of the loop’. Out of curiosity, how many people here have, or have considered deactivating your social.</p>
<p>That’s almost everyone. That FOMO you feel, the highlight reels, the social currency, those are all results of a relatively ‘normal’ social media experience. But what if going on social every day was a terrifying experience? Where you not just question your self-worth but you question your safety?</p>
<h3 id="4-Online-Harassment"><a href="#4-Online-Harassment" class="headerlink" title="4. Online Harassment"></a>4. Online Harassment</h3><p>40% of online adults have experienced online harassment. 73% have witnessed it. The unfortunate reality is that it is much worse and much more likely if you are a woman, LGBTQ, a person of color, muslim – I think you get the point.</p>
<p>The problem is that in the news we are seeing these big stories: The 18-year-old Tyler Clementi, who took his life after his roommate secretly filmed him kissing another guy and outed him on Twitter. We see women like Anita Sarkeesian being close to shamed of the internet and sent death and rape threats for sharing their feminism.</p>
<p>We see these stories once it is too late. What about the everyday online harassment? What about that ugly snapchat you sent your friend with the intention of it being private, and now it is up on Facebook? ‘And so? It’s just one photo, it’s funny’ ‘Just one mean comment, not a big deal.’</p>
<p>But when these micro moments happen over and over again, over time, that’s when we have a macro problem. We have to recognize these everyday instances as well. Because if they go unchecked and the effects unnoticed, we are going to have many more Tyler Clementis. The effects are not always easy to recognize.</p>
<h2 id="How-to-solve-this-problem"><a href="#How-to-solve-this-problem" class="headerlink" title="How to solve this problem"></a>How to solve this problem</h2><p><strong>Recognizing a problem</strong> is the first step to fixing it. So hearing this talk is just that, step one: recognize the problem. You know the power of suggestion, when someone tells you about something and you start seeing it everywhere.</p>
<p>That’s why awareness is critical. Because now you will at least be better able to recognize these effects if and when they happen to you.</p>
<p>The second thing you are going to do is <strong>audit your social media diet</strong>. The same way we monitor what goes into our mouth, monitor whatever goes into your head and heart. Ask yourself: ‘Did that Facebook scroll make me feel better or worse off?’ ‘How many times do I actually check likes?’ ‘Why am I responding this way to that photo?’ Then ask yourself if you are happy with the results.</p>
<p>You might be and that’s OK! But if you’re not, move on to step three. <strong>Create a better online experience.</strong> After my partner did his audit, he realized his self-worth was too tied up in social media, but particularly celebrities reminding him of the things he didn’t have. So he unfollowed all brands and all celebrities. That worked for him.</p>
<p>But it might not be celebrities for you. For me, I had to purge other people off my timeline. Let me tell you a secret. You do not have to follow your ‘friends’. The truth is that sometimes our friends, or the people we have on Facebook as a courtesy, they just suck online! You find yourself in this passive-aggressive status war you didn’t even know was happening.</p>
<p>Or you are looking at 50 photos of the same concert from the same angle. If you want to follow artists, or comedians, or cats, you can do that.</p>
<p>The last thing you will do is <strong>model good behavior</strong>. Offline we are taught not to bully other kids in the playground. We are taught to respect others and treat them how they deserve.</p>
<p>We are taught not to kick others when they are down, or take pleasure in their downfalls. Social media is a tool. A tool that can be used for good, for more positive groups, for revolutions, for putting grumpy cat in Disney movies. Internet is a weird place.</p>
<p>Is social media hurting your mental health? The answer is: it doesn’t have to. Social can tear you down, yes, or it can lift you up, where you leave feeling better off, or have an actual laugh-out-loud.</p>
<p>Finally, I have 24 hours in a day, if I spend two of those hours on social media, then I want my experiences to be full of inspiration, laughs, motivation, and a whole lot of grumpy cat in Disney movies.</p>
]]></content>
      <categories>
        <category>TED</category>
      </categories>
  </entry>
  <entry>
    <title>13 Things Mentally Strong People Don&#39;t Do</title>
    <url>/2020/01/22/13-Things-Mentally-Strong-People-Don-t-Do/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>By Amy Morin</p>
<p>Mentally strong people have healthy habits. They manage their emotions, thoughts, and behaviors in ways that set them up for success in life. Check out these things that mentally strong people don’t do so that you too can become more mentally strong.</p>
<a id="more"></a>
<iframe width="560" height="315" src="https://www.youtube.com/embed/TFbv757kup4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<ol>
<li><p>They Don’t Waste Time Feeling Sorry for Themselves<br>Mentally strong people don’t sit around feeling sorry about their circumstances or how others have treated them. Instead, they take responsibility for their role in life and understand that life isn’t always easy or fair.</p>
</li>
<li><p>They Don’t Give Away Their Power<br>They don’t allow others to control them, and they don’t give someone else power over them. They don’t say things like, “My boss makes me feel bad,” because they understand that they are in control over their own emotions and they have a choice in how they respond.</p>
</li>
<li><p>They Don’t Shy Away from Change<br>Mentally strong people don’t try to avoid change. Instead, they welcome positive change and are willing to be flexible. They understand that change is inevitable and believe in their abilities to adapt.</p>
</li>
<li><p>They Don’t Waste Energy on Things They Can’t Control<br>You won’t hear a mentally strong person complaining over lost luggage or traffic jams. Instead, they focus on what they can control in their lives. They recognize that sometimes, the only thing they can control is their attitude.</p>
</li>
<li><p>They Don’t Worry About Pleasing Everyone<br>Mentally strong people recognize that they don’t need to please everyone all the time. They’re not afraid to say no or speak up when necessary. They strive to be kind and fair, but can handle other people being upset if they didn’t make them happy.</p>
</li>
<li><p>They Don’t Fear Taking Calculated Risks<br>They don’t take reckless or foolish risks, but don’t mind taking calculated risks. Mentally strong people spend time weighing the risks and benefits before making a big decision, and they’re fully informed of the potential downsides before they take action.</p>
</li>
<li><p>They Don’t Dwell on the Past<br>Mentally strong people don’t waste time dwelling on the past and wishing things could be different. They acknowledge their past and can say what they’ve learned from it. However, they don’t constantly relive bad experiences or fantasize about the glory days. Instead, they live for the present and plan for the future.</p>
</li>
<li><p>They Don’t Make the Same Mistakes Over and Over<br>Mentally strong people accept responsibility for their behavior and learn from their past mistakes. As a result, they don’t keep repeating those mistakes over and over. Instead, they move on and make better decisions in the future.</p>
</li>
<li><p>They Don’t Resent Other People’s Success<br>Mentally strong people can appreciate and celebrate other people’s success in life. They don’t grow jealous or feel cheated when others surpass them. Instead, they recognize that success comes with hard work, and they are willing to work hard for their own chance at success.</p>
</li>
<li><p>They Don’t Give Up After the First Failure<br>Mentally strong people don’t view failure as a reason to give up. Instead, they use failure as an opportunity to grow and improve. They are willing to keep trying until they get it right.</p>
</li>
<li><p>They Don’t Fear Alone Time<br>Mentally strong people can tolerate being alone and they don’t fear silence. They aren’t afraid to be alone with their thoughts and they can use downtime to be productive. They enjoy their own company and aren’t dependent on others for companionship and entertainment all the time but instead can be happy alone.</p>
</li>
<li><p>They Don’t Feel the World Owes Them Anything<br>Mentally strong people don’t feel entitled to things in life. They weren’t born with a mentality that others would take care of them or that the world must give them something. Instead, they look for opportunities based on their own merits.</p>
</li>
<li><p>They Don’t Expect Immediate Results<br>Whether they are working on improving their health or getting a new business off the ground, mentally strong people don’t expect immediate results. Instead, they apply their skills and time to the best of their ability and understand that real change takes time.﻿</p>
</li>
</ol>
]]></content>
      <categories>
        <category>TED</category>
      </categories>
  </entry>
  <entry>
    <title>What makes a good life? - lesson from the Harvard Study of Adult Development</title>
    <url>/2020/01/22/What-makes-a-good-life-lesson-from-the-Harvard-Study-of-Adult-Development/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>This TedTalk by Robert Waldinger describes a study that began in 1938 and followed the lives of 724 men from their adolescence to their death (60% of them were still alive and participating in the study when the talk is given).<br>The Harvard Study of Adult Development is one of the longest studies of adult life which follows two groups of men: </p>
<ol>
<li>men who were <strong>sophomores at Harvard</strong></li>
<li>boys in the lower socioeconomic group/disadvantaged families in <strong>Boston’s poorest neighborhood</strong>.</li>
</ol>
<p>Each participant was medically examined, interviewed in their homes and had their families also interviewed. Every two years, the participants would answer another set of questions about their life (work, home, health…), complete a face-to-face interview, and a multitude of other data submissions.<br>The main conclusion of this 75-year study is this: <strong><em>Good relationships keep us happier and healthier.</em></strong></p>
<a id="more"></a>
<iframe width="560" height="315" src="https://www.youtube.com/embed/8KkKuTCFvzI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>This study found that the impact of relationships on our happiness and health is broken down into 3 main lessons:</p>
<ol>
<li><strong><em>Social connections are really good for us</em></strong>: The more social connections one has, the happier, healthier, and longer that individual will live. These connections can be with <strong>family, friends, or community</strong>.</li>
<li><strong><em>The quality of relationships is greater than the quantity</em></strong>: Having poor or conflict-ridden relationships significantly impacts physical health and mental well-being (e.g. High-conflict marriage without much affection). The people who are most satisfied with their relationships at the age of 50 are the healthiest when they are 80.</li>
<li><strong><em>Quality relationships protect our bodies and our brains</em></strong>: This study found that individuals who were in a securely attached relationship in their 80s maintained <strong>sharper memories</strong>longer than those who were not in a relationship. Our relationships, protect our brain and maintain <strong>our brain’s cognitive functioning</strong>.</li>
</ol>
<p>People ignored these points because managing relationship is a messy and complex work. It’s lifelong and the possibilities are practical endless. Young adults tend to believe that fame, wealth and high achievements are what they need to go after to have a good life. However, as the study has shown, the people who fared best are the people who leaned into relationships with families, with friends, with community.<br>We can’t predict what will it be like if we lean into relationships for now. But we can <strong>live up the relationships by doing something new together</strong>, like long walks and date nights, or even reaching out to that family member who you haven’t spoken to in years, because those all-too-common family feuds take a terrible toll on people who hold the grudges.</p>
]]></content>
      <categories>
        <category>TED</category>
      </categories>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/06/14/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>This is a previous auto-generated hexo user manual. And I keep adding some new issues.</p>
<a id="more"></a>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>About <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>: Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. When getting troubles, find answers in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or ask questions on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<ol>
<li>Create a new post</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<ol>
<li>Run server</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo s</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<ol>
<li>Generate static files</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo g</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<ol>
<li>Deploy to remote sites</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>
<p>More info: </p>
<ol>
<li><a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></li>
<li><a href="https://www.jianshu.com/p/f054333ac9e6" target="_blank" rel="noopener">Personally Beautify</a></li>
</ol>
<h2 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h2><p>Display only a part of the post: <code>&lt;!--more--&gt;</code></p>
<p>See:</p>
<ol>
<li><a href="https://www.jianshu.com/p/191d1e21f7ed" target="_blank" rel="noopener">Basic Syntax of Text</a> </li>
<li><a href="https://www.jianshu.com/p/e74eb43960a1" target="_blank" rel="noopener">Basic Mathematical Symbols</a></li>
<li><a href="https://blog.csdn.net/jyfu2_12/article/details/79207643" target="_blank" rel="noopener">Latex Formulars</a></li>
<li><a href="https://www.jianshu.com/p/523e806d6681" target="_blank" rel="noopener">Install MathJax</a></li>
<li><a href="https://www.jianshu.com/p/a0aa94ef8ab2" target="_blank" rel="noopener">MathJax</a></li>
<li><a href="http://www.ixirong.com/2016/08/17/hexo-next-plugin-test/" target="_blank" rel="noopener">Table, PDF…</a></li>
</ol>
<h2 id="Embed-Vedio"><a href="#Embed-Vedio" class="headerlink" title="Embed Vedio"></a>Embed Vedio</h2><p>To embed a YouTube video:</p>
<ol>
<li>Press the buttom “Share” below the video, and get the embed code.</li>
<li>Pase it directly in the Markdown document.</li>
</ol>
<p>e.g.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/p-y3zjfPjBg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</span><br></pre></td></tr></table></figure></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/p-y3zjfPjBg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Limit-Access-to-Some-Posts"><a href="#Limit-Access-to-Some-Posts" class="headerlink" title="Limit Access to Some Posts"></a>Limit Access to Some Posts</h2><ol>
<li><a href="https://www.jianshu.com/p/79fe9fb9dfa0" target="_blank" rel="noopener">hide some posts at the home page</a></li>
</ol>
<h2 id="Visual-Design"><a href="#Visual-Design" class="headerlink" title="Visual Design"></a>Visual Design</h2><h3 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a><a href="https://getbootstrap.com" target="_blank" rel="noopener">Bootstrap</a></h3><p>Bootstrap can be used to design a beautiful and insightful website with navigation bars on the top of the website.</p>
<h3 id="Graphic-Design"><a href="#Graphic-Design" class="headerlink" title="Graphic Design"></a>Graphic Design</h3><p><a href="https://www.fevte.com/tutorial-33830-1.html" target="_blank" rel="noopener">Some Beautiful Fonts</a></p>
<h2 id="Data-Visualization"><a href="#Data-Visualization" class="headerlink" title="Data Visualization"></a>Data Visualization</h2><h3 id="D3-js"><a href="#D3-js" class="headerlink" title="D3.js"></a><a href="https://d3js.org" target="_blank" rel="noopener">D3.js</a></h3><p>See: <a href="https://curran.github.io/dataviz-course-2018/" target="_blank" rel="noopener">Online course on data visualization analysis, design &amp; construction with D3.js</a></p>
<h2 id="Interaction"><a href="#Interaction" class="headerlink" title="Interaction"></a>Interaction</h2><h3 id="JQuery"><a href="#JQuery" class="headerlink" title="JQuery"></a><a href="https://jquery.com" target="_blank" rel="noopener">JQuery</a></h3><p>JQury can be used to build an interactive table rather than the common HTML table.</p>
]]></content>
      <categories>
        <category>Maintainance</category>
      </categories>
  </entry>
  <entry>
    <title>Towards Scalable and Dynamic Social Sensing Using A Distributed Computing Framework</title>
    <url>/2019/06/14/Towards-Scalable-and-Dynamic-Social-Sensing-Using-A-Distributed-Computing-Framework/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>Reference: <a href="https://www3.nd.edu/~sslab/pdf/icdcs17.pdf" target="_blank" rel="noopener">Towards Scalable and Dynamic Social Sensing Using A Distributed Computing Framework</a><br>2nd paper review for 2019 <a href="https://international.nd.edu/students-scholars/global-engagement-programs/summer-programs/isure/" target="_blank" rel="noopener">iSURE</a> @ <a href="https://www3.nd.edu/~sslab/" target="_blank" rel="noopener">Social Sensing Lab at University of Notre Dame</a>.</p>
</blockquote>
<p>This paper developed a <strong>Scalable Streaming Truth Discovery (SSTD)</strong> solution to address the problems of <strong><em>truth discovery</em></strong>: dynamic truth, scalability and heterogeneity of streaming data.</p>
<ol>
<li><strong>Dynamic</strong> truth discovery: the ground truth of claims changes over time.</li>
<li>Scalability to large-scale social sensing events.</li>
<li>The heterogeneity and unpredictability of the social sensing data traffic. And additional challenges to the <strong>resource allocation</strong> and system responsiveness.</li>
</ol>
<p>Methods in the solution:</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model" target="_blank" rel="noopener">Hidden Markov Models(HMM)</a> help the <strong>dynamic</strong> truth discovery scheme effectively infer the evolving truth of reported claims.</li>
<li>A distributed framework implements the <strong>dynamic</strong> truth discovery scheme using Work Queue in <a href="https://research.cs.wisc.edu/htcondor/description.html" target="_blank" rel="noopener">HTCcondor</a> system.</li>
<li>the SSTD scheme intergraded with an optimal <strong>workload allocation</strong> mechanism .</li>
</ol>
<p>Evaluation using Twitter data feeds: Boston Bombing, Paris Shooting and College Football</p>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Goal of truth discovery</strong>: to identify the reliability of the sources and the truthfulness of claims they make without the prior knowl edge.</p>
<h3 id="Three-challenges"><a href="#Three-challenges" class="headerlink" title="Three challenges"></a>Three challenges</h3><h4 id="The-dynamic-truth-challenge"><a href="#The-dynamic-truth-challenge" class="headerlink" title="The dynamic truth challenge"></a>The dynamic truth challenge</h4><p>two critical tasks:</p>
<ol>
<li>to capture the transition of truth in <strong>a timely manner</strong></li>
<li>to be <strong>robust against noisy data</strong> that may lead to the incorrect detection of the truth transition.</li>
</ol>
<h4 id="The-Scalability-aspect-of-the-truth-discovery-problem"><a href="#The-Scalability-aspect-of-the-truth-discovery-problem" class="headerlink" title="The Scalability aspect of the truth discovery problem"></a>The Scalability aspect of the truth discovery problem</h4><p>Current centralized truth discovery solutions are incapable of handling large volume of social sensing data due to the resource limitation on a single computing device.<br>A distributed solution based on Hadoop system is not very good, bucause:</p>
<ol>
<li>its a heavy-weight solution which requires a long time to start</li>
<li>it is suitable for data of very large volume (far more large than we need for social sensing network)</li>
<li>it ignores the heterogenity of the computational resources.</li>
</ol>
<h4 id="The-heterogenity-and-unpredictability-of-the-streaming-data-traffic"><a href="#The-heterogenity-and-unpredictability-of-the-streaming-data-traffic" class="headerlink" title="The heterogenity and unpredictability of the streaming data traffic"></a>The heterogenity and unpredictability of the streaming data traffic</h4><ol>
<li>different topics or evens generate different amounts i social sensing data</li>
<li>the traffic volume of the same event is noy constant over time.</li>
</ol>
<h3 id="Solution-of-this-paper"><a href="#Solution-of-this-paper" class="headerlink" title="Solution of this paper"></a>Solution of this paper</h3><ol>
<li>a Hidden Markov Model based solution to <strong>dynamically</strong> estimate the true value of claims based on the observations reported by social sensors. </li>
<li>a light-weight distributed framework that is both <strong>scalable</strong> and efficient to solve the truth discovery problem using Work Queue and HTCondor system. </li>
<li>integrated the SSTD scheme with an optimal workload allocation mechanism using feedback control (i.e., Proportional Integral Derivative (PID) controller) to dynamically <strong>allocate the resources</strong> (e.g., cores, memories) to the truth discovery tasks. </li>
</ol>
<h2 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><h3 id="For-the-soicial-media"><a href="#For-the-soicial-media" class="headerlink" title="For the soicial media"></a>For the soicial media</h3><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.1.png" alt="Problem Formulation"><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.2.png" alt="Problem Formulation"></p>
<h3 id="For-the-deployed-system"><a href="#For-the-deployed-system" class="headerlink" title="For the deployed system"></a>For the deployed system</h3><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.3.png" alt="Problem Formulation"></p>
<h2 id="Scalable-and-Streaming-Truth-Discovery"><a href="#Scalable-and-Streaming-Truth-Discovery" class="headerlink" title="Scalable and Streaming Truth Discovery"></a>Scalable and Streaming Truth Discovery</h2><p>The Scalable and Streaming Truth Discovery (SSTD) scheme based on a Hidden Markov Model (HMM) is developed to decode the streaming social sensing date and output the corresponding truth values o claims in real time.<br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.4.png" alt="HMM"><br>This solution can be implemented in <strong>a distributed system</strong> where <strong>multiple truth discovery jobs can run in parallel</strong> to address the scalability challenge in social sensing applications.</p>
<h3 id="Deriving-Hidden-States-and-Observation-Sequence"><a href="#Deriving-Hidden-States-and-Observation-Sequence" class="headerlink" title="Deriving Hidden States and Observation Sequence"></a>Deriving Hidden States and Observation Sequence</h3><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.5.png" alt="HMM"></p>
<h3 id="Estimating-Parameters-of-the-HMM-Model"><a href="#Estimating-Parameters-of-the-HMM-Model" class="headerlink" title="Estimating Parameters of the HMM Model"></a>Estimating Parameters of the HMM Model</h3><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.6.png" alt="Define HMM parameters"><br><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.7.png" alt="Goal of Estimating"><br>this estimating problem is solved by an expectation maximization <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">(EM)</a> based algorithm.</p>
<h3 id="Decoding-State-Sequence"><a href="#Decoding-State-Sequence" class="headerlink" title="Decoding State Sequence"></a>Decoding State Sequence</h3><p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.8.png" alt="Goal of decoding"></p>
<p>This decoding problem is solved by the <a href="https://en.wikipedia.org/wiki/Viterbi_algorithm" target="_blank" rel="noopener">Viterbi Algorithm</a>.</p>
<p>By the esitimatied ${\lambda}_u$ of HMM model and the given observation sequence $F(u)$, we can infer the corresponding hidden true value sequence $VT_u$ that is most likely to generate the observations. It is solved recursively as follows:</p>
<p><img src="https://raw.githubusercontent.com/xiaxii/MarkdownPhotos/master/PR1.9.png" alt="Decoding"></p>
<h2 id="Implimentation-on-a-Distributed-Computer-Framework"><a href="#Implimentation-on-a-Distributed-Computer-Framework" class="headerlink" title="Implimentation on a Distributed Computer Framework"></a>Implimentation on a Distributed Computer Framework</h2><p>(to be continued…)</p>
]]></content>
      <categories>
        <category>Literature review</category>
      </categories>
  </entry>
</search>
